play video starting follow transcript 000 hello welcome cs410 dso text information systems online course offered university illinois urbanachampaign name chengxiang zhai nickname cheng im professor computer science university illinois urbanachampaign im instructor course lecture introduction course lets start motivation problem trying address course harness big text data text data kinds data form natural languages english chinese data growing quickly example find kinds web pages internet number pages growing quickly find blogs articles news articles emails documents enterprise environment course lot scientific literature text form social media growing quickly tweets social media data form text text data encode lot useful knowledge world sense data reported human census observe world analyzed data discover lot useful knowledge especially knowledge human opinions preferences data useful computational methods turn data useful knowledge applications main techniques making happen text retrieval text mining main techniques cover course logically order make lot text data text retrieval thats due large set text data smaller relevant set data actually particular problem step usually implemented text retrieval techniques involve humans loop find locate relevant documents particular problem find relevant documents step text mining analyze found relevant documents discover useful knowledge extract knowledge directly application especially application decision making two steps corresponding text retrieval text mining techniques cover course based picture show course designed leverage corresponding books ive offered coursera cover text retrieval text mining respectively book called text retrieval search engines second book called text mining analytics two books comprehensive lecture videos cover basic concepts principles methods text retrieval text mining respectively online course leverage lecture videos online quizzes provided coursera platform addition add additional components order explore applications books covered general techniques necessary discussing depths techniques applications make coverage complete cs410 adding two additional components course products technology review meant give students freedom particular way apply techniques learned two books solve real world problem learn particular topic project opportunities apply knowledge learned two books solve real world problem integrated manner technical review leverage learned learn tool kit particular technology extend knowledge solve problem format course mixture online videos plus high engagement module consists interactions forums explain later lot interactions help finish course project technology review number goals kept mind designing course share goals help understand course particular format asked components tasks goal emphasize theory practice theory obviously important basic concepts general principles covering theoretical part applicable applications means todays applications solving future problems general long lasting impact utility value achieved having watch lecture videos quizzes exams make sure mastered basic ideas basic concepts general principles general methods practical skills important specific practical skills immediately useful solving problems today able resolve problems encountered job achieved having programming assignments able existing tool kits look algorithms depths algorithms sense work improve finally course important integrate theory practice done having work course projects second goal personalized learning different different preference different schedules full time workers personalized learning important ensure receive best education achieve goal intentionally designed deadlines format course flexible lot freedom selfpaced learning example watch lecture videos anytime watch watch finish quizzes pretty anytime assignment program assigns particularly flexible way addition self paced learning choices topics project technology review able work topic thats interesting course project technology review finally goal collaborative learning maximize efficiency learning common goal help learn maximum amount knowledge spending hopefully minimum amount effort common goal work help achieve goal promote collaborative learning facilitate collaborative learning forumbased interactions enable different time zones interact effectively way support collaborative learning work groups finish cost projects technology reviews technology reviews products done working group overall format follows watch lecture videos two moocs slide take quizzes quizzes given weekly manner deadlines actually flexible able finish quizzes soon finish corresponding lecture videos quizzes two two kinds quizzes practice quizzes help understand concepts test quizzes course make sure mastered materials two exams two exams given end mooc corresponding exam given end mooc test retrieval second given end second mooc test mining period watching videos working programming assignments end semester leave two weeks time work intensively course project working course project semester time end semester course project sequentially following multiple steps select topic select topic list topics propose topic ask submit short proposal specific work middle semester asked short progress report check progress help timely manner end semester deliver two things software documentation upload public website available people second tutorial presentation short presentation explain software people technology review component mandatory component correlated based completion required finish component component designed give opportunity explore topic youre interested examination tool kit interested tool course project comparison multiple tools similar things looked multiple tools opportunity compare figure best writing helpful understand tool kit course interested methods indepth examine type methods write brief review looking cutting edge topic research write review recent papers topic hope able align technology review course project two synergistic technology review help learn topic related course project course project give motivation indepth study topic technology review course try help finish tasks best help means tas interact various ways help way synchronous question answering discussing forums way synchronous weekly office hours video teleconferencing grading done follows 25 grade based quizzes quizzes two moocs 30 based two exams two exams proctored exams 25 based programming assignments multiple programming assignments semester remaining 20 based course project thats distribution follows 5 topic selection 5 proposal 5 progress report 65 grade course project based software deposit deliverable project finally 20 based tutorial presentation components course project graded based completion lot tasks programming assignments graded way believe designed program assignments course project way able learn lot simply going tasks effective way learning thats grade based completion means lot control grades ensure finish tasks grades part based quality solution tutorial presentation actually based quality tutorial presenting based software actually work propose functions propose work likely affect grade tutorial presentation meaning software reason doesnt pass test deduct points technology review actually contributing grade metric component graded based completion 5 extra credit based participation forum discussions encourage help particularly answering questions posed able log data forum give credit extra credit extra credit points actually added regular points allow actually increase grade detail going determine final letter grades based grade points collected semester map slide five points bracket earned 5 extra credit adding extra credit likely help move grades bracket wont bracket feel fixed mapping give complete control grade monitor grade semester assess progress adjust schedule accordingly visualization workload horizontally show timeline instruction instruction vertically mainly six tasks semester spend time watching lecture videos thick black line shows effort probably spent watching lecture videos taking 12 quizzes spreading semester corresponding 12 weeks expected watch lecture videos emphasize spend time watch videos make sure understand materials take quizzes ensure dont leave holes way quizzes guide lecture videos leave holes hurt performance exams two proctored exams given middle semester later semester end two box third task fourth task programming assignments entire semester actually weeks semester weeks dont two weeks reserve work course project course project fifth component finally finish technology review work project expected done end semester actually start working beginning soon semester starts ask think topics discuss topics form teams submit proposal course 12 weeks occupied lecture videos quizzes assignments programming thats likely time work project end technology review designed extend knowledge based project course complete freedom topic review dont tie project imagine start working bit decided project topic decide tie technology review project good keep picture mind semester irregular schedule example find busy middle semester picture help adjust schedule degree probably work tasks beginning semester dont overwhelm middle semester similarly expect busy end semester start working project earlier hope picture mind able adjust schedule accordingly particularly work tasks proactively case anticipate busy time period taken moocs think naturally time work problems course take advantage proactively finish tasks quickly particular watched videos simply review try work quizzes finish quizzes quickly able finish programming assignments quickly going helpful sense lot time work course project allow help answering questions forums helping way teaming work project say tasks unfortunately fixed time work advance example two exams scheduled particular dates flexibility work earlier tasks programming assignments synchronized example run competition tasks synchronization thats needed minimize dependency hopefully work tasks early course encourage time finish challenging course project finish higher quality technology review rely lot forum discussion different time zones hard find time works forum important advantages able accommodate discussion primary way interactions engagement particular piazza forum courses proven useful forum lot useful functions second advantage forum enable ask questions soon question hopefully accelerate question answering question answered quickly forum waiting office hour finally hope forum discussions help identify difficult concepts lectures focus discussing concepts explaining concepts hard understand office hours make better office hours help reasons protocol question answering follows emphasize important follow protocol make effective office hours questions answered quickly help learning soon question issue discuss post immediately forum number advantages give opportunity question answered quickly question answered peers answered teacher posting question immediately better chance getting question answered quickly wont wait secondly question help students similar question realize encountered question articulated question helpful peers discussing question good way learn question answered timely manner forum addressed adequately perspective email question tas please subject line contains keyword cs410dso course subject line contain keywords based question dont receive reply email timely manner join officehour best reply emails depending number emails depending schedule able reply emails timely manner course best respond quickly cant come office hours try schedule office hours different time slots example time slot morning late morning early afternoon time slot evening hopefully accommodate different time zones slot time equally convenient best diversify time slots terms time terms days format office hours follows based make effective efficient limited office hours help best way hold weekly office hours publish time slots office hours given videoteleconference particularly zoom system worked join leave office hour time means join late leave early flexible dont feel come beginning office hour feel free stop ten minutes thats best time taking advantage forum discussion hopefully time going office hour deal relatively difficult questions priority give highest priority issues posted forums resolved email communications clearly toughest issues posted forum good answer emailed satisfactory solved give issues highest priority means issues raised office hour issues given priority look unresolved issues forums thats important post issue forum resolving issues posted forums take questions issues posted forums course hesitate bring questions issues discuss policy prioritize issues handle maximum benefit office hours efficiently finally say general course important advice plan ahead based schedule busy take look picture showed earlier tasks consider schedule try imagine periods relatively busy period identify tasks youre supposed work period try finish tasks earlier dont overlap busy period course time please know help forums step thing mention allocate sufficient time preparation two proctored exams given means chance take exam prepare exams confirm mastered materials similar questions quiz questions fact questions exactly questions quizzes allow sense questions look exams surprise actually worked questions quizzes made sure understood answers questions course try complete quizzes program assignments ahead time advantage raise questions earlier allow time questions answered time take quiz questions resolved allow actively help discuss problems encountered help earn extra credit second advice post questions forum immediately difficulty understanding part course materials emphasize immediate action posting issue question forums best resolve issues forums effective way engage peers help hesitate post questions wont penalize posting questions fact reward thats way contribute forum discussion finally leverage collaborative learning related posting questions forums actively participate forum discussion actually learn lot reading peoples posts know answers opinions expressed materials hope active discussion forums help help particularly time understand difficult concepts quizzes exams finish assignments smoothly finally encourage help understand materials encourage answer questions system record answers statistics give extra credit overall introduction course information visit course website coursera hope enjoy course look working thank
welcome cs 410 text information systems overview module familiar course instructor classmates learning environment time orientation take approximately 3 hours complete goals objectives goal orientation module familiarize course structure online learning environment orientation helps obtain technical skills required course module able recall important information course know classmates familiar discussion forums operate course instructional activities list activities assignments complete module click name activity detailed instructions activity estimated time required watch course introduction video opens new tab video previous semester information date accurate description cs410 fall 2023 please refer deck slides opens new tab 40 minutes read review syllabus opens new tab course deadlines opens new tab course communication opens new tab pages 45 minutes complete orientation quiz opens new tab 15 minutes complete course prequiz opens new tab 30 minutes mark completed item completed dislike report issue
syllabus cs 410 text information systems course description growth “big data” created unprecedented opportunities leverage computational statistical approaches turn raw data actionable knowledge support various application tasks especially true optimization decision making virtually application domains health medicine security safety learning education scientific discovery business intelligence course covers general computational techniques building intelligent text information systems help users manage make large amounts text data kinds applications text data data form natural language text eg english text chinese text web pages social media data tweets news scientific literature emails government documents kinds enterprise data text data play essential role lives communicate natural languages produce consume large amount text data covering kinds topics explosive growth text data makes impossible people consume relevant text data timely manner two main techniques assist people consuming digesting making text data text retrieval helps identify relevant text data particular problem large collection text documents avoiding processing large number nonrelevant documents text mining helps users analyze digest found relevant text data extract actionable knowledge finishing task course covers text retrieval text mining opportunity complete spectrum techniques building intelligent text information system building two moocs covering topic course project course enables learn basic concepts principles general techniques text retrieval mining gain handson experience software tools develop interesting text data applications course goals objectives successful completion course able explain basic concepts text retrieval text mining explain main ideas major models algorithms text retrieval text mining explain major models algorithms text retrieval text mining work explain implement commonly algorithms text retrieval text mining explain evaluate applications text retrieval text mining textbook required textbook course optional readings suggested weeks overview page readings listed weekly overview pages optional primarily following textbook zhai c massung s 2016 text data management analysis practical introduction information retrieval text mining acm book series morgan claypool publishers course outline dates topics 1 august 21 august 27 part speech tagging syntactic analysis semantic analysis ambiguity “bag words” representation push pull querying browsing probability ranking principle relevance vector space model dot product bit vector representation 2 august 28 september 3 term frequency tf document frequency df inverse document frequency idf tf transformation pivoted length normalization bm25 inverted index postings binary coding unary coding gammacoding dgap zipf’s law 3 september 4 10 cranfield evaluation methodology precision recall average precision mean average precision map geometric mean average precision gmap reciprocal rank mean reciprocal rank fmeasure normalized discounted cumulative gain ndcg statistical significance test 4 september 11 17 pr1qd query likelihood pqd statistical unigram language models maximum likelihood estimate background collection document language models smoothing unigram language models relation query likelihood tfidf weighting linear interpolation jelinekmercer smoothing dirichlet prior smoothing 5 september 18 24 relevance feedback pseudorelevance feedback implicit feedback rocchio feedback kullbackleiber divergence kldivergence retrieval function mixture language model scalability efficiency spams crawler focused crawling incremental crawling google file system gfs mapreduce link analysis anchor text pagerank 6 september 25 october 1 contentbased filtering collaborative filtering betagamma threshold learning linear utility user profile explorationexploitation tradeoff memorybased collaborative filtering cold start 7 october 2 8 text representation especially bagofwords representation context word context similarity paradigmatic relation syntagmatic relation 8 october 9 15 entropy conditional entropy mutual information topics coverage topic language model generative model unigram language model word distribution background language model parameters probabilistic model likelihood bayes rule maximum likelihood estimation prior posterior distributions bayesian estimation inference maximum posteriori map estimate prior model posterior mode exam 1 9 october 16 22 mixture model component model constraints probabilities probabilistic latent semantic analysis plsa expectationmaximization em algorithm estep mstep hidden variables hill climbing local maximum latent dirichlet allocation lda 10 october 23 october 29 clustering document clustering term clustering clustering bias perspective similarity hierarchical agglomerative clustering kmeans direction evaluation clustering indirect evaluation clustering text categorization topic categorization sentiment categorization email routing spam filtering naïve bayes classifier smoothing 11 october 30 november 5 generative classifier discriminative classifier training data logistic regression knearest neighbor classifier classification accuracy precision recall f measure macroaveraging microaveraging opinion holder opinion target sentiment opinion representation sentiment classification features ngrams frequent patterns overfitting 12 november 6 12 textbased prediction “data mining loop” context text data contextual text mining contextual probabilistic latent semantic analysis cplsa views topic coverage topics spatiotemporal trends topics event impact analysis networkregularized topic modeling netplsa causal topics iterative topic modeling time series supervision 13 november 13 18 project work 14 november 18 26 thanksgiving break 15 november 27 december 3 exam 2 new content work final project 16 december 4 10 final project presentation report due start finals elements course lecture videos instructor teach concepts know collection short video lectures stream videos playback browser clicking titles download video later offline playback clicking download icon videos usually total 15 2 hours generally spend least amount time digesting content videos actual amount time needed digest content naturally vary background quizzes weeks forcredit quiz two attempts quiz highest score final grade top 10 quiz scores calculate final grade drop two lowest quiz scores exams course two 1hour exams exams intended test understanding material learn course contain questions similar weekly quizzes programming assignments programming assignments course opportunity practice programming skills experiment algorithms data sets based youve learned course set aside 24 hours work programming assignment plan finish tech review 4credit students require generate brief review interesting courserelated cuttingedge technology topic covered lecture final course project culminating project due end course require work groups oneperson group allowed apply youve learned course solve real world problem developing new useful application extending existing tool add new functions software developed documentation made publicly available expected produce presentation demonstrate software developed grading final grade calculated based activities listed table note grade coursera accurately reflect grade course activity percent final grade quizzes 25 programming assignments 25 course project 20 exam 1 15 exam 2 15 letter grade points needed letter grade points needed letter grade points needed 95 b 80 c 60 90 b 75 d 55 85 b 70 f 55 final grade calculated based activities listed table official final course grade listed enterprise opens new tab course grade displayed coursera match official final course grade additional course policies student code policies student university illinois urbana‑champaign campus member university community members least rights responsibilities common citizens free institutional censorship affiliation university student diminish rights responsibilities held student community member citizen larger communities state nation world university illinois student code opens new tab information cs department maintains policies handbook graduate student information graduate student handbook opens new tab additionally coursera learners required follow honor code opens new tab code conduct opens new tab please review items commencing studies academic integrity students expected abide campus regulations academic integrity found student code conduct opens new tab standards enforced infractions rules tolerated course sharing copying providing part homework solution code infraction university’s rules academic integrity actively looking violations policy homework project submissions violation punished severely possible sanctions penalties typically ranging failing grade assignment failing grade course letter offending infraction kept students permanent university record good rule thumb keep typed word piece code think operating gray area probably clarification specifics please contact course staff disability accommodations students learning physical disabilities requiring assistance contact instructor soon possible you’re unsure applies think please contact instructor disability resources educational services dres opens new tab soon possible contact dres 1207 s oak street champaign phone 217 3331970 email disabilityillinoisedu opens new tab late policy late homework homework email accepted ta instructors prior instructor approval mark completed item completed dislike report issue
course deadlines late policies academic calendar 5course deadlines quizzes assignment release date hard deadline quiz 1 class end 7 quiz 2 class end 7 quiz 3 class end 7 quiz 4 class end 7 quiz 5 class end 7 quiz 6 class end 7 quiz 7 class end 13 quiz 8 class end 13 quiz 9 class end 13 quiz 10 class end 13 quiz 11 class end 13 quiz 12 class end 13 programming assignments assignment release date hard deadline programming assignment 1 2 sept 10 1159 pm cdt programming assignment 21 3 sept 17 1159 pm cdt programming assignment 22 sept 12 1159pm cdt sept 24 1159 pm cdt programming assignment 23 sept 21 1159pm cdt oct 1 1159 pm cdt programming assignment 3 sept 25 1159pm cdt oct 22 1159 pm cdt programming assignment 4 nov 8 1159pm cdt nov 19 1159pm cdt course project assignment release date hard deadline team formation sept 24 1159pm cdt oct 15 1159 pm cdt project proposal submission oct 1 1159pm cdt oct 27 1159 pm cdt project progress report submission nov 5 1159pm cdt nov 19 1159 pm cdt project progress report peer review nov 19 1159pm cdt nov 26 1159 pm cdt project code documentation submission nov 19 1159pm cdt dec 8 1159 pm cdt project presentation submission nov 18 1159pm cdt dec 8 1159 pm cdt project code documentation presentation peer review dec 3 1159pm cdt dec 15 1159 pm cdt technology review 4credit students assignment hard deadline technology review submission nov 12 1159 pm cdt exams exam name exam start date exam end date exam 1 mon oct 9 900am cdt sun oct 15 1000pm cdt exam 2 mon nov 27 900am cdt sun dec 3 1000pm cdt dates tentative subject change please informational item proctoru orientation module late policy specified assignments due 1159 pm central time due date time zone converter opens new tab hard deadline deadline receive 0 points assignments regardless did assignment late submission accepted extremely rare nonacademic circumstances usually require approval deans office weeks quiz due sunday late quiz submissions accepted hard deadline late penalty 5 deducted daily submission made grade reaches 0 requests extensions programming assignments handled case case basis please send email tas post privately class campuswire request extension make sure state reason requesting extension extensions guaranteed penalties apply assignment accepted december 15th academic calendar graduate college university illinois maintains graduate college calendar opens new tab calendar includes important dates final exam dates course registration cancellation holidays campus wide calendar opens new tab available cs department sends reminders upcoming deadlines receive graduate college newsletter exchange email account mark completed item completed dislike report issue
course communication course communication important announcements posted campuswire opens new tab forum please check periodically goto place ask clarifying questions course content quizzes programming assignments final project post check asked question highly recommended check campuswire forum least twice mcssupportillinoisedu goto place noncontent related administrative questions course staff program technical issues platform committed answering questions 24 48 hours working course staff response turnaround time course staff attempt ensure question answered 2448 hours posted mean post questions minute eg right deadline office hours course staff host weekly office hours zoom check weekly schedule attend office hours please refer live events opens new tab page zoom plan attend office hours please sign free zoom opens new tab account download zoom client application zoom training support please refer end page slack slack offers instant messaging collaboration connect class student sign free slack account httpsmcsdsstudentsslackcomsignup opens new tab make sure register illinoisedu email address emails work issues setting slack account please send inquiry email mcssupportillinoisedu slack account join slack channel course searching cs410textinfosyst course help resources course content issues discussions questions lecture videos assignments course campuswire opens new tab forum goto place search posted similar question post thread forum mcsds program support mcsds support team teaching operational specialists university illinois coursera dedicated providing program support help question course enrollment letters course completion reach team mcsdssupportillinoisedu coursera platform technical support technical issue coursera help center opens new tab great place start help center detailed information account setup opens new tab video troubleshooting downloads opens new tab assignments opens new tab peer reviews opens new tab degree student features opens new tab coursera policies opens new tab coursera platform urgent technical support speak urgent technical support welcome chat support support offered 24 hours 7 days degree student access chat support page course help center opens new tab remember coursera chat support know degree student please know degree student mcsds program soon start chat way ensure problem solved quickly possible zoom training support zoom help center opens new tab zoom help center offers comprehensive resources zoom type issues search solution zoom video tutorials opens new tab video tutorials taken pace zoom technical webinars opens new tab hosted month zoom weekly training webinars opens new tab free register join 90minute user onboarding session live qa attend view latest recording zoom 247 phone support phone dialin 18887999666 ext 2 16503976096 ext 2 zoom 247 live chat opens new tab live chat feature available lower bottom zoom pages popup button help click help button type question typing question live chat option chat zoom agent zoom ticket opens new tab submit ticket zoom nonurgent account technical issues mark completed item completed dislike report issue
office hours course staff host weekly office hours zoom check weekly schedule attend office hours please refer live events opens new tab page default days times online office hours held instructor tas follows times given central time 24hour clock time zone converter opens new tab occasionally change time particular office hour due schedule conflict case post announcement campuswire monday 7pm8pm yuxiang liu ta campuswire coordinator tuesday 8pm9pm chengxiang zhai instructor wednesday 8pm9pm yunzhe li ta course project coordinator thursday 8pm9pm muchun wang ta livedatalab support thursday 9pm10pm junting wang head ta overall coordinator friday 3pm4pm ruike zhu ta programming assignment coordintor mark completed item completed dislike report issue
programming assignments overview overview construction please check friday aug 25 4 programming assignments mps mps individual assignments unlimited attempts complete links python tutorials provided end reading programming assignments managed livedatalab opens new tab link work point please follow livedatalab setup instructions setup process needs completed please wait livedatalab setup 1 please sign livedatalab opens new tab illinois email id please note remember password log livedatalab 2 enroll course following link httplivedatalabcentraluscloudappazurecomcoursejoinwzs77p00e570j74 opens new tab 3 follow instructions pdf link github account livedatalab view pdf file livedatalab setuppdf pdf file please follow mp setup process pdf process needs completed mp view pdf file mpsetupfinalpdf pdf file python tutorials httpscs231ngithubiopythonnumpytutorialpython opens new tab httpsdocspythonorg3tutorial opens new tab httpswwwtutorialspointcompythonindexhtm opens new tab mark completed item completed dislike report issue
technology review information cs410 technology review 4credit students cs410 technology review technology review assignment designed students opportunity materials covered course lectures learn interesting courserelated cuttingedge technology topic covered lecture assignment student required write short review article chosen topic student list suggested topics instructor tas student propose topic list subject approval instructor topic technology review three broad topic categories related general topic “text data retrieval analysis” 1 useful software toolkits processing text data building text data applications 2 emerging new applications text retrieval analysis 3 new techniques text retrieval analysis list specific topics provided students students propose additional topics interesting subject approval instructor review cover toolkitapplicationtechnique indepth compare multiple toolkitsapplicationstechniques former allowed toolkitapplicationtechnique sufficiently complex justify devoting entire review case review novel content exist existing literature webpages offer unique informationknowledge learn review please make sure check review topic devote time complete review find existing review topic write topic make sure take different perspective existing review add new content top existing review extending way technology review completed individually graded based completion following two tasks 1 topic proposal student required select topic provided topic list propose topic deadline httpsdocsgooglecomspreadsheetsd1hwayxd82fcitn9eg3ymw6ckq6l1vasbtywpapbywmpcedituspsharing opens new tab sample topics provided httpsdocsgooglecomspreadsheetsd1yekm8hjbyrghiudvzv9s3zzu5hdteto6yecivposedituspsharing opens new tab 2 review submission student required submit complete technology review end 11 nov 12 2023 review coherent storyline intro body conclusion cite relevant references least 2 pages deadline set earlier time course project code submission give students opportunity read relevant reviews especially toolkits finishing projects mark completed item completed dislike report issue
proctoru exams dso section following information students dso section cs410 students sections tig tiu oncampus students schedule exams different way receive detailed instructions schedule exams schedule exam proctoru step 1 test equipment 1 check technical requirements online proctored exam make sure right computer equipment 2 test system’s equipment proctoru system test step 2 create proctoru user account 1 time scheduling exam proctoru click sign link university illinois proctoru portal page create new user account proctoru loginpassword 2 browser ask allow proctoru camera take snapshot note step skipped don’t wish take snapshot time case proctor upload picture testing session 3 fill fields account creation page username name name easily remember part email address symbol 4 accept terms service 5 click create account button create account 6 preferences page select dropdowns optimal time take exams eg weekdays weekends mornings evenings important depending specific exam window course preferred time available 7 click update button step 3 schedule exam 1 exams page click schedule new exam button schedule exam date time 2 fill institution term exam dropdown menus click find reservations button 3 schedule exam page select reservation time calendar bottom screen important reservations listed please select view radio button filter results display exam times specified preference 4 click book button desired exam appointment time 5 confirm selection page click proceed cart button ready continue 6 cart click proceed checkout button 7 enter appropriate credit card information click make payment note sections exams paid department 8 exam confirmation page receive email message scheduled exam information step 4 take exam 1 date time appointment login university illinois proctoru portal page 2 logging countdown exam time top page prior exam appointment reschedule reschedule button 3 appointment time start button appear appointment click start button connected proctor guide rest proctored exam process mark completed item completed dislike report issue
course project overview introduction course project give students handson experience developing novel information retrieval andor text mining tools allow students potentially apply knowledge skills learned course solve realworld problem group work encouraged required oneperson team maximum size team 5 members avoid challenges efficient coordination work team members team larger size possible subject approval instructor typical reason larger team project natural task division team members frequent interactions coordination team members minimum despite large size team possible collaboration multiple project teams strongly encouraged minimize amount work team expertise resource sharing generate “combined impact” eg team develop crawler team develops search engine grading criteria project graded based following weighting scheme corresponding three stages work 1 team search formation 2 proposal development 3 project result submission team members receive grade provided member made sufficient effort least 20 hours quality time work project team formation 5 student required form team beginning 9 oct 18 2023 team shall designate team members team leader responsible submitting andor uploading course project deliverables project proposal 5 project team required submit roughly onepage project proposal oct 27 2023 graded based completion specifically following grades assigned based answering questions expected answer information later 100 answers questions 90 missing two questions 75 missing two questions significantly incomplete understand 0 proposal repository progress report 5 project team required submit short progress report nov 19 2023 listing progress made remaining tasks challengesissues faced graded based completion respect addressing following points 1 progress made 2 remaining tasks 3any challengesissues faced grades assigned follows 100 addresses points 90 missing point 75 missing two points 0 missing points submission software code submission documentation 65 due dec 8 2023 project team asked submit produced source code reasonable documentation documentation cover software software implemented 65 grade distributed follows 45 source code submission 20 documentation submission graded based completion software usage tutorial presentation 20 due dec 8 2023 10 grading based completion remaining 10 based result testing software graders course project work graded primarily based effort followed guidelines completed required tasks receive least 90 total points project encourage students pay attention time management set realistic goals actually completed end semester remaining 10 based software works fully functioning software given 10 buggy software software missing functions result losing 10 grade completion functioning software emphasized due potential dependency multiple projects contributing larger project eg team produce crawler crawl data team build search engine proposal progress report final submission peergraded tas review peer reviews make sure 1 reviews fair 2 submissions satisfy requirements peergrading instructions peergrading grading project proposals progress reports final submissions later semester receive email cmt inviting reviewer make announcement emails peer grading begin soon submission deadlines passed progress report peergrading done nov 19 1200 cstnov 26 1159 pm cst final submissions peergrading done dec 08 1200 cstdec 15 1159 pm cst please finish gradings time project reviewed least 2 students student review 23 projects comments scores guide assign final scores projects please grade carefully honestly appreciate help managing grading large class hope process good learning experience specific instructions announced later instructions 1 form team 5 due beginning 9 oct 16 2023 beginning 9 form teams groups 5 members highly discouraged team needs designate member team team leader team leader responsible submitting andor uploading course project deliverables 1 form 2 proposal 3 presentation 4 code 2 pick topic write proposal 5 due end 9 oct 22 2023 picking project topic students able topic select topic list suggested topics 4 writing project proposal project team required write onepage proposal actually depth topic proposal due end 9 proposal names email addresses team members member designated project coordinatorleader team please make sure indicate project coordinator responsible coordination project work team communication instructor ta team needs help detailed instructions required content proposal provided 4 short set questions answered proposal long questions addressed applicable proposal long couple sentences question sufficient 3 work project try reuse existing tools possible minimize amount work sacrificing goal discuss problems issues teammates classmates campuswire leverage campuswire collaborate consistent course policy strongly encourage help course work maximize gain new knowledge skills minimizing work possible best help consider documenting work regularly way lot things written end semester 4 submit progress report 5 due nov 19 2023 team submit short report detailing 1 progress made 2 remaining tasks 3 challengesissues faced graders tas instructor help suggestions based report continue working project final submission 5 peerreview progress reports due nov 26 2023 student review progress reports 12 groups feedbacksuggestions 6 software code submission documentation 65 due middle 16 dec 08 2023 team submit software code produced project written documentation documentation consist following elements 1 overview function code 2 documentation software implemented sufficient detail basic understanding code future extension improvement 3 documentation usage software documentation usages apis detailed instructions install run software applicable 4 brief description contribution team member case multiperson team note team responsibility figure contribute group project act proactively timely manner group coordinator assigned task opportunity make task failed accomplish general members team grade project documentation submission indicates members superficially participated project actual work case discount grade expected spend least 20 hours seriously work course project minimum time spent preparing documentation 65 grade distributed follows 45 source code submission 20 documentation submission 20 documentation submission includes 5 overview functions 10 implementation documentation 5 usage documentation strict length requirement documentation 7 software usage tutorial presentation 20 due middle 16 dec 08 2023 end semester project team asked submit short tutorial presentation eg voiced ppt presentation explain developed software presentation 1 sufficient instructions install software applicable 2 sufficient instructions software 3 least example case allow grader provided case test software strict length requirement video submission target 510 minutes presentation shorter 5 minutes unlikely detailed help users understand software longer video 10 minutes long impatient users feel free produce longer presentation needed tutorial presentation graded based 1 completion presentation 10 2 result testing software graders 10 software passes test working expected full points given points deducted 10 allocated “result testing software graders” 8 peerreview project code documentation presentations due dec 15 2023 student review final project submissions 23 groups feedbacksuggestions mark completed item completed dislike report issue
1 overview six weeks course based content text retrieval search engines mooc weeks lessons learn overall design mooc overview natural language processing techniques foundation kinds textprocessing applications concept retrieval model basic idea vector space model time module take approximately 3 hours dedicated time complete videos assignments activities activities module listed required assignments bold activity estimated time required 1 video lectures 2 hours 1 graded quiz 1 hour goals objectives actively engage learning experiences module able explain basic concepts natural language processing text information access explain text retrieval defined ranking problem explain basic idea vector space retrieval model instantiate simplest bitvector representation guiding questions develop answers following guiding questions watching video lectures computer order understand natural language sentence ambiguity natural language processing nlp difficult computers bagofwords representation modern search engines simple representation text two modes text information access mode web search engine google support browsing useful querying help user find relevant information text retrieval task defined ranking task retrieval model two assumptions made probability ranking principle vector space retrieval model work define dimensions vector space model “bag words” representation mean retrieval function intuitively capture instantiate vector space model bag words representation bit representation documents queries additional readings resources following readings optional n j belkin w b croft 1992 information filtering information retrieval two sides coin commun acm 35 12 dec 1992 2938 c zhai s massung text data management analysis practical introduction information retrieval text mining acm book series morgan claypool publishers 2016 chapters 16 key phrases concepts keep eyes open following key terms phrases complete readings interact lectures topics help better understand content module part speech tagging syntactic analysis semantic analysis ambiguity “bag words” representation push pull querying browsing probability ranking principle relevance vector space model dot product bag words representation bit vector representation tips success recommend following review video lectures number times gain solid understanding key questions concepts introduced possible tips suggestions peers class learning community help learn grow way helping address questions peers pose engaging we’ll learn better it’s good idea refer video lectures chapter readings weve read reference responses appropriate critique information presented take notes read materials watch lectures taking notes interacting material find easier remember understand notes you’ll find it’s easier complete assignments ahead favor take notes getting giving help getgive help following means learner help center opens new tab find information regarding specific technical problems example technical problems error messages difficulty submitting assignments problems video playback find answer documentation report problem coursera staff clicking contact link available topics page learner help center content issues opens new tab forum report errors lecture video content assignment questions answers assignment grading text links course pages content course materials university illinois staff community tas monitor forum respond issues mark completed item completed dislike report issue
play video starting follow transcript 000 sound play video starting 9 follow transcript 009 lecture natural language content analysis picture step process text data text data natural languages computers understand natural languages extent order make data thats topic lecture going cover three things natural language processing main technique processing natural language obtain understanding play video starting 43 follow transcript 043 second state art nlp stands natural language processing play video starting 49 follow transcript 049 finally going cover relation natural language processing text retrieval nlp best way explain think text foreign language understand play video starting 16 follow transcript 106 order understand text basically computers facing looking simple sentence dog chasing boy playground play video starting 118 follow transcript 118 dont problems understanding sentence imagine computer order understand general following know dog noun chasings verb called lexical analysis partofspeech tagging figure syntactic categories words thats step going figure structure sentence example shows dog form noun phrase play video starting 155 follow transcript 155 wont dog structures right play video starting 24 follow transcript 204 structure shows look sentence try interpret sentence words words play video starting 216 follow transcript 216 show noun phrases intermediate components verbal phrases finally sentence structure called semantic analysis parsing parser accompanying program automatically created structure point know structure sentence dont know meaning sentence semantic analysis mind usually map sentence know knowledge base example imagine dog looks theres boy theres activity computer symbols denote play video starting 3 follow transcript 300 wed symbol d1 denote dog b1 denote boy p1 denote playground play video starting 312 follow transcript 312 chasing activity thats happening relationship chasing connects symbols computer obtain understanding sentence play video starting 325 follow transcript 325 representation infer things naturally think read text called inference example believe someones chased person scared rule computers infer boy scared extra knowledge youd infer based understanding text understand person say sentence language called pragmatic analysis order understand speak actor sentence right say basically achieve goal theres purpose language case person sentence reminding person bring back dog possible intent play video starting 433 follow transcript 433 reach level understanding require steps computer steps order completely understand sentence humans trouble understanding instantly play video starting 452 follow transcript 452 reason thats large knowledge base brain common sense knowledge help interpret sentence computers unfortunately hard obtain understanding dont knowledge base incapable reasoning uncertainties play video starting 514 follow transcript 514 makes natural language processing difficult computers fundamental reason natural language processing difficult computers simply natural language designed computers natural languages designed communicate languages designed computers example programming languages harder right natural languages designed make communication efficient result omit lot common sense knowledge assume knows keep lot ambiguities assume receiver hearer know decipher ambiguous word based knowledge context theres demand different words different meanings overload word different meanings problem play video starting 610 follow transcript 610 reasons makes step natural language processing difficult computers ambiguity main difficulty play video starting 618 follow transcript 618 common sense reasoning required thats hard play video starting 623 follow transcript 623 give examples challenges play video starting 627 follow transcript 627 consider word level ambiguity play video starting 630 follow transcript 630 word different syntactic categories example design noun verb play video starting 639 follow transcript 639 word root multiple meanings square root math sense root plant play video starting 646 follow transcript 646 able think meanings syntactical ambiguities example main topic lecture natural language processing actually interpreted two ways terms structure think moment figure usually think processing natural language think say language processing natural play video starting 716 follow transcript 716 example synaptic ambiguity different structures play video starting 724 follow transcript 724 applied sequence words common example ambiguous sentence following man boy telescope case question telescope play video starting 738 follow transcript 738 called prepositional phrase attachment ambiguity pp attachment ambiguity generally dont problem ambiguities lot background knowledge help disambiguate ambiguity play video starting 755 follow transcript 755 example difficulty anaphora resolution think sentence john persuaded bill buy tv question refer john bill background context figure finally presupposition problem consider sentence quit smoking obviously implies smoked play video starting 822 follow transcript 822 imagine computer wants understand subtle differences meanings lot knowledge figure maintain large knowledge base meanings words connected common sense knowledge world difficult play video starting 845 follow transcript 845 result steep perfect fact perfect understanding natural language computers slide sort gains simplified view state art technologies play video starting 91 follow transcript 901 part speech tagging pretty showed 97 accuracy number obviously based dataset dont take literally shows pretty perfect terms parsing partial parsing pretty means noun phrase structures verb phrase structure segment sentence dude correct terms structure play video starting 934 follow transcript 934 evaluation results 90 accuracy terms partial parsing sentences say numbers relative dataset datasets numbers lower existing work evaluated news dataset lot numbers biased news data think social media data accuracy likely lower play video starting 105 follow transcript 1005 terms semantical analysis able complete understanding sentence techniques allow partial understanding sentence mention example techniques allow extract entities relations mentioned text articles example recognizing dimensions people locations organizations text called entity extraction able recognize relations example person visited place person met person company acquired company relations extracted computer current natural language processing techniques theyre perfect entities entities harder play video starting 113 follow transcript 1103 word sense disintegration extend figure word sentence meaning context computer figure different meaning perfect direction play video starting 1119 follow transcript 1119 sentiment analysis meaning figure sentence positive negative especially useful review analysis example play video starting 1130 follow transcript 1130 examples semantic analysis help obtain partial understanding sentences play video starting 1138 follow transcript 1138 giving complete understanding showed sentence help gain understanding content useful play video starting 1151 follow transcript 1151 terms inference probably general difficulty inference uncertainties general challenge artificial intelligence thats probably dont complete semantical representation natural inaudible text hard domains limited domains lot restrictions word uses able perform inference extent general reliably speech act analysis done analysis special cases roughly gives idea state art talk bit cant cant 100 part speech tagging looks simple task think example two uses different syntactic categories try make fine grained distinctions easy figure differences play video starting 1310 follow transcript 1310 hard general complete parsing sentence example play video starting 1318 follow transcript 1318 ambiguity hard disambiguate imagine example lot knowledge context sentence background order figure actually telescope sentence looks simple actually pretty hard cases sentence long imagine four five prepositional phrases possibilities figure play video starting 1348 follow transcript 1348 harder precise deep semantic analysis heres example sentence john owns restaurant define owns exactly word understand hard precisely describe meaning computers play video starting 1411 follow transcript 1411 result robust general natural language processing techniques process lot text data play video starting 1422 follow transcript 1422 shallow way meaning superficial analysis example parts speech tagging partial parsing recognizing sentiment deep understanding understanding exact meaning sentence play video starting 1441 follow transcript 1441 hand deep understanding techniques tend scale meaning fill restricted text dont restrict text domain words techniques tend work work based machine learning techniques data similar training data program trained generally wouldnt work data different training data pretty summarizes state art natural language processing course short amount time cant give complete view nlp big field id expect multiple courses natural language processing topic relevance topic talk useful know background case happen exposed mean text retrieval play video starting 1548 follow transcript 1548 text retrieval dealing kinds text hard restrict text domain dealing lot text data means nlp techniques general robust efficient implies today fairly shallow nlp techniques text retrieval fact search engines today called bag words representation play video starting 1620 follow transcript 1620 probably simplest representation possibly think turn text data simply bag words meaning keep individual words ignore orders words keep duplicated occurrences words called bag words representation represent text way ignore lot valid information makes harder understand exact meaning sentence weve lost order play video starting 1653 follow transcript 1653 representation tends actually work pretty search tasks partly search task difficult matching query words text document chances document topic exceptions play video starting 1713 follow transcript 1713 comparison tasks example machine translation require understand language accurately translation wrong comparison tasks relatively easy representation sufficient thats representation major search engines today google bing play video starting 1735 follow transcript 1735 course put parentheses course queries answered current search engines require replantation bag words replantation require natural language processing done play video starting 1752 follow transcript 1752 reason sophisticated nlp techniques modern search engines thats retrieval techniques actually naturally solved problem nlp example word sense disintegration think word java mean coffee mean program language play video starting 1815 follow transcript 1815 look word anome ambiguous user uses word query usually words example im looking usage java applet applet implies java means program language contest help naturally prefer documents java referring program languages documents probably match applet java occurs documents means coffee match applet small probability case retrieval techniques naturally achieve goal word play video starting 191 follow transcript 1901 example technique called feedback talk later lectures technique allow add additional words query additional words related query words words help matching documents original query words occurred achieves extent semantic matching terms techniques helped bypass difficulties natural language processing play video starting 1940 follow transcript 1940 long run deeper natural language processing techniques order improve accuracy current search engines particularly needed complex search tasks play video starting 1952 follow transcript 1952 question answering play video starting 1955 follow transcript 1955 google recently launched knowledge graph step goal knowledge graph contain entities relations goes simple bag words replantation technique help improve search engine utility play video starting 2014 follow transcript 2014 significantly open topic research exploration sum lecture talked nlp weve talked state techniques finally explain bag words replantation remains dominant replantation modern search engines deeper nlp needed future search engines know take look additional readings cited thats good starting point thanks music
play video starting follow transcript 000 sound lecture going talk text access play video starting 14 follow transcript 014 previous lecture talked natural language content analysis play video starting 19 follow transcript 019 explained state natural language processing techniques good process lot unrestricted text data robust manner result bag words remains popular applications search engine play video starting 39 follow transcript 039 lecture going talk highlevel strategies help users access text data important step convert raw big text data small random data actually needed specific application main question address text information system help users access relevant text data going cover two complimentary strategies push versus pull play video starting 112 follow transcript 112 going talk two ways implement pull mode querying versus browsing play video starting 120 follow transcript 120 push versus pull play video starting 124 follow transcript 124 two different ways connect users right information right time play video starting 131 follow transcript 131 difference takes initiative play video starting 137 follow transcript 137 party takes initiative play video starting 140 follow transcript 140 pull mode users take initiative start information access process play video starting 147 follow transcript 147 case user typically search engine fulfill goal example user type query browse results find relevant information play video starting 22 follow transcript 202 usually appropriate satisfying users ad hoc information play video starting 210 follow transcript 210 ad hoc information temporary information example buy product suddenly read reviews related product cracked information purchased product generally longer information temporary information play video starting 231 follow transcript 231 case hard system predict proper users take initiative thats search engines useful today people information needs time speaking google probably processing queries adequate information needs play video starting 257 follow transcript 257 pull mode contrast push mode system take initiative push information user recommend information user case usually supported recommender system play video starting 313 follow transcript 313 appropriate user stable information play video starting 317 follow transcript 317 example research interest topic interest tends stay stable hobby example stable information case system interact learn interest monitor information stream system hasnt relevant items interest system take initiative recommend information example news filter news recommended system monitor news stream identify interesting news simply push news articles play video starting 359 follow transcript 359 mode information access property system good knowledge users happens search context example search information web search engine infer interested related formation recommend information reminds example advertisement placed search page play video starting 427 follow transcript 427 two high level strategies two modes text access play video starting 435 follow transcript 435 lets look pull mode detail play video starting 439 follow transcript 439 pull mode distinguish two ways help users querying versus browsing querying user enter query typical keyword query search engine system return relevant documents play video starting 454 follow transcript 454 works user knows exactly keywords know exactly looking tend know right keywords query works time play video starting 59 follow transcript 509 know doesnt work dont know right keywords query browse information topic area browsing useful case case browsing users simply navigate relevant information following paths play video starting 534 follow transcript 534 supported structures documents system maintain structures user follow structures navigate play video starting 547 follow transcript 547 works user wants explore information space user doesnt know keywords query simply user finds inconvenient type query user knows query type user cellphone search information harder enter query case browsing tends convenient relationship browsing querying best understood making imagine youre site play video starting 625 follow transcript 625 imagine youre touring city know exact address attraction play video starting 631 follow transcript 631 taking taxi fastest way directly site dont know exact address walk take taxi nearby place walk play video starting 644 follow transcript 644 turns exactly information studies know exactly looking right keywords query find information youre thats usually fastest way find information play video starting 659 follow transcript 659 dont know exact keywords clearly probably wont related pages walk information space meaning following links browsing finally relevant page play video starting 717 follow transcript 717 learn likely lot browsing looking area interesting attractions related inaudible analogy tells today good support query dont good support browsing order browse effectively map guide map chicago city chicago topical map tour information space construct topical map fact interesting research question bring interesting browsing experience web applications play video starting 819 follow transcript 819 summarize lecture weve talked two high level strategies text access push pull push tends supported recommender system pull tends supported search engine course sophisticated inaudible information system combine two play video starting 838 follow transcript 838 pull mode inaudible querying browsing generally combine two ways help assist support querying nad browsing play video starting 851 follow transcript 851 know relationship pull push read article give excellent discussion relationship machine filtering information retrieval informational filtering similar information recommendation push mode information access music
play video starting follow transcript 000 music lecture text retrieval problem play video starting 12 follow transcript 012 picture shows overall plan lectures play video starting 16 follow transcript 016 lecture talked high level strategies text access talked push versus pull play video starting 25 follow transcript 025 engines main tools supporting pull mode starting lecture going talk search engines work detail play video starting 38 follow transcript 038 text retrieval problem play video starting 42 follow transcript 042 going talk three things lecture define text retrieval second going make comparison text retrieval related task database retrieval play video starting 58 follow transcript 058 finally going talk document selection versus document ranking two strategies responding users query play video starting 19 follow transcript 109 text retrieval play video starting 112 follow transcript 112 task thats familiar web search engines time play video starting 119 follow transcript 119 text retrieval basically task system respond users query relevant documents basically supporting query play video starting 132 follow transcript 132 way implement poll mode information access play video starting 139 follow transcript 139 situation following collection text retrieval documents documents webpages web literature articles digital library text files computer play video starting 158 follow transcript 158 user typically give query system express information system return relevant documents users relevant documents refer documents useful user typed query play video starting 216 follow transcript 216 task phone call information retrieval play video starting 221 follow transcript 221 literally information retrieval broadly retrieval nontextual information example audio video worth noting text retrieval core information retrieval sense medias video retrieved exploiting companion text data example current image search engines actually match users query companion text data image play video starting 259 follow transcript 259 problem called search problem play video starting 35 follow transcript 305 technology called search technology industry play video starting 311 follow transcript 311 take course databases useful pause lecture point think differences text retrieval database retrieval two tasks similar ways play video starting 329 follow transcript 329 important differences play video starting 333 follow transcript 333 spend moment think differences two think data information managed search engine versus managed database system play video starting 347 follow transcript 347 think different queries typically specify database system versus queries typed users search engine play video starting 359 follow transcript 359 finally think answers play video starting 42 follow transcript 402 whats difference two okay think information data managed two systems text retrieval data unstructured free text databases structured data clear defined schema tell column names people column ages play video starting 431 follow transcript 431 unstructured text obvious names people mentioned text play video starting 440 follow transcript 440 difference text information tends ambiguous talk processing chapter databases dont tend find semantics play video starting 458 follow transcript 458 results important difference queries partly due difference information data play video starting 57 follow transcript 507 test queries tend ambiguous research queries typically welldefined think sql query clearly specify records returned welldefined semantics play video starting 527 follow transcript 527 keyword queries electronic queries tend incomplete doesnt specify documents retrieved complete specification returned play video starting 547 follow transcript 547 differences answers different case text retrieval looking documents play video starting 558 follow transcript 558 database search retrieving records match records sequel query precisely play video starting 69 follow transcript 609 case text retrieval right answers query specified discussed play video starting 621 follow transcript 621 unclear right answers query important consequences textual retrieval empirically defined problem play video starting 638 follow transcript 638 problem empirically defined mathematically prove method better method play video starting 652 follow transcript 652 means rely empirical evaluation involving users know method works better play video starting 72 follow transcript 702 thats lectures cover issue evaluation important topic sir jennings play video starting 713 follow transcript 713 knowing evaluate heroism properly theres way tell got better system better play video starting 728 follow transcript 728 lets look problem formal way play video starting 732 follow transcript 732 slide shows formal formulation text retrieval problem play video starting 737 follow transcript 737 vocabulary set set words language play video starting 744 follow transcript 744 considering language reality web multiple natural languages texts kinds languages play video starting 757 follow transcript 757 simplicity assume language techniques retrieving data multiple languages similar techniques retrieving documents end important difference principle methods similar play video starting 821 follow transcript 821 query sequence words play video starting 826 follow transcript 826 play video starting 831 follow transcript 831 query defined sequence words q sub word vocabulary play video starting 842 follow transcript 842 document defined way sequence words d sub ij word vocabulary play video starting 852 follow transcript 852 typically documents longer queries play video starting 857 follow transcript 857 cases documents short play video starting 94 follow transcript 904 think example case play video starting 99 follow transcript 909 hope think twitter search tweets short play video starting 916 follow transcript 916 general documents longer queries play video starting 922 follow transcript 922 collection documents collection large think web large play video starting 936 follow transcript 936 goal text retrieval youll find set relevant documents denote rq depends query general subset documents collection play video starting 952 follow transcript 952 unfortunately set relevant documents generally unknown userdependent sense query typed different users expect relevant documents different play video starting 109 follow transcript 1009 query given user hint document set play video starting 1017 follow transcript 1017 user generally specify exactly set especially case web search connections large user doesnt complete knowledge production play video starting 1034 follow transcript 1034 best search system compute approximation relevant document set denote rq task compute rq approximation relevant documents imagine asked write program play video starting 118 follow transcript 1108 think moment right input query documents play video starting 1120 follow transcript 1120 compute answers query set documents useful user play video starting 1129 follow transcript 1129 solve problem general two strategies play video starting 1139 follow transcript 1139 strategy document selection going binary classification function binary classifier play video starting 1149 follow transcript 1149 thats function take document query input give zero output indicate document relevant query play video starting 122 follow transcript 1202 case document play video starting 128 follow transcript 1208 relevant document set defined follows basically documents value 1 function play video starting 1225 follow transcript 1225 case system decide document relevant basically say zero called absolute relevance basically needs know exactly going useful user play video starting 1241 follow transcript 1241 alternatively theres strategy called document ranking play video starting 1246 follow transcript 1246 case system going make call document random system going real value function f play video starting 1258 follow transcript 1258 simply give value indicate document likely relevant play video starting 135 follow transcript 1305 going make call document relevant say document likely relevant function random documents going user decide stop user looks document threshold theta determine documents approximation set going assume documents ranked threshold set effect documents deliver user theta cutoff determined user play video starting 1356 follow transcript 1356 weve got collaboration user sense dont make cutoff user helped system make cutoff play video starting 148 follow transcript 1408 case system needs decide document likely relevant needs determine relative relevance play video starting 1419 follow transcript 1419 opposed absolute relevance play video starting 1422 follow transcript 1422 probably sense relative relevance easier determine absolute relevance case say exactly document relevant play video starting 1437 follow transcript 1437 turns ranking generally preferred document selection play video starting 1446 follow transcript 1446 lets look two strategies detail picture shows works left side documents pluses indicate relevant documents true relevant documents consists set true relevant documents consists process documents play video starting 1517 follow transcript 1517 document selection function going basically classify two groups relevant documents nonrelevant ones course classified perfect make mistakes approximation relevant documents got number documents play video starting 1543 follow transcript 1543 similarly relevant document thats misclassified nonrelevant case document ranking system simply ranks documents descending order scores going user stop user wants stop user wants examine documents user scroll stop inaudible user wants read random documents user stop top position case user stops d4 fact delivered four documents user play video starting 1633 follow transcript 1633 ranking generally preferred reasons classifier case document selection unlikely accurate clue usually query query accurate sense overly constrained play video starting 1657 follow transcript 1657 example expect relevant documents talk play video starting 174 follow transcript 1704 topics specific vocabulary result match relevant documents collection discussed topic vocabularies right case problem play video starting 1725 follow transcript 1725 relevant documents return case overconstrained query play video starting 1733 follow transcript 1733 hand query underconstrained example query sufficient descriptive words find random documents actually end having delivery thought words sufficient help find right documents turns sufficient distractions documents similar words case delivery play video starting 188 follow transcript 1808 unfortunately hard find right position two extremes play video starting 1815 follow transcript 1815 users looking information general user good knowledge information found case user good knowledge play video starting 1830 follow transcript 1830 vocabularies relevent documents hard user prespecify right level constraints play video starting 1844 follow transcript 1844 classifier accurate rend relevant documents generally equally relevant play video starting 1856 follow transcript 1856 relevance matter degree play video starting 1859 follow transcript 1859 prioritize documents user examine play video starting 196 follow transcript 1906 note prioritization important play video starting 1912 follow transcript 1912 user digest content user generally look document sequentially play video starting 1921 follow transcript 1921 make sense users relevant documents thats ranking reasons ranking generally preferred play video starting 1936 follow transcript 1936 preference theoretical justification given probability ranking principle play video starting 1944 follow transcript 1944 end lecture reference play video starting 1949 follow transcript 1949 principle says returning ranked list documents descending order probability document relevant query optimal strategy following two assumptions play video starting 202 follow transcript 2002 utility document user independent utility document play video starting 2010 follow transcript 2010 second user assumed browse results sequentially easy understand assumptions needed order justify site ranking strategy documents independent evaluate utility document thats separate play video starting 2036 follow transcript 2036 allow computer score document independently going rank documents based scrolls play video starting 2045 follow transcript 2045 second assumption say user follow rank list user going follow ranked list going examine documents sequentially obviously ordering optimal play video starting 21 follow transcript 2100 two assumptions theoretically justify ranking strategy fact best ive put question two assumptions hold play video starting 2118 follow transcript 2118 suggest pause lecture moment think play video starting 2127 follow transcript 2127 think examples suggest assumptions arent necessarily true play video starting 2144 follow transcript 2144 think moment realize assumptions actually true play video starting 2153 follow transcript 2153 example case independence assumption documents similar exactly content look relevant play video starting 227 follow transcript 2207 user assume generally useful user similar duplicated play video starting 2219 follow transcript 2219 clearly utility document dependent documents user play video starting 2227 follow transcript 2227 cases scenario document useful user three particular documents put answers users question play video starting 2242 follow transcript 2242 collective relevance suggests value document depend documents play video starting 2253 follow transcript 2253 sequential browsing generally make sense ranked list play video starting 2259 follow transcript 2259 rank list evidence showing users dont strictly sequentially entire list look bottom example skip think complicated interfaces possibly two dimensional phase put additional information screen sequential browsing restricted assumption play video starting 2332 follow transcript 2332 point play video starting 2335 follow transcript 2335 assumptions true play video starting 2341 follow transcript 2341 probability ranking principle establishes solid foundation play video starting 2346 follow transcript 2346 ranking primary pattern search engines actually basis lot research work information retrieval hours designed based assumption play video starting 241 follow transcript 2401 despite assumptions arent necessarily true address problem post processing ranked list example remove redundancy play video starting 2420 follow transcript 2420 summarize lecture main points take away following text retrieval empirically defined problem means algorithm better judged users second document ranking generally preferred help users prioritize examination search results play video starting 2447 follow transcript 2447 bypass difficulty determining absolute relevance help users determining make cut flexible play video starting 251 follow transcript 2501 suggests main technical challenge designing search engine design effective ranking function play video starting 2510 follow transcript 2510 words define value function f query document pair play video starting 2521 follow transcript 2521 design function main topic following lectures play video starting 2529 follow transcript 2529 two suggested additional readings classical paper probability ranking principle play video starting 2537 follow transcript 2537 second mustread research information retrieval classic ir book excellent coverage main research results early days time book written chapter six book indepth discussion probability ranking principle probably retrieval models general music
play video starting follow transcript 000 sound lecture overview text retrieval methods play video starting 13 follow transcript 013 previous lecture introduced problem text retrieval explained main problem design ranking function rank documents query lecture give overview different ways designing ranking function play video starting 33 follow transcript 033 problem following query sequence words document thats sequence words hope define function f play video starting 45 follow transcript 045 compute score based query document main challenge hear design good ranking function rank relevant documents top nonrelevant ones clearly means function able measure likelihood document d relevant query q means way define relevance particular order implement program computational definition relevance achieve goal designing retrieval model gives formalization relevance play video starting 132 follow transcript 132 decades researchers designed different kinds retrieval models fall different categories play video starting 142 follow transcript 142 family models based similarity idea play video starting 150 follow transcript 150 basically assume document similar query document say document relevant second case ranking function defined similarity query document known example case vector space model cover detail later lecture play video starting 220 follow transcript 220 second models called probabilistic models family models follow different strategy assume queries documents observations random variables play video starting 236 follow transcript 236 assume binary random variable called r play video starting 242 follow transcript 242 indicate document relevant query play video starting 246 follow transcript 246 define score document respect query probability random variable r equal 1 given particular document query different cases general idea classic probabilistic model language model divergence randomness model play video starting 312 follow transcript 312 later lecture talk case language model third model based probabilistic inference idea associate uncertainty inference rules quantify probability show query follows document play video starting 337 follow transcript 337 finally family models axiomatic thinking idea define set constraints hope good retrieval function satisfy play video starting 355 follow transcript 355 case problem seek good ranking function satisfy desired constraints play video starting 45 follow transcript 405 interestingly different models based different thinking end retrieval function tends similar functions tend involve similar variables lets take look common form state art retrieval model examine common ideas models play video starting 433 follow transcript 433 models based assumption bag words represent text explained natural language processing lecture bag words representation remains main representation search engines play video starting 453 follow transcript 453 assumption score query presidential campaign news respect document d based scores computed based individual word play video starting 59 follow transcript 509 means score depend score word presidential campaign news three different components corresponding document matches query words play video starting 531 follow transcript 531 functions number heuristics play video starting 538 follow transcript 538 example factor affects function d times word presidential occur document called term frequency tf play video starting 551 follow transcript 551 denote c presidential d general word occurs frequently document value function larger factor long document document length scoring general term occurs long document times significant occurred number times short document long document term expected occur frequently play video starting 638 follow transcript 638 finally factor called document frequency look presidential occurs entire collection call document frequency df presidential models probability characterize information play video starting 75 follow transcript 705 show probability presidential collection play video starting 710 follow transcript 710 trying characterize popularity term collection general matching rare term collection contributing overall score matching common term play video starting 725 follow transcript 725 captures main ideas pretty older state art original models play video starting 734 follow transcript 734 natural question model works best play video starting 739 follow transcript 739 turns models work equally list four major models generally regarded state art original models pivoted length normalization bm25 query likelihood pl2 optimized models tend perform similarly discussed detail reference end lecture bm25 probably popular likely virtually search engines method discussed research papers play video starting 822 follow transcript 822 talk method later lectures play video starting 830 follow transcript 830 summarize main points made lecture design good ranking function prerequires computational definition relevance achieve goal designing appropriate retrieval model play video starting 847 follow transcript 847 second models equally effective dont single winner researchers active working problem trying find truly optimal retrieval model play video starting 9 follow transcript 900 finally state art ranking functions tend rely following ideas bag words representation second tf document frequency words information weighting function determine overall contribution matching word document length combined interesting ways discuss exactly combined rank documents lectures later play video starting 936 follow transcript 936 two suggested additional readings time play video starting 941 follow transcript 941 paper find detailed discussion comparison multiple state art models play video starting 949 follow transcript 949 second book chapter gives broad review different retrieval models music
play video starting follow transcript 000 sound lecture vector space retrieval model going give introduction basic idea play video starting 18 follow transcript 018 lecture talked different ways designing retrieval model give different arranging function play video starting 30 follow transcript 030 lecture going talk specific way designing ramping function called vector space retrieval model play video starting 37 follow transcript 037 going give brief introduction basic idea play video starting 44 follow transcript 044 vector space model special case similarity based models discussed means assume relevance roughly similarity document query play video starting 12 follow transcript 102 assumption true actually question order solve search problem convert vague notion relevance precise definition implemented program analogy process make number assumptions assumption make basically assume document similar query document document assumed relevant second basis ranking documents approach play video starting 146 follow transcript 146 questionable best definition randoms later ways model randoms play video starting 158 follow transcript 158 basic idea vectors base retrieval model actually easy understand imagine high dimensional space dimension corresponds term play video starting 211 follow transcript 211 issue three dimensional space three words programming library presidential term defines dimension play video starting 224 follow transcript 224 consider vectors three dimensional space going assume documents query placed vector space example document represented vector d1 means document probably covers library presidential doesnt talk programming mean terms representation document means going look document perspective vector going ignore basically vector root condition document play video starting 314 follow transcript 314 course document information example orders words inaudible model thats assume inaudible words inaudible presentation d1 simply suggests inaudible library different document recommended different vector d2 case document covers programming library doesnt talk presidential remind probably guess topic likely program language library software lab library play video starting 358 follow transcript 358 shows vector space reproduction actually capture differences topics documents play video starting 49 follow transcript 409 imagine vectors example d3 pointing direction presidential program fact place documents vector space pointing kinds directions similarly going place query space vector play video starting 432 follow transcript 432 going measure similarity query vector document vector case example easily d2 closest query vector d2 rendered play video starting 451 follow transcript 451 basically main idea vector space model play video starting 458 follow transcript 458 precise vector space model framework framework make following assumptions represent document query term vector play video starting 518 follow transcript 518 term basic concept example word phrase n gram characters sequence characters word play video starting 534 follow transcript 534 term assumed defined dimension n terms vocabulary define ndimensional space play video starting 544 follow transcript 544 query vector consist number elements play video starting 549 follow transcript 549 corresponding weights different terms play video starting 556 follow transcript 556 document vector similar number elements value element indicating weight corresponding term assume n dimensions n elements play video starting 615 follow transcript 615 corresponding weight particular term play video starting 621 follow transcript 621 relevance case assumed similarity two vectors play video starting 629 follow transcript 629 ranking function defined similarity query vector document vector play video starting 637 follow transcript 637 ask write program implement approach search engine play video starting 644 follow transcript 644 realize clear havent lot things detail impossible actually write program implement thats framework play video starting 659 follow transcript 659 refined order actually play video starting 74 follow transcript 704 suggest particular ranking function implement computer play video starting 710 follow transcript 710 framework say actually hasnt things required order implement function play video starting 724 follow transcript 724 did say define select basic concepts exactly play video starting 732 follow transcript 732 clearly assume concepts orthogonal redundancy example two synonyms distinguish two different concepts defining two different dimensions clearly cause redundancy emphasizing matching concept match two dimensions actually matched semantic concept play video starting 811 follow transcript 811 secondly did say exactly place documents query space basically show examples query document vectors exactly vector particular document point play video starting 829 follow transcript 829 equivalent define term weights compute lose element values vectors important question term weight query vector indicates importance term play video starting 848 follow transcript 848 depending assign weight prefer terms matched play video starting 856 follow transcript 856 similarly total word document meaningful indicates term characterizes document got wrong clearly dont represent document accurately play video starting 910 follow transcript 910 finally define similarity measure given questions addressed operational function actually implement program language play video starting 925 follow transcript 925 solve problems main topic lecture music
play video starting follow transcript 000 lecture going talk instantiate vector space model specific ranking function play video starting 22 follow transcript 022 continue discussion vector space model particular approach design ranking function play video starting 34 follow transcript 034 going talk general framework vector space model guidance instantiate framework derive specific ranking function going cover symbolist instantiation framework play video starting 55 follow transcript 055 discussed previous lecture vector space model framework didnt say play video starting 15 follow transcript 105 discussed previous lecture vector space model framework say things play video starting 114 follow transcript 114 example shows did say define dimension play video starting 120 follow transcript 120 did say place document vector space play video starting 127 follow transcript 127 did say place query vector vector space play video starting 132 follow transcript 132 finally did say measure similarity query vector document vector play video starting 140 follow transcript 140 imagine order implement model play video starting 146 follow transcript 146 say specifically compute vectors exactly xi exactly yi play video starting 158 follow transcript 158 determine place document vector place query vector course say exactly similarity function play video starting 211 follow transcript 211 definition concepts define dimensions xis yis weights terms queries document able place document vectors query vectors defined space specify similarity function defined ranking function play video starting 241 follow transcript 241 lets think instantiation actually suggest pause lecture point spend couple minutes think suppose asked implement idea play video starting 259 follow transcript 259 come idea vector space model havent figured compute vectors exactly define similarity function play video starting 312 follow transcript 312 think couple minutes proceed play video starting 320 follow transcript 320 lets think simplest ways instantiating vector space model define dimension obvious choice word vocabulary define dimension show n words vocabulary n dimensions word defines dimension basically bag words play video starting 348 follow transcript 348 lets look place vectors space play video starting 354 follow transcript 354 simplest strategy play video starting 358 follow transcript 358 bit vector represent query document play video starting 44 follow transcript 404 means element xi yi taking value zero 1 play video starting 413 follow transcript 413 1 means corresponding word present document query 0 going mean absent play video starting 427 follow transcript 427 imagine user types words query query vector 1s zeros play video starting 437 follow transcript 437 document vector generally 1s course zeros vocabulary generally large words dont occur document play video starting 452 follow transcript 452 words occasionally occur document play video starting 458 follow transcript 458 lot words absent particular document play video starting 54 follow transcript 504 placed documents query vector space play video starting 511 follow transcript 511 lets look measure similarity play video starting 515 follow transcript 515 commonly similarity measure dot product play video starting 520 follow transcript 520 dot product two vectors simply defined sum products corresponding elements two vectors product x1 y1 x2 multiplied y2 finally xn multiplied yn take sum play video starting 550 follow transcript 550 thats dot product represent general way sum play video starting 558 follow transcript 558 different ways measuring similarity defined dimensions defined vectors defined similarity function finally simplest vector space model based bit vector inaudible dot product similarity bag words inaudible formula looks formula thats actually particular retrieval function ranking function right finally implement function program language rank documents query point pause lecture think interpreted score gone process modeling retrieval problem vector space model make assumptions place vectors vector space define similarity end weve got specific retrieval function play video starting 715 follow transcript 715 step think retrieval function actually makes sense right expect function actually perform rank documents users queries play video starting 728 follow transcript 728 worth thinking value calculating end number number mean meaningful play video starting 742 follow transcript 742 spend couple minutes sort think play video starting 745 follow transcript 745 course general question believe good ranking function actually work think interpret value actually meaningful play video starting 81 follow transcript 801 mean related document matched query play video starting 88 follow transcript 808 order assess simplest vector space model actually works lets look example play video starting 817 follow transcript 817 show sample documents sample query query news presidential campaign five documents cover different terms query play video starting 834 follow transcript 834 look documents moment realize play video starting 841 follow transcript 841 documents probably relevant probably relevant play video starting 848 follow transcript 848 asked rank documents rank basically ideal ranking humans examine documents try rank play video starting 93 follow transcript 903 think moment take look slide pausing lecture play video starting 912 follow transcript 912 think agree d4 d3 probably better cover query match news presidential campaign play video starting 927 follow transcript 927 looks documents probably better ranked top three d2 d1 d5 relevant say d4 d3 relevant documents d1 d2 d5 nonrelevant lets simplest vector space model closer lets think actually model score documents right show two documents d1 d3 query vector space model course compute vectors documents query showed vocabulary end dimensions thinking think vector query play video starting 1027 follow transcript 1027 note assuming zero 1 indicate term absent present query document zero1 bit vectors play video starting 1043 follow transcript 1043 think query vector play video starting 1047 follow transcript 1047 query four words four words 1 rest zeros play video starting 1057 follow transcript 1057 documents d1 two rows news two 1s rest zeroes similarly two vectors lets compute similarity play video starting 1117 follow transcript 1117 going product dot product multiply corresponding elements right two formal product two generate product two generate product play video starting 1140 follow transcript 1140 easily actually dont care play video starting 1148 follow transcript 1148 zeroes zero product zero take sum pairs zero entries gone play video starting 124 follow transcript 1204 long zero product zero fact counting pairs 1 1 case two result 2 mean means number value scoring function simply count unique query terms matched document term matched document two ones play video starting 1241 follow transcript 1241 zero document side play video starting 1246 follow transcript 1246 similarly document term term query zero query vector dont count result scoring function basically measures unique query terms matched document interpret score play video starting 137 follow transcript 1307 take look d3 case result 3 d3 matched three distinctive query words news presidential campaign d1 matched two case reasonable rank d3 top d1 play video starting 1329 follow transcript 1329 simplest vector space model looks pretty good examine model detail likely find problems im going show scores five documents easily verify theyre correct basically counting number unique query terms matched document play video starting 1356 follow transcript 1356 note measure actually makes sense right basically means document matches unique query terms document assumed relevant make sense problem note three documents d2 d3 d4 tied 3 score play video starting 1425 follow transcript 1425 thats problem look carefully d4 ranked d3 d3 mentions presidential d4 mentioned multiple times case d3 presidential dimension d4 clearly presidential campaign problem d2 d3 score look three words matched case d2 matched news campaign case d3 matched news presidential campaign play video starting 1512 follow transcript 1512 intuitively reads better matching presidential important matching presidential query play video starting 1526 follow transcript 1526 intuitively d3 ranked d2 model doesnt play video starting 1533 follow transcript 1533 means model good solve problems play video starting 1541 follow transcript 1541 summarize lecture talked instantiate vector space model play video starting 1547 follow transcript 1547 mainly three things define dimension second decide place documents vectors vector space place query vector space vector play video starting 167 follow transcript 1607 third define similarity two vectors particularly query vector document vector play video starting 1617 follow transcript 1617 talked various simple way instantiate vector space model thats probably simplest vector space model derive case word define dimension zero 1 bit vector represent document query case basically care word presence absence ignore frequency play video starting 1645 follow transcript 1645 dot product similarity function play video starting 1650 follow transcript 1650 instantiation showed scoring function basically score document based number distinct query words matched document play video starting 174 follow transcript 1704 showed simple vector space model doesnt work improve play video starting 1712 follow transcript 1712 topic going cover lecture music
2 overview weeks lessons learn vector space model works detail major heuristics designing retrieval function ranking documents respect query implement information retrieval system search engine build inverted index score documents quickly query time module take approximately 6 hours dedicated time complete videos assignments activities activities module listed assignments bold activity estimated time required 2 video lectures 2 hours 2 graded quiz 1 hour programming assignment 1 3 hours goals objectives actively engage learning experiences module able explain tfidf weighting tf transformation document length normalization necessary design effective ranking function explain inverted index construct large set text documents fit memory explain variablelength encoding compress integers unary coding gammacoding work explain scoring documents response query done quickly inverted index explain zipf’s law guiding questions develop answers following guiding questions completing readings working assignments different ways place document vector vector space term frequency tf tf transformation document frequency df inverse document frequency idf tfidf weighting penalize long documents text retrieval pivoted document length normalization main ideas retrieval function bm25 typical architecture text retrieval system inverted index desirable compress inverted index create inverted index collection documents fit memory leverage inverted index score documents quickly additional readings resources following readings optional c zhai s massung text data management analysis practical introduction information retrieval text mining acm book series morgan claypool publishers 2016 chapter 6 section 63 chapter 8 ian h witten alistair moffat timothy c bell managing gigabytes compressing indexing documents images second edition morgan kaufmann 1999 key phrases concepts keep eyes open following key terms phrases complete readings interact lectures topics help better understand content module term frequency tf document frequency df inverse document frequency idf tf transformation pivoted length normalization bm25 inverted index postings binary coding unary coding gammacoding dgap zipf’s law tips success recommend following review video lectures number times gain solid understanding key questions concepts introduced possible tips suggestions peers class learning community help learn grow way helping address questions peers pose engaging we’ll learn better it’s good idea refer video lectures chapter readings weve read reference responses appropriate critique information presented take notes read materials watch lectures taking notes interacting material find easier remember understand notes you’ll find it’s easier complete assignments ahead favor take notes getting giving help getgive help following means learner help center opens new tab find information regarding specific technical problems example technical problems error messages difficulty submitting assignments problems video playback find answer documentation report problem coursera staff clicking contact link available topics page learner help center content issues opens new tab forum report errors lecture video content assignment questions answers assignment grading text links course pages content course materials university illinois staff community tas monitor forum respond issues2 mark completed item dislike report issue
play video starting follow transcript 000 sound lecture going talk improve instantiation vector space model play video starting 17 follow transcript 017 continued discussion vector space model going focus improve instantiation model play video starting 30 follow transcript 030 previous lecture simple instantiations vector space model come simple scoring function give basically account unique query terms matched document play video starting 50 follow transcript 050 function problem slide particular look three documents score match three unique query words play video starting 16 follow transcript 106 intuitively d4 ranked d3 d2 relevant play video starting 114 follow transcript 114 problem function couldnt capture following heuristics give credit d4 matched presidential times d3 play video starting 132 follow transcript 132 second intuitively matching presidential important matching common word occurs doesnt carry content play video starting 147 follow transcript 147 lecture lets improve model solve two problems worth thinking point problems play video starting 21 follow transcript 201 look back assumptions made instantiating vector space model realize problem coming assumptions particular placed vectors vector space play video starting 222 follow transcript 222 naturally order fix problems revisit assumptions different ways instantiate vector space model particular place vectors different way play video starting 241 follow transcript 241 lets improve natural thought order consider multiple times term document consider term frequency absence presence order consider difference document query term occurred multiple times query term occurred consider term frequency count term document play video starting 313 follow transcript 313 simplest model modeled presence absence term ignored actual number times term occurs document lets add back going represent document vector term frequency element say elements query vector document vector 0 1s counts word query document play video starting 352 follow transcript 352 bring additional information document accurate representation documents lets formula look change representation youll slide dot product play video starting 410 follow transcript 410 formula looks similar form fact looks identical sum course x y different counts word query document point suggest pause lecture moment think interpret score new function similar simplest vsm change vector new score different interpretation difference consideration multiple occurrences term document importantly know fix problems simplest vector space model lets look example suppose change vector representation term frequency vectors lets look three documents query vector words occurred exactly query vector 01 vector fact d2 essentially representing way words repeated times result score 3 play video starting 545 follow transcript 545 true d3 3 play video starting 551 follow transcript 551 d4 different presidential occurred twice ending presidential document vector 2 1 play video starting 64 follow transcript 604 result score d4 higher 4 play video starting 610 follow transcript 610 means term frequency rank d4 d2 d3 hoped play video starting 619 follow transcript 619 solved problem d4 play video starting 626 follow transcript 626 d2 d3 filtering way identical scores did fix problem play video starting 640 follow transcript 640 fix problem intuitively give credit matching presidential matching solve problem general way way determine word treated importantly word basically ignored word carry content essentially ignore call word stock word generally frequent occur matching doesnt mean computationally capture play video starting 724 follow transcript 724 encourage think bit play video starting 729 follow transcript 729 came statistical approaches distinguish presidential play video starting 737 follow transcript 737 think moment youll realize difference word occurs count occurrence word collection higher frequency presidential tends occur documents play video starting 81 follow transcript 801 idea suggests global statistics terms information trying downweight element vector representation d2 time hope increase weight presidential vector d3 expect d2 overall score 3 d3 score 3 able rank d3 top d2 play video starting 845 follow transcript 845 systematically play video starting 848 follow transcript 848 rely statistical count case particular idea called inverse document frequency document frequency signal modern retrieval functions play video starting 95 follow transcript 905 discussed previous lecture specific way document frequency count documents contain particular term say inverse document frequency actually reward word doesnt occur documents play video starting 924 follow transcript 924 way incorporate vector representation modify frequency count multiplying idf corresponding word penalize common words generally lower idf reward rare words higher idf specifically idf defined logarithm m1 divided k m total number documents collection k df document frequency total number documents containing word w plot function varying k curve look general give higher value low df word rare word play video starting 1034 follow transcript 1034 maximum value function log m1 play video starting 1040 follow transcript 1040 interesting think whats minimum value function interesting exercise play video starting 1050 follow transcript 1050 specific function important heuristic simply penalize popular terms play video starting 111 follow transcript 1101 turns particular function form worked play video starting 117 follow transcript 1107 theres better form function open research question clear linear penalization whats line reasonable standard idf play video starting 1129 follow transcript 1129 particular difference standard idf play video starting 1135 follow transcript 1135 turning point play video starting 1141 follow transcript 1141 point going say terms essentially useful essentially ignored makes sense term occurs frequently lets say term occurs 50 documents term unlikely important basically common term play video starting 123 follow transcript 1203 important match word standard idf basically assumed low weights theres difference look linear penalization point difference intuitively wed focus discrimination low df words common words play video starting 1232 follow transcript 1232 course works better validated empirically correlated dataset users judge results better play video starting 1248 follow transcript 1248 lets solve problem 2 lets look two documents play video starting 1256 follow transcript 1256 idf weighting term frequency vectors idf weighting adjust tf weight multiplying idf value example adjustment particular theres adjustment idf value smaller idf value presidential look idf distinguish two words result adjustment larger make weight larger play video starting 1337 follow transcript 1337 score new vectors happen course share weights news campaign matching discriminate result idf weighting d3 ranked d2 matched rare word d2 matched common word shows idf weighting solve problem 2 play video starting 1412 follow transcript 1412 effective model general tfidf weighting lets look documents new scores new documents effective new weighting method new scoring function point play video starting 1433 follow transcript 1433 lets overall effective new ranking function tfidf weighting play video starting 1440 follow transcript 1440 show five documents scores play video starting 1447 follow transcript 1447 scores four documents reasonable expected play video starting 1458 follow transcript 1458 new problem d5 did high score simplest vector space model actually high score fact highest score play video starting 1516 follow transcript 1516 creates new problem actually common phenomenon designing retrieval functions basically try fix problem tend introduce problems thats tricky design effective ranking function whats best ranking function open research question researchers working play video starting 1542 follow transcript 1542 lectures going talk additional ideas improve model try fix problem play video starting 1555 follow transcript 1555 summarize lecture weve talked improve vector space model weve got improve instantiation vector space model based tdidf weighting improvement placement vector give high weight term occurred times document infrequently collection play video starting 1623 follow transcript 1623 improved model looks better simplest vector space model problems lecture going look address additional problems music
play video starting follow transcript 000 music play video starting 10 follow transcript 010 lecture continue discussion vector space model particular going talk tf transformation previous lecture derived tf idea weighting formula vector space model play video starting 27 follow transcript 027 assumed model actually works pretty examples slide d5 received high score received highest score documents document intuitive nonrelevant desirable play video starting 53 follow transcript 053 lecture going talk going tf transformation solve problem play video starting 1 follow transcript 100 discuss details lets take look formula simple tfidf weighting ranking function document received high score formula look formula carefully involves sum matched query terms play video starting 123 follow transcript 123 sum matched query term particular weight weight tfidf weighting play video starting 131 follow transcript 131 idea component two variables total number documents collection m document frequency number documents contained word w variables involved formula count query term play video starting 21 follow transcript 201 w query count word document play video starting 27 follow transcript 207 look document hard realize reason hasnt received high score high count campaign count campaign document 4 higher documents contributed high score document treating amount lower score document restrict contribution matching term document think matching terms document carefully actually realize probably shouldnt reward multiple occurrences generously mean occurrence term says lot matching term goes zero count count increase means lot play video starting 317 follow transcript 317 word document likely document talking word extra occurrence top occurrence two say second occurrence confirmed accidental managing word sure document talking word imagine lets say 50 times word document adding extra occurrence going test evidence sure document word play video starting 41 follow transcript 401 youre thinking way restrict contribution high count term idea tf transformation transformation function going turn real count word term frequency weight word document show x axis count y axis show term frequency weight play video starting 433 follow transcript 433 previous breaking functions actually imprison rate transformation example 01 bit vector recantation play video starting 444 follow transcript 444 actually transformation function basically count 0 0 weight weight 1 flat play video starting 459 follow transcript 459 term count tf weight thats linear function exactly weight count play video starting 511 follow transcript 511 desirable play video starting 518 follow transcript 518 example algorithm function cant sublinear transformation looks control influence high weight going lower inference retain inference small counts play video starting 536 follow transcript 536 bend curve applying logarithm twice play video starting 542 follow transcript 542 people tried methods working better linear form transformation play video starting 550 follow transcript 550 works best special transformation called bm25 transformation play video starting 558 follow transcript 558 bm stands best matching play video starting 61 follow transcript 601 transformation theres parameter k play video starting 66 follow transcript 606 k controls upper bound function easy function upper bound look x divided x k k nonactive number numerator able exceed denominator right upper bounded k1 difference transformation function logarithm transformation play video starting 637 follow transcript 637 doesnt upper bound play video starting 639 follow transcript 639 interesting property function vary k play video starting 645 follow transcript 645 actually simulate different transformation functions two extremes 01 bit transformation linear transformation example set k 0 play video starting 73 follow transcript 703 function value 1 precisely recover 01 bit transformation play video starting 715 follow transcript 715 set k large number hand going look linear transformation function play video starting 724 follow transcript 724 sense transformation flexible allows control shape transformation nice property upper bound play video starting 738 follow transcript 738 upper bound useful control inference particular term play video starting 743 follow transcript 743 prevent spammer increasing count term spam queries match term play video starting 757 follow transcript 757 words upper bound ensure terms counted aggregate weights compute score play video starting 86 follow transcript 806 transformation function worked play video starting 812 follow transcript 812 summarize lecture main point sublinear tf transformation needed capture intuition diminishing return higher term counts play video starting 826 follow transcript 826 avoid dominance single term bm25 transformation talked interesting bestperforming tf transformation formulas upper bound robust effective play video starting 847 follow transcript 847 plugging function tfidf weighting vector space model wed end having following ranking function bm25 tf component play video starting 91 follow transcript 901 close state odd ranking function called bm25 discuss improve formula lecture music
play video starting follow transcript 000 sound play video starting 8 follow transcript 008 lecture document length normalization vector space model lecture continue discussion vector space model particular going discuss issue document length normalization play video starting 25 follow transcript 025 lectures vector space model various signals document assess matching document query particular considered tone frequency count tone document considered global statistics idf inverse document frequency considered document lengths play video starting 54 follow transcript 054 show two example documents d4 shorter 100 words play video starting 11 follow transcript 101 d6 hand 5000 words look matching query words d6 matchings query words reason d6 matched query words scattered manner play video starting 124 follow transcript 124 topic d6 topic query play video starting 131 follow transcript 131 discussion campaign beginning document managing presidential end play video starting 140 follow transcript 140 general think long documents higher chance matching query fact generate long document randomly assembling words distribution words eventually probably match inquiry play video starting 2 follow transcript 200 sense penalize documents naturally better chance matching query idea document normalization play video starting 212 follow transcript 212 careful avoiding penalize long documents play video starting 219 follow transcript 219 hand penalize long document hand dont overpenalize reasoning document long different reasons play video starting 232 follow transcript 232 case document long uses words play video starting 238 follow transcript 238 example think vortex article research paper words corresponding abstract play video starting 249 follow transcript 249 case probably penalize matching play video starting 254 follow transcript 254 long documents full paper compare matching words long document matching words shop abstract play video starting 37 follow transcript 307 long papers general higher chance matching clearer words penalize case document long document simply content consider case long document simply concatenate lot abstracts different papers case obviously dont overpenalize long document probably dont penalize document long play video starting 339 follow transcript 339 thats careful right degree penalization play video starting 348 follow transcript 348 method working based recent results called pivoted length normalization case idea average document length pivot reference point means assume average length documents score right normalizer 1 document longer average document length play video starting 414 follow transcript 414 penalization shorter reward illustrated slide axis xaxis length document yaxis show normalizer case pivoted length normalization formula normalizer interpolation 1 normalize document length controlled parameter b play video starting 453 follow transcript 453 divide length document average documents gives sense document compared average documents gives benefit worrying unit length measure length words characters play video starting 520 follow transcript 520 normalizer interesting property set parameter b 0 value 1 theres lens normalization b sense controls lens normalization play video starting 539 follow transcript 539 set b nonzero value normalizer look right value higher documents longer average document lens play video starting 553 follow transcript 553 value normalizer shorter smaller shorter documents sense penalization long documents theres reward short documents play video starting 69 follow transcript 609 degree penalization controlled b set b larger value normalizer look theres penalization long documents reward short documents adjusting b varies 0 1 control degree length normalization plug length normalization fact vector space model ranking functions examined play video starting 641 follow transcript 641 end having following formulas play video starting 646 follow transcript 646 fact state vector space model formulas lets take look called pivoted length normalization vector space model reference inaudible duration model basically tfi model discussed idea component familiar play video starting 718 follow transcript 718 query term frequency component play video starting 724 follow transcript 724 middle normalizer tf case logarithm discussed achieve sublinear transformation put document length normalizer bottom right cause penalization long document larger denominator smaller course controlled parameter b play video starting 81 follow transcript 801 b set 0 length normalization play video starting 88 follow transcript 808 okay two effective base model formulas called bm25 okapi similar idf component query idf component play video starting 832 follow transcript 832 middle normal issues bit different explained copy tf transformation sublinear transformation upper bound play video starting 848 follow transcript 848 case put length normalization factor adjusting k achieves similar factor put normalizer denominator document longer term weight smaller play video starting 910 follow transcript 910 gone n answers talked end reached basically state god functions talked mainly place document vector vector space play video starting 935 follow transcript 935 played important role determining effectiveness simple function dimensions did examine details example improve instantiation dimension vector space model weve assumed bag words representation issue dimension word obviously choices example stemmed word words havent transformed root form computation computing match stop word removal remove common words dont carry content play video starting 1026 follow transcript 1026 phrases define dimensions later semantical analysis find clusters words represent late concept engine play video starting 1039 follow transcript 1039 smaller unit character end grams sequences characters dimensions play video starting 1050 follow transcript 1050 practice people found bagofwords representation phrases effective efficient popular dimension instantiation method play video starting 1110 follow transcript 1110 major search engines play video starting 1113 follow transcript 1113 mention language specific domain specific tokenization actually important variations terms prevent matching mean thing languages chinese challenge segmenting play video starting 1140 follow transcript 1140 text obtain word band rates sequence characters word correspond character two characters three characters easier english space separate words languages americanize processing figure way boundaries words possibility improve similarity function top product imagine measures example measure cosine angle two vectors euclidean distance measure play video starting 1224 follow transcript 1224 possible dot product best reason general play video starting 1233 follow transcript 1233 fact sufficiently general consider possibilities waiting different ways play video starting 1244 follow transcript 1244 example cosine measure thought thought product two normalized factors means normalize factor take thought product critical cosine measure mentioned bm25 effective formulas play video starting 134 follow transcript 1304 developments improving bm25 words changed bm25 fundamental line work people divide bm25 f f stands field bm25 documents structures example consider title field abstract body research article anchor text web page text fields describe links pages combined proper way different fields help improve scoring different documents bm25 document obvious choice apply bm25 field combine scores basically idea bm25f combine frequency counts terms fields apply bm25 advantage avoiding counting occurrence term remember sublinear transformation tf occurrence important contributes large weight fields term gained lot advantage field combine word frequencies transformation time time extra occurrences counted fresh recurrences play video starting 1448 follow transcript 1448 method working scoring structure documents play video starting 1455 follow transcript 1455 line extension called bm25 line risk address problem penalization long documents bm25 play video starting 158 follow transcript 1508 address problem fix actually simple simply add small constant tf normalization formula whats interesting analytically prove small modification fix problem penalization law documents original bm25 new formula called bm25 empirically analytically better bm25 play video starting 1542 follow transcript 1542 summarize vector space model major take away points model similarity relevance assuming relevance document respect query play video starting 162 follow transcript 1602 basically proportional similarity query document naturally implies query document represented way case present vectors highdimensional vector space dimensions defined words concepts terms general play video starting 1625 follow transcript 1625 generally lot heuristics design ranking function examples show needs heuristics tf weighting transformation play video starting 1638 follow transcript 1638 idf weighting document length normalization major heuristics important heuristics ensure general ranking function work kinds test finally bm25 pivoted normalization effective formulas vector space model say put bm25 category vector space model fact bm25 derived probabilistic model play video starting 1711 follow transcript 1711 reason ive put vector space model ranking function actually nice interpretation vector space model easily looks vector space model special waiting function play video starting 1728 follow transcript 1728 second reason original bm25 different form idf play video starting 1736 follow transcript 1736 form idf inaudible doesnt work standard idf effective retrieval function bm25 probably heuristic modification idf make look vector space model play video starting 1759 follow transcript 1759 additional readings paper pivoted length normalization excellent example empirical data analysis suggest length normalization derive length normalization formula second original paper bm25 proposed play video starting 1824 follow transcript 1824 third paper thorough discussion bm25 extensions particularly bm25 f play video starting 1832 follow transcript 1832 finally paper discussion improving bm25 correct penalization long documents music
play video starting follow transcript 000 music lecture implementation text retrieval systems play video starting 12 follow transcript 012 lecture discuss implement text retrieval method build search engine main challenge manage lot text data enable query answered quickly respond queries typical text retrieval system architecture documents processed tokenizer tokenized units example words words tokens processed indexer create index data structure search engine quickly answer query query going similar processing step tokenizer apprised query text processed way units matched querys representation given scorer index quickly answer users query scoring documents ranking results given user user look results provided feedback explicit judgements documents good documents bad implicit feedback user didnt extra end user look results skip click result view interacting signals system improve ranking accuracy assuming viewed documents better skipped ones search engine system divided three parts part indexer second part scorer responds users query third part feedback mechanism typically indexer done offline manner preprocess correct data build inventory index introduce moment data structure online module scorer process users query dynamically quickly generate search results feedback mechanism done online offline depending method implementation indexer scorer standard main topic lecture lectures feedback mechanism hand variations depends method usually done algorithms specific way lets talk tokenizer tokernization normalized lexical units form semantically similar words matched language english stemming map inflectional forms words root form example computer computation computing matched root form compute way different forms computing matched normally good idea increase coverage documents matched query beneficial subtlest difference computer computation suggest difference coverage content cases stemming beneficial tokenize text languages example chinese face special challenges segmenting text find word boundaries obvious boundary theres space separate course language specific processing techniques tokenization index text documents itll convert documents data structure enable faster search basic idea precompute basically commonly index call inverted index search engines support basic search algorithms indices example document index needed order support feedback techniques standard vary lot feedback methods understand inverted index useful think respond single term query quickly time think pause video think pre process text data quickly respond query word thought question realize best simply create list documents match term vocabulary way basically preconstruct answers term simply fetch random list documents term return list user thats fastest way respond single term idea invert index actually basically going preconstructed search index allows quickly find documents match particular term lets take look example three documents documents previous lectures suppose create inverted index documents maintain dictionary dictionary entry term going store basic statistics term example number documents match term total number code frequency term means duplicate occurrences term example news term occur three documents count documents three realize needed count documents document frequency computing statistics vector space model think weighting heuristic count thats idea right inverse document frequency idf property term compute right document count easy compute idea time old index random time query addition basic statistics store documents matched news entries stored file called postings play video starting 824 follow transcript 824 case matched three documents store information three documents document id document 1 frequency 1 tf news second document 1 cetera list documents match term news know frequency news documents query word news easily look table find entry quicker postings fetch documents matching lets take look term play video starting 99 follow transcript 909 time lets take look word presidential play video starting 914 follow transcript 914 occur document document 3 document frequency 1 occurred twice document frequency count two frequency count reachable method frequency play video starting 934 follow transcript 934 assess popularity term collection similarly pointer postings case entry play video starting 948 follow transcript 948 term occurred document thats document id 3 occurred twice play video starting 959 follow transcript 959 basic idea inverted index actually pretty simple right play video starting 106 follow transcript 1006 structure easily fetch documents match term basis scoring documents query store positions terms play video starting 1025 follow transcript 1025 cases term occurred document theres position example case play video starting 1035 follow transcript 1035 case term occurred twice theres two positions position information useful checking matching query terms actually small window lets say five words ten words play video starting 1052 follow transcript 1052 matching two query terms fact phrase two words checked quickly position play video starting 115 follow transcript 1105 inverted index good fast search talked possibility two answer singleterm query thats easy multiple term queries lets look special cases boolean query boolean query basically boolean expression value document match term term b thats conjunctive query web documents match term term b thats disjunctive query answer query inverted index play video starting 1152 follow transcript 1152 think bit obvious simply fetch documents match term fetch documents match term b take intersection answer query b take union answer query b easy answer going quick multiterm keyword query talked vector space model example match query document generate score score based aggregated term weights case boolean query scoring actually done similar way basically similar disjunctive boolean query basically b take union documents match least query term aggregate term weights basic idea inverted index scoring documents general going talk detail later lets look question index good idea basically efficient sequentially scanning documents obvious approach compute score document sort straightforward method going slow imagine wealth theres lot documents take long time answer query question invert index faster word distribution text heres common phenomena word distribution text languages independent patterns stable play video starting 14 follow transcript 1400 patterns basically characterized following pattern words common words occur frequently text account large percent occurrences words play video starting 1419 follow transcript 1419 words occur rarely words occur lets say document collection true frequent words corpus rare means general phenomenon applicable observed cases exact words common vary context context phenomena characterized whats called zipfs law law says rank word multiplied frequency word roughly constant play video starting 157 follow transcript 1507 formally fw denote frequency rw denote rank word formula basically says thing mathematical term c basically constant parameter alpha adjusted better fit empirical observations plot word frequencies sorted order easily x axis basically word rank rw y axis word frequency fw curve shows product two roughly constant look words separated three groups middle intermediary frequency words words tend occur documents frequent words rare play video starting 1618 follow transcript 1618 tend play video starting 1622 follow transcript 1622 queries tend high tfidf weights intermediate frequency words look left part curve play video starting 1635 follow transcript 1635 highest frequency words covered frequently usually words words frequent fact two frequent discriminated generally useful retrieval removed called stop words removal pretty words collection infer words stop words basically highest frequency words play video starting 1713 follow transcript 1713 occupy lot space inverted index imagine posting entries word long remove words lot space inverted index play video starting 1729 follow transcript 1729 show tail part lot rare words words dont occur frequently words play video starting 1739 follow transcript 1739 words actually useful search user happens interested topic theyre rare true users arent necessarily interested words retain allow match document accurately generally high idf play video starting 185 follow transcript 1805 data structures store inverted index two parts right recall dictionary postings dictionary modest size web going large compare postings distinct play video starting 1826 follow transcript 1826 fast random access entries going look query term quickly wed prefer keep dictionary memory possible collection large feasible collection large general possible vocabulary size large obviously cant general thats goes data structures storing dictionary direct access structures hash table btree cant store memory disk try build structure allow quickly look entries play video starting 1914 follow transcript 1914 postings huge play video starting 1918 follow transcript 1918 general dont direct access specific entry generally look sequence document ids frequencies documents matches query term play video starting 1933 follow transcript 1933 read entries sequentially play video starting 1937 follow transcript 1937 large generally store postings disc stay disc contain information document ids term frequency term positions etcetera large compression desirable play video starting 1959 follow transcript 1959 disc space course benefit compression going occupy space help improving speed play video starting 2013 follow transcript 2013 know input output cost lot time comparison time taken cpu cpu faster io takes time compressing inverter index opposing files smaller entries readings memory process query term smaller reduce amount tracking io lot time course processing data uncompress data memory cpu fast time play video starting 218 follow transcript 2108 compression disc space speed loading index music
play video starting follow transcript 000 sound play video starting 7 follow transcript 007 lecture inverted index construction play video starting 13 follow transcript 013 lecture continue discussion system implementation particular going discuss construct inverted index play video starting 25 follow transcript 025 construction inverted index actually easy dataset small easy construct dictionary store postings file play video starting 36 follow transcript 036 problem data able fit memory special method deal play video starting 46 follow transcript 046 unfortunately retrieval applications dataset large generally loaded memory play video starting 56 follow transcript 056 approaches solve problem sortingbased method common works four steps collect local termid documentid frequency tuples basically locate terms small set documents collect accounts sort count based terms able local partial inverted index called rounds write temporary file disk merge step 3 pairwise merging runs eventually merge runs generate single inverted index play video starting 147 follow transcript 147 illustration method left documents right term lexicon document id lexicon lexicons map stringbased representations document ids terms integer representations map back integers stream representation reason interest integers present ids integers easier handle example integers index array easy compress play video starting 234 follow transcript 234 reason tend map strings integers play video starting 242 follow transcript 242 dont carry strings approach work simple going scan documents sequentially parse documents count frequencies terms stage generally sort frequencies document ids process document sequentially encounter terms document document ids ones case followed document ids two natural results process data sequential order point run memory write disc re going sort memory sort time going sort based term ids note term ids key sort entries share term grouped case ids documents match term 1 grouped going write temporary file allows memory process makes batch documents going documents going write lot temporary files disc stage merge sort basically going merge sort eventually single inverted index entries sorted based term ids play video starting 446 follow transcript 446 top going older entries documents match term id 1 basically construction inverted index data loaded manner mention earlier hostings large desirable compress lets take bit compressed inverted index idea compression general leverage skewed distributions values generally variablelength encoding fixedlength encoding default program manager c leverage skewed distributions values compress values general bits encode frequent words cost longer bit string code rare values case lets think compress tf tone frequency play video starting 65 follow transcript 605 picture inverted index look post things lot tone frequencies frequencies terms documents think values frequent probably able guess small numbers tend occur frequently large numbers think distribution words sip slopes words occur rarely lot small numbers fewer bits small highly frequent integers thats cost bits larger integers play video starting 658 follow transcript 658 trade course values distributed uniform wont space tend small values frequent average large number lot bits play video starting 719 follow transcript 719 document ids postings distributed skewed way deal turns trick called dgap store difference term ids imagine term matched documents longest document ids take gap take difference adjacent document ids gaps small lot small numbers term occurred documents gap large large numbers frequent creates skewed distribution allow compress values play video starting 811 follow transcript 811 possible order uncover uncompress document ids sequentially process data stored difference order recover exact document id recover previous document id add difference previous document id restore current document id possible needed sequential access document ids look term look document ids match term sequentially process natural thats trick actually works play video starting 853 follow transcript 853 different methods encoding binary code commonly code program language basically fixed glance coding unary code gamma code delta code possibilities possibilities lets look detail binary coding equal length coding thats property randomly distributed values unary coding variable length coding method case integer 1 encoded x 1 1 bit followed 0 example 3 encoded 2 1s followed 0 5 encoded 4 1s followed 0 imagine bits large number 100 bits exactly number 100 exactly 100 bits number bits value number inefficient likely large numbers imagine occasionally number 1000 1000 bits works absolutely sure large numbers small numbers decode code variable length encoding methods cant count bits stop play video starting 1038 follow transcript 1038 cant say 8bits 32bits start code variable length rely mechanism case unary easy boundary easily 0 signal end encoding count 1s end hit 0 finished number start number play video starting 117 follow transcript 1107 unary coding aggressive rewarding small numbers occasionally big number disaster aggressive method gamma codings method unary coding transform form 1 plus floor log x magnitude value lower original x thats afford unary code unary code coding log x followed uniform code binary code basically uniform code binary code going coder code remaining part value x basically precisely x1 floor log x play video starting 1225 follow transcript 1225 unary code basically called flow log x add remaining part uniform code actually code difference x 2 log x play video starting 1249 follow transcript 1249 easy show play video starting 1255 follow transcript 1255 difference bits floor log x bits play video starting 136 follow transcript 1306 easy understand difference large higher floor log x play video starting 1314 follow transcript 1314 examples example 3 encoded 101 two digits unary code isnt value 2 10 encodes 2 unary coding play video starting 1332 follow transcript 1332 means floor log x 1 wont actually unary codes code 1 plus flow log x two know flow log x actually 1 play video starting 1352 follow transcript 1352 3 larger 2 1 difference 1 1 encoded end play video starting 141 follow transcript 1401 thats 101 3 similarly 5 encoded 110 followed 01 play video starting 1412 follow transcript 1412 case unary code code 3 unary code 110 flow log x 2 means going compute difference 5 2 2 thats 1 1 end time going 2 bits level flow log x numbers 5 6 7 share prefix 110 order differentiate 2 bits end differentiate imagine 6 10 end 01 10 play video starting 154 follow transcript 1504 true form gamma code odd number bits center 0 thats end unary code play video starting 1518 follow transcript 1518 left side 0 1s right side 0 binary coding uniform coding play video starting 1532 follow transcript 1532 decode code unary coding hit 0 got unary code tell bits read decode uniform code decode gamma code delta code thats basically gamma code replace unary prefix gamma code thats conservative gamma code terms wording small integers means okay occasionally large number play video starting 1614 follow transcript 1614 okay delta code play video starting 1616 follow transcript 1616 fine gamma code big loss unary code operating course different degrees favoring short favoring small integers means appropriate sorting distribution perfect distributions method works best depend actual distribution dataset inverted index compression people found gamma coding work play video starting 1655 follow transcript 1655 uncompress inverted index talk firstly decode encoded integers think discussed decode unary coding gamma coding document ids compressed dgap going sequential decoding supposed encoded list x1 x2 x3 decode x1 obtain document id id1 decode x2 actually difference second id add decoder value x2 id1 recover value id secondary position play video starting 1746 follow transcript 1746 advantages converting document ids integers allows compression repeat decode documents time document id previous position help recover document id position play video starting 188 follow transcript 1808 music
play video starting follow transcript 000 sound lecture faster search invert index play video starting 14 follow transcript 014 lecture going continue discussion system implementation particular going talk support faster search invert index play video starting 26 follow transcript 026 lets think general scoring function look play video starting 32 follow transcript 032 course vector space model special case imagine retrieval functions form play video starting 42 follow transcript 042 form function follows play video starting 46 follow transcript 046 scoring function document d query q defined function fa adjustment function consider two factors ill assume end f sub d d f sub q q adjustment factors document query level document query function theres function called h main part scoring function scoring factors level document query example document inaudible aggregate punching combine h function functions compute weights contribution matched query term ti play video starting 28 follow transcript 208 g function g gives weight matched query term ti document d play video starting 223 follow transcript 223 h function aggregate weights example take sum matched query terms play video starting 236 follow transcript 236 product way aggregating play video starting 241 follow transcript 241 finally adjustment functioning consider document level query level factors adjust score example document inaudible general form cover state inaudible functions lets look score documents function virtual index play video starting 37 follow transcript 307 heres general algorithm works follows query level document level factors precomputed indexing time course query compute query time document example document inaudible precomputed maintain score accumulator document d computer h play video starting 334 follow transcript 334 h aggregation function matching query terms period term going fetch inverted list invert index give documents match query term play video starting 352 follow transcript 352 includes d1 f1 dn fn pair document id frequency term document entry d sub j f sub j particular match term particular document d sub j going compute function g give weight term computing weight completion matching query term document going update score accumulator document allow add accumulator incrementally compute function h basically general way allow pseudo computer functions form inbound index note dont attach document didnt match query term fast process documents matched least query term end going adjust score computer function f sub sort lets take look specific example case lets assume scoring function simple takes sum t f role t f count term document play video starting 525 follow transcript 525 simplification help shield algorithm clearly easy extend computation weights transformation tf inaudible idf inaudible lets take look specific example queries information security play video starting 548 follow transcript 548 show entries invert index right side information occurred four documents frequencies security occurred three documents lets arrows works iterate overall query terms fetch query thats information right imagine score accumulators score play video starting 617 follow transcript 617 scores documents imagine allocated needed waiting terms dont score comes actually score accumulators eventually allocating play video starting 638 follow transcript 638 lets fetch interest entity inaudible information play video starting 646 follow transcript 646 four accumulators obviously initialize zeros play video starting 651 follow transcript 651 entry d1 3 3 occurrences information document scoring function assume score sum raw counts add 3 score accumulator account increase score due matching term information document d1 entry thats d2 4 add 4 score accumulator d2 course point allocate score accumulator needed point allocated d1 d2 d3 add allocate score inaudible d3 add finally d4 gets 5 term information occurred five times document okay completes processing entries invert index information processed contributions matching information four documents play video starting 81 follow transcript 801 error thats security going fetch inverted index entries security play video starting 810 follow transcript 810 case three entries going d2 3 means security occur three humps d2 exactly did information time going change score inaudible d2 allocated add 3 existing value 4 7 d2 play video starting 841 follow transcript 841 d2 score increased match falls information security entry thats d4 1 score d4 add 1 d4 d4 goes 5 6 finally process d5 3 allocated score accumulated d5 point going allocate 1 d5 going add 3 scores rule final scores documents play video starting 920 follow transcript 920 scoring function simple tf values play video starting 927 follow transcript 927 actually form addition going inaudible point document play video starting 936 follow transcript 936 summarize right process information determine query term information processed entries index term process security right think order processing query terms make difference especially dont keep score accumulators lets say keep promising score accumulators think good order process common term process rare term play video starting 1024 follow transcript 1024 answers process rare term rare term match documents score contribution higher ideal value higher allows attach diplomacy documents helps pruning nonpromising ones dont documents returned user heuristics improving accuracy incorporate idea waiting right inaudible incorporate inaudible process query time fetch inverted index fetch document frequency compute idf idf value precomputed indexed documents time computed idf value fetch done time mean process entries information words adjusted idf idf information play video starting 1136 follow transcript 1136 basic idea inverted index fast research works kinds formulas general form generally general form covers actually state art retrieval functions tricks improve efficiency general techniques encode caching store results popular queries time query simply return stored results similarly slow list inverted index memory popular term query term popular likely soon factor inverted index term keeping memory help general techniques improving efficiency keep promising accumulators user generally doesnt examine documents return high qualities subset documents likely ranked top play video starting 1247 follow transcript 1247 purpose prune accumulators dont store accumulators point keep highest value accumulators technique parallel processing thats needed process large data set web data set scale webscale special techniques parallel processing distribute storage files machines list text retrieval toolkits complete list find information url bottom listed four lucenes popular toolkits support lot applications nice support applications build search engine application quickly downside easy extend algorithms implemented advanced algorithms lemur indri toolkit nice support web application lucene advanced search algorithms easy extend terrier toolkit good support application capability advanced algorithms thats lemur lucene combining strands thats useful tool kit meta toolkit problem assignment new toolkit play video starting 1447 follow transcript 1447 combination text retrieval algorithms text mining algorithms talking models implement number text analysis algorithms implemented toolkit basic search algorithms summarize discussion system implementation play video starting 1511 follow transcript 1511 major takeaway points inverted index primary data structure supporting search engine thats key enable faster response users query play video starting 1526 follow transcript 1526 basic idea preprocess data compression appropriate disk space speed io processing inverted index general talked construct invert index data cant fit memory talk faster search index basically whats exploit invective index accumulate scores documents inaudible algorithm exploit zipfs law avoid touching documents dont match query term algorithm actually support wide range ranking algorithms play video starting 1613 follow transcript 1613 basic techniques great potential scaling distributed file system parallel processing caching two additional readings take look time interested learning classical textbook efficiency o inverted index compression techniques general feel efficient inputs space overhead speed second newer textbook nice discussion implementing evaluating search engines play video starting 1658 follow transcript 1658 music
3 overview weeks lessons learn evaluate information retrieval system search engine basic measures evaluating set retrieved results major measures evaluating ranked list average precision ap normalized discounted cumulative gain ndcg practical issues evaluation statistical significance testing pooling time module take approximately 7 hours dedicated time complete videos assignments activities activities module listed assignments bold activity estimated time required 3 video lectures 2 hours 3 graded quiz 1 hour programming assignment 21 4 hours goals objectives actively engage learning experiences module able explain cranfield evaluation methodology works evaluating text retrieval system explain evaluate set retrieved documents compute precision recall f1 explain evaluate ranked list documents explain compute plot precisionrecall curve explain compute average precision mean average precision map explain evaluate ranked list multilevel relevance judgments explain compute normalized discounted cumulative gain explain important perform statistical significance tests guiding questions develop answers following guiding questions completing readings working assignments evaluation critical research application development text retrieval cranfield evaluation methodology work evaluate set retrieved documents compute precision recall f1 evaluate ranked list search results compute average precision compute mean average precision map geometric mean average precision gmap mean reciprocal rank map appropriate precision k documents comparing two retrieval methods precision k documents meaningful average precision user’s perspective evaluate ranked list search results multilevel relevance judgments compute normalized discounted cumulative gain ndcg normalization necessary ndcg map similar normalization important perform statistical significance tests compare retrieval accuracies two search engine systems additional readings resources mark sanderson test collection based evaluation information retrieval systems foundations trends information retrieval 4 4 2010 247375 c zhai s massung text data management analysis practical introduction information retrieval text mining acm book series morgan claypool publishers 2016 chapter 9 key phrases concepts keep eyes open following key terms phrases complete readings interact lectures topics help better understand content module cranfield evaluation methodology precision recall average precision mean average precision map geometric mean average precision gmap reciprocal rank mean reciprocal rank fmeasure normalized discounted cumulative gain ndcg statistical significance test tips success recommend following review video lectures number times gain solid understanding key questions concepts introduced possible tips suggestions peers class learning community help learn grow way helping address questions peers pose engaging we’ll learn better it’s good idea refer video lectures chapter readings weve read reference responses appropriate critique information presented take notes read materials watch lectures taking notes interacting material find easier remember understand notes you’ll find it’s easier complete assignments ahead favor take notes getting giving help getgive help following means learner help center opens new tab find information regarding specific technical problems example technical problems error messages difficulty submitting assignments problems video playback find answer documentation report problem coursera staff clicking contact link available topics page learner help center content issues opens new tab forum report errors lecture video content assignment questions answers assignment grading text links course pages content course materials university illinois staff community tas monitor forum respond issues mark completed item completed dislike report issue
play video starting follow transcript 000 music play video starting 7 follow transcript 007 lecture evaluation text retrieval systems previous lectures talked number text retrieval methods different kinds ranking functions play video starting 23 follow transcript 023 know works best order answer question compare means evaluate retrieval methods play video starting 34 follow transcript 034 main topic lecture play video starting 40 follow transcript 040 lets think evaluation give reason evaluation figure retrieval method works better important advancing knowledge wouldnt know new idea works better old idea beginning course talked problem text retrieval compare data base retrieval play video starting 18 follow transcript 108 mentioned text retrieval empirically defined problem evaluation rely users system works better judged users play video starting 125 follow transcript 125 challenging problem users involved evaluation fair comparison different method play video starting 137 follow transcript 137 back reasons evaluation play video starting 141 follow transcript 141 listed two reasons second reason basically reason assess actual utility text regional system imagine youre building annual applications interesting knowing search engine works users case matches reflect utility actual users real occasion typically done user starters real search engine play video starting 216 follow transcript 216 second case second reason play video starting 219 follow transcript 219 measures actually collated utility actually dont accurately reflect exact utility users play video starting 231 follow transcript 231 measure needs good tell method works better play video starting 238 follow transcript 238 usually done test collection main idea talking course important comparing different algorithms improving search engine system general play video starting 258 follow transcript 258 lets talk measure aspects searching measure evaluate listed three major aspects effectiveness accuracy accurate search results case measuring systems capability ranking relevant documents top non relevant ones second efficiency quickly results computing resources needed answer query case measure space time overhead system play video starting 332 follow transcript 332 third aspect usability basically question useful system new user tasks obviously interfaces things important typically user studies play video starting 347 follow transcript 347 course going talk effectiveness accuracy measures efficiency usability dimensions unique search engines needed software systems good coverage causes evaluate search engines quality accuracy unique text retrieval going talk lot main idea people proposed test set evaluate text retrieval algorithm called cranfield evaluation methodology actually developed long time ago developed 1960s methodology laboratory test system components play video starting 445 follow transcript 445 sampling methodology useful search engine evaluation evaluating virtually kinds empirical tasks example natural language processing fields problem empirical find typically methodology today big data challenging machine learning methodology popular developed search engine application 1960s basic idea approach build reusable test collection define measures play video starting 527 follow transcript 527 test collection built test different algorithms going define measures allow quantify performance system algorithm play video starting 541 follow transcript 541 exactly work sample collection documents adjusted simulate real document collection search application going sample set queries topics simulator uses queries play video starting 556 follow transcript 556 relevance judgments judgments documents returned queries ideally made users formulated queries people know exactly documents finally matches quantify systems result matches ideal ranked list constructed base users relevance judgements methodology useful starting retrieval algorithms test reused times fair comparison methods criteria dataset compare different algorithms allows compare new algorithm old algorithm divided years ago standard illustration works queries showing q1 q2 documents thats called document caching right side relevance judgments basically binary judgments documents respect query example d1 judged relevant q1 d2 judged relevant d3 judged relevant q1 created users play video starting 734 follow transcript 734 basically test collection two systems compare run system queries documents system return results lets say queries q1 results show r sub results system remember talked task computing approximation relevant document set r sub system approximation play video starting 814 follow transcript 814 r sub b system bs approximation relevant documents play video starting 821 follow transcript 821 lets take look results better imagine user lets take look results differences documents returned systems look results feel better sense dont number element documents three documents returned two relevant thats good precise hand council say b better weve got documents weve got three two better quantify play video starting 98 follow transcript 908 obviously question highly depends users task depends users imagine users system better user interested getting random documents right case user doesnt read million users relevant documents hand imagine user random documents possible example youre literature survey sigma category find system b better case define measures quantify define multiple measures users different perspectives looking results play video starting 958 follow transcript 958 music
play video starting follow transcript 000 sound lecture basic measures evaluation text retrieval systems lecture going discuss design basic measures quantitatively compare two retrieval systems slide earlier lecture talked granville evaluation methodology test faction consists queries documents inaudible run two systems data sets contradict evaluator performance raise question set results better system better system b better lets talk accurately quantify performance suppose total 10 relevant documents collection query relevant judgments show right inaudible obviously 3 inaudible inaudible documents imagine random documents judging query intuitively thought system better did noise particular three results two relevant system b five results three relevant intuitively looks system accurate infusion captured matching holder position simply compute extent retrieval results relevant 100 position mean retrieval documents relevant case system position two three system b sweet hold 5 shows system better frequency talked system b prefered units retrieve random documents possible case compare number relevant documents retrieve theres method called recall method uses completeness coverage random documents retrieval result assume ten relevant documents collection weve got two system recall 2 10 system b called 3 3 10 recall system b better two measures turn basic measures evaluating search engine important widely test evaluation problems example look applications machine learning tend precision recall numbers reported kinds tasks play video starting 335 follow transcript 335 okay lets define two measures precisely measures evaluate set retrieved documents means considering approximation set relevant documents play video starting 350 follow transcript 350 distinguish 4 cases depending situation documents document retrieved retrieved right talking set results play video starting 42 follow transcript 402 document relevant relevant depending user thinks useful document play video starting 411 follow transcript 411 counts documents four categories represent number documents retrieved relevant b documents retrieved play video starting 431 follow transcript 431 table define precision play video starting 436 follow transcript 436 ratio relevant retrieved documents total relevant retrieved documents play video starting 448 follow transcript 448 divided sum c sum column play video starting 456 follow transcript 456 singularly recall defined dividing sum b thats divide sum row column right precision recall focused looking play video starting 516 follow transcript 516 thats number retrieved relevant documents going different denominators play video starting 523 follow transcript 523 okay ideal result easily ideal case precision recall oil 10 means got 1 relevant documents results results returned relevant least theres single relevant document returned play video starting 548 follow transcript 548 reality high recall tends associated low precision imagine thats case try random documents possible tend encounter lot documents precision note set defined cut rest thats two measures defined retrieve documents actually useful evaluating rank list fundamental measures task retrieval tasks interested precision ten documents web search means look documents top ten results actually relevant meaningful measure tells relevant documents user expect page typically show ten results play video starting 650 follow transcript 650 precision recall basic matches evaluate search engine building blocks play video starting 73 follow transcript 703 tends trailoff precision recall naturally interesting combine heres method thats called fmeasure inaudible mean precision recall defined slide play video starting 722 follow transcript 722 compute play video starting 729 follow transcript 729 inverse r p interpret 2 coefficients depending parameter beta play video starting 742 follow transcript 742 transformation easily form play video starting 749 follow transcript 749 case agent precision recall beta parameter thats set 1 control emphasis precision recall set beta 1 end having special case fmeasure called f1 popular measure thats combined precision recall formula looks simple play video starting 816 follow transcript 816 play video starting 820 follow transcript 820 easy larger precision larger recall f measure high whats interesting trade precision recall captured interesting way f1 order understand play video starting 842 follow transcript 842 look natural combining symbol arithmetically efficient likely natural way combining think play video starting 91 follow transcript 901 think pause video play video starting 97 follow transcript 907 good f1 play video starting 913 follow transcript 913 whats problem play video starting 918 follow transcript 918 think arithmetic mean sum multiple terms case sum precision recall case sum total value tends dominated large values means high p high r dont care value low sum high desirable easily perfect recall perfect recall easily imagine play video starting 959 follow transcript 959 probably easy imagine simply retrieve documents collection perfect recall play video starting 107 follow transcript 1007 give 05 average results clearly useful users average formula relevantly high play video starting 1021 follow transcript 1021 contrast f 1 reward case precision recall roughly seminar case extremely high value play video starting 1035 follow transcript 1035 means f encodes different trade example shows actually important methodology try solve problem naturally think solution lets say error mechanism play video starting 1053 follow transcript 1053 important settle source important think ways combine play video starting 112 follow transcript 1102 think multiple variance important analyze difference think makes sense case think carefully think f1 probably makes sense simple cases different results case reasonable dont pay attention subtle differences take easy way combine ahead later find measure doesnt work right methodology actually important general solving problems try think best solution try understand problem know needed measure combine precision recall guide finding good way solve problem play video starting 123 follow transcript 1203 summarize talked precision addresses question retrievable results relevant talk recall addresses question relevant documents retrieved two two basic matches text retrieval tasks talk f measure way combine precision precision recall play video starting 1229 follow transcript 1229 talked tradeoff precision recall turns depend users search tasks discuss point later lecture music
play video starting follow transcript 000 music play video starting 7 follow transcript 007 lecture evaluate ranked list play video starting 13 follow transcript 013 lecture continue discussion evaluation particular going look evaluate ranked list results play video starting 24 follow transcript 024 previous lecture talked precisionrecall two basic measures quantitatively measuring performance search result play video starting 40 follow transcript 040 talked ranking framed text retrieval problem ranking problem play video starting 50 follow transcript 050 evaluate quality ranked list play video starting 56 follow transcript 056 precisionrecall evaluate ranked list naturally look precisionrecall different cutoffs end approximation relevant documents set given ranked list determined user stops browsing right assume user securely browses list results user stop point point determine set thats important cutoff consider compute precisionrecall knowing exactly user stop consider positions user stop lets look positions look slide lets look user stops document whats precisionrecall point think play video starting 156 follow transcript 156 easy document precision got document thats relevent recall note assuming ten relevant documents query collection ten play video starting 216 follow transcript 216 user stops second position play video starting 219 follow transcript 219 top two play video starting 221 follow transcript 221 precision 100 two two record two ten play video starting 228 follow transcript 228 user stops third position interesting case got additional relevant document record change play video starting 241 follow transcript 241 precision lower weve got number inaudible whats exactly precision play video starting 249 follow transcript 249 two three right recall two ten point recall different look list wont happen relevant document case d5 point recall increased three ten precision three five play video starting 315 follow transcript 315 keep d8 precision four eight eight documents four relevant recall four ten play video starting 329 follow transcript 329 recall five ten list dont list dont know convenience assume precision zero play video starting 347 follow transcript 347 othe precision zero levels recall search results course pessimistic assumption actual position higher make make assumption play video starting 45 follow transcript 405 order easy way compute measure called average precision discuss later play video starting 414 follow transcript 414 say make assumptions clearly accurate play video starting 422 follow transcript 422 okay purpose comparing text methods relative comparison okay actual measure actual actual number deviates bit true number long deviation biased particular retrieval method okay accurately tell method works better important point keep mind compare different algorithms keys avoid bias method long avoid okay transformation measures preserve order play video starting 59 follow transcript 509 okay talk lot precisionrecall numbers different positions imagine plot curve shows xaxis show recalls play video starting 523 follow transcript 523 yaxis show precision precision line marked 1 2 3 10 right different levels recall yaxis different amounts thats precision play video starting 545 follow transcript 545 plot precisionrecall numbers got points picture link points form curve youll assumed precision highlevel recalls zero thats zero actual curve probably discussed doesnt matter comparing two methods play video starting 620 follow transcript 620 underestimated method play video starting 625 follow transcript 625 okay precisionrecall curve compare ranked back list right means compare two pr curves play video starting 638 follow transcript 638 show two cases system showing red system b showing blue theres crosses play video starting 648 follow transcript 648 right better hope system clearly better level recall play video starting 658 follow transcript 658 level recall precision point system better system b theres question imagine code look ideal search system perfect precision recall points line ideal system general higher curve better right problem case actually happens two curves cross play video starting 732 follow transcript 732 case better play video starting 735 follow transcript 735 think play video starting 738 follow transcript 738 real problem actually face suppose build search engine old algorithm thats blue system b come new idea test results red curve play video starting 759 follow transcript 759 question new method better old method play video starting 85 follow transcript 805 practically replace algorithm youre search engine new algorithm system method replace method b going real decision make make replacement search engine behave system dont system b play video starting 836 follow transcript 836 spend time think pause video actually useful think real decision make building search engine youre working company cares search play video starting 852 follow transcript 852 thought moment realize case hard say users system users system b whats difference difference know low level recall region system b better theres higher precision high recall region system better play video starting 920 follow transcript 920 means depends user cares high recall low recall high precision imagine going check whats happening today find relevant news play video starting 934 follow transcript 934 better think play video starting 938 follow transcript 938 case clearly system b better user unlikely examining lot results user doesnt care high recall play video starting 947 follow transcript 947 hand think case user starting problem find idea ha started case emphasize high recall relevant documents possible favor system means better actually depends users precisely users task play video starting 1019 follow transcript 1019 means necessarily able come number play video starting 1025 follow transcript 1025 accurately depict performance play video starting 1029 follow transcript 1029 look overall picture practical decision make replace actually come single number quantify method compare different methods research ideally number compare easily make lot comparisons reasons desirable single number match needs number summarize range precisionrecall curve right way summarize ranked list curve look area curve play video starting 1119 follow transcript 1119 right way measure ways measure turns play video starting 1126 follow transcript 1126 particular way matching popular long time ago text basically way called average precision basically going take look different recall point play video starting 1147 follow transcript 1147 look precision know know precision different recall dont count recall level going look number thats precision different recall level cetera know added precisions different points corresponding retrieving relevant document second third follows cetera missed relevant documents cases assume zero precisions play video starting 1233 follow transcript 1233 finally take average divide ten total number relevant documents collection play video starting 1241 follow transcript 1241 note dividing sum four number retrieved relevant documents imagine divide four happen play video starting 1254 follow transcript 1254 think moment play video starting 1257 follow transcript 1257 common mistake people overlook play video starting 132 follow transcript 1302 right divide four actually good fact favoring system retrieve random documents case denominator small good matching note denomina denominator ten total number relevant documents basically compute area needs occur standard method evaluating ranked list play video starting 1341 follow transcript 1341 note actually combines recall precision know precision numbers secondly consider recall missed zeros right combines precision recall measure sensitive small change position relevant document lets say move relevant document bit increase means average precision move relevant document lets say move relevant document decrease uhthe average precision good sensitive ranking relevant document tell small differences two ranked lists algorithm works slightly better difference contrast look precision ten documents look set whats precision think easy thats four ten right precision meaningful tells user thats pretty useful right meaningful measure users perspective measure compare systems wouldnt good wouldnt sensitive four relevant documents ranked move precision ten right good measure comparing different algorithms contrast average precision better measure tell difference different difference ranked list subtle ways music
play video starting follow transcript 000 sound play video starting 11 follow transcript 011 average precision computer query generally experiment different queries avoid variance queries depending queries make different conclusions right better queries play video starting 33 follow transcript 033 queries take average average precision queries play video starting 41 follow transcript 041 play video starting 43 follow transcript 043 naturally think arithmetic mean play video starting 50 follow transcript 050 tend think way give whats called mean average position map case take arithmetic mean average precisions queries topics play video starting 19 follow transcript 109 mentioned lecture good play video starting 115 follow transcript 115 call talked different ways combining precision recall conclude arithmetic mean good map measure think alternative ways aggregating numbers dont automatically assume lets take arithmetic mean average position queries lets think whats best way aggregating think different ways naturally probably able think way geometric mean play video starting 151 follow transcript 151 call average gmap play video starting 155 follow transcript 155 way think two different ways thing natural question ask better play video starting 25 follow transcript 205 map gmap play video starting 29 follow transcript 209 thats important question imagine testing new algorithm comparing ways old algorithms made search engine play video starting 218 follow transcript 218 tested multiple topics youve got average precision topics thinking looking overall performance take average play video starting 230 follow transcript 230 strategy play video starting 234 follow transcript 234 think question did make difference think scenarios make difference give different rankings methods means depending way average detect average average positions play video starting 255 follow transcript 255 different conclusions makes question important play video starting 31 follow transcript 301 right play video starting 35 follow transcript 305 look difference different ways aggregating average position youll realize arithmetic mean sum dominating large values large value mean means query relatively easy high pres average position play video starting 325 follow transcript 325 gmap tends affected low values play video starting 330 follow transcript 330 queries dont good performance average precision low play video starting 337 follow transcript 337 think improving search engine difficult queries gmap preferred right play video starting 347 follow transcript 347 hand improved lot play video starting 352 follow transcript 352 kinds queries particular popular queries easy make perfect map preferred answer depends users users tasks pref preferences play video starting 48 follow transcript 408 point think multiple ways solve problem compare think carefully differences makes sense make sense situation make sense different situation important pick situations preferred play video starting 435 follow transcript 435 special case mean average position think case precisely rank document happens example whats called known item search know target page lets say find amazon homepage relevant document hope find thats call known item search case theres precisely relevant document application question answering theres answer rank answers goal rank particular answer top right case easily verify average position basically boil reciprocal rank 1 r r rank position single relevant document document ranked top 1 1 reciprocal rank ranked second 1 2 cetera play video starting 541 follow transcript 541 take average average precision reciprocal rank set topics give called mean reciprocal rank popular measure item search know problem relevant item play video starting 63 follow transcript 603 r actually meaningful r basically indicating effort user make order find relevant document ranked top low effort make effort ranked 100 actually play video starting 627 follow transcript 627 read presumably 100 documents order find sense r meaningful measure reciprocal rank take reciprocal r r directly play video starting 642 follow transcript 642 natural question simply r imagine design ratio measure performance random system relevant item play video starting 655 follow transcript 655 thought r directly measure measures users effort right think take average large number topics play video starting 712 follow transcript 712 make difference right single topic r 1 r wouldnt make difference larger r corresponds small 1 r right play video starting 726 follow transcript 726 difference show show topics think average mean reciprocal rank versus average r whats difference difference difference change oath systems conclusion play video starting 749 follow transcript 749 turns actually big difference think think pause video play video starting 759 follow transcript 759 basically difference take directory dominated large values r values basically large values indicate lower ranked results means relevant items rank low list sum thats average dominated relevant documents ranked lower portion ranked users perspective care highly ranked documents taking transformation reciprocal rank play video starting 840 follow transcript 840 emphasize difference top know think difference 1 2 make big difference 1 r think 100 1 wont make difference big difference 100 lets say 1000 right desirable play video starting 96 follow transcript 906 hand 1 2 wont make difference case multiple choices thing figure makes sense play video starting 917 follow transcript 917 summarize showed precisionrecall curve characterize overall accuracy ranked list emphasized actual utility ranked list depends top ranked results user actually examine users examine average person uses standard measure comparing two ranking methods combines precision recall sensitive rank random document music
play video starting follow transcript 000 music play video starting 7 follow transcript 007 lecture evaluate text retrieval system multiple levels judgements lecture continue discussion evaluation going look evaluate text retrieval system multiple levels judgements play video starting 27 follow transcript 027 talked binary judgements means document judged relevant relevant play video starting 35 follow transcript 035 earlier talk relevance medal degrees distinguish high relevant documents useful documents moderately relevant documents okay useful adding documents useful play video starting 57 follow transcript 057 imagine ratings pages multiple levels ratings example show example three levels 3 relevant sorry 3 relevant 2 marginally relevant 1 nonrelevant evaluate search engine system judgements obvious map doesnt work average precision doesnt work precision recall doesnt work rely binary judgements lets look top ranked results judgements imagine user care top ten results play video starting 143 follow transcript 143 marked rating levels relevance levels documents 3 2 1 1 3 etcetera call gain reason call gain measure infusing called ndcg normalized accumulated gain play video starting 210 follow transcript 210 gain basically measure gain random information user obtain looking document right looking document user gain 3 points looking nonrelevant document user gain 1 point play video starting 229 follow transcript 229 looking moderator marginally relevant document user 2 points etcetera gain measures utility document users perspective course assume user stops 10 documents looking cutoff 10 look total gain user whats thats simply sum call cumulative gain user stops position 1 thats 3 user looks document thats 32 user looks documents cumulative gain course cost spending time examine list cumulative gain gives idea total gain user user examines documents ndcg letter d discounted cumulative gain play video starting 329 follow transcript 329 discounting look cumulative gain deficiency did consider rank position documents example looking sum know 1 highly relevant document 1 marginally relevant document 2 nonrelevant documents dont care ranked ideally two ranked top case play video starting 43 follow transcript 403 capture intuition say 3 good 3 top means contribution gain different positions weighted position idea discounting basically going say discounted user assumed document second discounted bit theres small possibility user wouldnt notice divide gain weight based position log 2 2 rank position document third position discounted normalizer log 3 take sum lower ranked document contribute highly ranked document means example switch position lets say position discount put example relevant document opposed imagine put 3 discounted good put 3 idea discounting play video starting 537 follow transcript 537 okay point got discounted cumulative gain measuring utility ranked list multiple levels judgements play video starting 551 follow transcript 551 happy rank systems bit order make measure comparable different topics step way show dcg 10 total sum dcg 10 documents step called n normalization normalized dcg idea going normalize dcg ideal dcg cutoff ideal dcg dcg ideal ranking imagine 9 documents collection rated 3 means total 9 documents rated 3 play video starting 653 follow transcript 653 ideal rank lister put 9 documents top 3 followed 2 thats best run 3 positions 3 right ideal ranked list play video starting 718 follow transcript 718 computed dcg ideal rank list play video starting 723 follow transcript 723 given formula ideal dcg normalizer dcg idea dcg normalizer imagine normalization essentially compare actual dcg best dcg possibly topic map dcg values range 0 1 play video starting 757 follow transcript 757 best value highest value query 1 thats rank list fact ideal list general lower play video starting 813 follow transcript 813 dont transformation normalization doesnt affect relative comparison systems topic ideal dcg systems ranking systems based dcg exactly rank based normalized dcg difference multiple topics dont normalization different topics different scales dcg play video starting 846 follow transcript 846 topic 9 highly relevant documents dcg high imagine case two relevant documents total collection highest dcg system achieve topic high face problem different scales dcg values take average dont average dominated high values easy queries normalization avoided problem making queries contribute equal average idea ndcg measuring rank list based multiple level relevance judgements play video starting 942 follow transcript 942 general way basically measure applied ranked task multiple level judgements scale judgements multiple binary binary multiple levels 1 0 5 depending application main idea measure summarize measure total utility top k documents cutoff measure total utility discount contribution lowly ranked document finally normalization ensure comparability queries music
play video starting follow transcript 000 sound lecture practical issues address evaluation text retrieval systems play video starting 14 follow transcript 014 lecture continue discussion evaluation cover practical issues solve actual evaluation text retrieval systems play video starting 25 follow transcript 025 order create test collection create set queries set documents set relevance judgments play video starting 35 follow transcript 035 turns actually challenging create documents queries representative represent real queries real documents users handle play video starting 48 follow transcript 048 queries documents order avoid bias conclusions play video starting 56 follow transcript 056 matching relevant documents queries ensure exists lot relevant documents query query thats relevant option actually informative compare different methods query theres room difference ideally relevant documents clatch queries represent real queries care play video starting 131 follow transcript 131 terms relevance judgments challenge ensure complete judgments documents queries minimizing human fault human labor label documents labor intensive result impossible actually label documents queries especially considering giant data set web play video starting 158 follow transcript 158 actually major challenge difficult challenge measures challenging measures accurately reflect perceived utility users consider carefully users care design measures measure measure measuring right thing conclusion misled important play video starting 226 follow transcript 226 going talk couple issues statistical significance test reason lot queries question sure observe difference doesnt simply result particular queries sample results average position system system b different experiments bottom mean average position mean look mean average position mean average positions exactly experiments right 020 040 system b 020 040 identical look exact average positions different queries look numbers detail realize case feel trust conclusion given average play video starting 336 follow transcript 336 case case feel im sure dont take look numbers moment pause media look average mean average position easily say system b better right 040 twice 020 thats better performance look two experiments look detailed results play video starting 411 follow transcript 411 weve confident say case experiment case numbers consistently better system b play video starting 425 follow transcript 425 experiment 2 sure looking results system better case system better play video starting 439 follow transcript 439 look average system b better play video starting 445 follow transcript 445 think play video starting 449 follow transcript 449 reliable conclusion look average play video starting 455 follow transcript 455 case intuitively feel experiment 1 reliable play video starting 51 follow transcript 501 quantitate answer question statistical significance test play video starting 59 follow transcript 509 idea statistical significance test basically assess variants different queries big variance means results fluctuate lot different queries believe lot queries results change set queries right c high variance reliable play video starting 543 follow transcript 543 lets look results second case show two different ways compare sign test look sign system b better system plus sign system better minus sign case seven cases actually four cases system b better three cases system better intuitively random results right take random sample flip seven coins plus denote head minus denote tail easily results randomly flipping seven coins fact average larger doesnt tell cant reliably conclude quantitatively measured p value basically means play video starting 649 follow transcript 649 probability result fact random fluctuation case probability 10 means surely random fluctuation play video starting 71 follow transcript 701 willcoxan test nonparametric test looking signs looking magnitude difference draw similar conclusion say likely random illustrate lets think distribution called distribution assume mean zero lets say started assumption theres difference two systems assume random fluctuations depending queries observe difference actual difference left side right side right play video starting 743 follow transcript 743 curve shows probability actually observe values deviating zero play video starting 753 follow transcript 753 look picture play video starting 81 follow transcript 801 difference observed chance high fact random observation right define region likely observation random fluctuation 95 outcomes observed random fluctuation play video starting 828 follow transcript 828 observe value region difference side difference unlikely random fluctuation right theres small probability observe difference random fluctuation play video starting 848 follow transcript 848 case conclude difference real system b better play video starting 856 follow transcript 856 idea statical significance test takeaway message queries avoid jumping conclusion case say system b better play video starting 99 follow transcript 909 different ways statistical significance test play video starting 915 follow transcript 915 lets talk problem making judgments earlier hard judge documents completely small data set question afford judging documents collection subset judge play video starting 935 follow transcript 935 solution pooling strategy cases solve problem play video starting 946 follow transcript 946 idea pooling following diverse set ranking methods text retrieval systems play video starting 957 follow transcript 957 hope methods help nominate relevant documents goal pick relevant documents make judgements relevant documents useful documents users perspectives going return topk documents play video starting 1017 follow transcript 1017 k vary systems point ask suggest likely relevant documents play video starting 1025 follow transcript 1025 simply combine topk sets form pool documents human assessors judge imagine systems ten k documents take topk documents form union course documents duplicated systems retrieved random documents duplicate documents play video starting 1056 follow transcript 1056 unique documents returned system idea having diverse set ranking methods ensure pool broad possible relevant documents possible play video starting 1112 follow transcript 1112 users human assessors make complete judgments data set pool unjudged documents usually assumed non relevant pool large assumption okay play video starting 1132 follow transcript 1132 pool large actually reconsidered strategies deal methods handle cases strategy generally okay comparing systems contribute pool means participate contributing pool unlikely penalize system problematic documents judged play video starting 124 follow transcript 1204 problematic evaluating new system contributed pool case new system penalized nominated read documents judged documents assumed non relevant thats unfair summarize part textual evaluation extremely important problem empirically defined problem play video starting 1238 follow transcript 1238 dont rely users theres way tell method works better play video starting 1243 follow transcript 1243 property experiment design misguide research applications draw wrong conclusions discussions make sure right research application play video starting 13 follow transcript 1300 main methodology cranfield evaluation methodology main paradigm kinds empirical evaluation tasks search engine variation map ndcg two main measures definitely know appropriate comparing ranking algorithms research papers precision 10 documents easier interpret users perspective thats useful play video starting 1330 follow transcript 1330 whats covered evaluation strategy ab test system mix two results two methods randomly show mixed results users course users dont result method users judge results click documents search engine application case search engine check click documents method contributed click documents user tends click results method play video starting 1413 follow transcript 1413 suggests message better leverages real users search engine evaluation called ab test strategy modern search engines commercial search engines way evaluate ir textual retrieval user studies havent covered ive put references look know play video starting 1441 follow transcript 1441 three additional readings three mini books evaluation excellent covering broad review information retrieval evaluation covers things discussed lot offer play video starting 152 follow transcript 1502 music
4 overview weeks lessons learn probabilistic retrieval models statistical language models particularly detail query likelihood retrieval function two specific smoothing methods query likelihood retrieval function connected retrieval heuristics vector space model time module take approximately 6 hours dedicated time complete videos assignments activities activities module listed assignments bold activity estimated time required 4 video lectures 2 hours 4 graded quiz 1 hour programming assignment 22 3 hours goals objectives actively engage learning experiences module able explain interpret pr1qd estimate based large set collected relevance judgments clickthrough information query q document d explain interpret conditional probability pqd scoring documents query likelihood retrieval function explain statistical language model unigram language model explain compute maximum likelihood estimate unigram language model explain unigram language models discover semantically related words compute pqd based given document language model pwd explain smoothing show query likelihood retrieval function implements tfidf weighting smooth document language model pwd collection language model pwc reference language model compute estimate pwd jelinekmercer jm smoothing dirichlet prior smoothing respectively guiding questions develop answers following guiding questions completing readings working assignments given table relevance judgments form three columns query document binary relevance judgments estimate pr1qd interpret query likelihood conditional probability pqd statistical language model unigram language model parameters unigram language model compute maximum likelihood estimate unigram language model based text sample background language model collection language model document language model smooth document language model query likelihood retrieval model happen don’t smoothing smooth document language model collection language model reference language model probability assigned unseen word document prove query likelihood retrieval function implements tfidf weighting collection language model smoothing linear interpolation jelinekmercer smoothing work formula dirichlet prior smoothing work formula similarities differences jelinekmercer smoothing dirichlet prior smoothing additional readings resources c zhai s massung text data management analysis practical introduction information retrieval text mining acm book series morgan claypool publishers 2016 chapter 6 section 64 key phrases concepts keep eyes open following key terms phrases complete readings interact lectures topics help better understand content module pr1qd query likelihood pqd statistical unigram language models maximum likelihood estimate background collection document language models smoothing unigram language models relation query likelihood tfidf weighting linear interpolation jelinekmercer smoothing dirichlet prior smoothing tips success recommend following review video lectures number times gain solid understanding key questions concepts introduced possible tips suggestions peers class learning community help learn grow way helping address questions peers pose engaging we’ll learn better it’s good idea refer video lectures chapter readings weve read reference responses appropriate critique information presented take notes read materials watch lectures taking notes interacting material find easier remember understand notes you’ll find it’s easier complete assignments ahead favor take notes getting giving help getgive help following means learner help center opens new tab find information regarding specific technical problems example technical problems error messages difficulty submitting assignments problems video playback find answer documentation report problem coursera staff clicking contact link available topics page learner help center content issues opens new tab forum report errors lecture video content assignment questions answers assignment grading text links course pages content course materials university illinois staff community tas monitor forum respond issues mark completed item completed dislike report issue
play video starting follow transcript 000 sound lecture probabilistic retrieval model lecture going continue discussion text retrieval methods going look different way design ranking functions vector space model discussed play video starting 32 follow transcript 032 probabilistic models define ranking function based probability document relevant query words introduce binary random variable variable r assume query documents observations random variables play video starting 1 follow transcript 100 note vectorbased models assume vectors assume data observed random variables problem retrieval estimate probability relevance play video starting 119 follow transcript 119 category models different variants classic probabilistic model led bm25 retrieval function discussed vectorsbased model form actually similar backwards space model play video starting 135 follow transcript 135 lecture discuss sub class play video starting 141 follow transcript 141 p class called language modeling approaches retrieval particular going discuss query likelihood retrieval model play video starting 151 follow transcript 151 effective models probabilistic models play video starting 157 follow transcript 157 line called divergence randomness model led pl2 function play video starting 26 follow transcript 206 effective state art retrieval functions query likelihood assumption probability relevance approximated probability query given document relevance intuitively probability captures following probability user likes document d likely user enter query q order retrieve document d assume user likes d relevance value ask question likely particular query user play video starting 254 follow transcript 254 basic idea understand idea lets take look general idea basic idea probabilistic retrieval models listed imagined relevance status values relevance judgments queries documents example line shows q1 query user typed d1 document user 1 means user thinks d1 relevant q1 r approximated clickthrough data search engine collect watching interacted search results case lets say user clicked document theres 1 play video starting 350 follow transcript 350 similarly user clicked d2 1 words d2 assumed relevant q1 play video starting 4 follow transcript 400 hand d3 nonrelevant theres 0 play video starting 47 follow transcript 407 d4 nonrelevant d5 relevant part data collected different user user typed q1 found d1 actually useful d1 actually nonrelevant contrast relevant query typed user different times d2 relevant data queries play video starting 448 follow transcript 448 imagine lot data play video starting 452 follow transcript 452 ask question estimate probability relevance play video starting 5 follow transcript 500 compute probability relevance intuitively means look entries particular d particular q likely column basically means collect counts play video starting 519 follow transcript 519 count times q d pair table count times actually 1 third column compute ratio play video starting 539 follow transcript 539 lets take look specific examples suppose trying compute probability d1 d2 d3 q1 estimated probability think pause video needed try take look table try give estimate probability play video starting 67 follow transcript 607 interested q1 d1 looking two pairs cases actually cases user 1 relevant r 1 two cases case 0 thats two d1 d2 d1 d2 d1 d2 cases case r 1 two two approach actually score documents query right score d1 d2 d3 query simply rank based probabilities thats basic idea probabilistic retrieval model makes lot sense case going rank d2 documents cases c q1 d2 r 1 user clicked document show lot clickthrough data search engine learn lot data improve search engine simple example shows small amount entries estimate probabilities probabilities give sense document relevant useful user typing query play video starting 747 follow transcript 747 course problems dont observe queries documents relevance values right play video starting 755 follow transcript 755 lot unseen documents general collected data documents users unseen queries predict queries typed users obviously approach wont work apply unseen queries unseen documents play video starting 818 follow transcript 818 shows basic idea probabilistic retrieval model makes sense intuitively case lot unseen documents unseen queries solutions approximate way particular case called query likelihood retrieval model approximate conditional probability pq given d r1 condition part assume user likes document user clicked document play video starting 856 follow transcript 856 part shows interested likely user actually enter query likely query row note made interesting assumption basically going assume user types query user likes document words actually make following assumption play video starting 922 follow transcript 922 user formulates query based imaginary relevant document look conditional probability obvious making assumption meant new conditional probability help score new conditional probability able estimate conditional probability relying big table having similar problems making assumption way bypass big table try model user formulates query okay simplify general model derive specific relevant function later lets look model work example basically going case ask following question documents likely imaginary relevant document users mind user formulates query ask question quantify probability probability conditional probability observing query particular document fact imaginary relevant document users mind weve computed query likelihood probabilities likelihood queries given document values rank documents based values summarize general idea modern relevance proper risk model assume introduce binary random variable r scoring function defined based conditional probability talked approximating query likelihood play video starting 1122 follow transcript 1122 case ranking function thats basically based probability query given document probability interpreted probability user likes document d pose query q play video starting 1140 follow transcript 1140 question course compute conditional probability general compute probability text q text model called language model models proposed model text play video starting 122 follow transcript 1202 specifically interested following conditional probability user liked document likely user pose query lecture going giving introduction language models model text probable risk model general music
play video starting 7 follow transcript 007 sound lecture statistical language model lecture going give introduction statistical language model model text data probabilistic models related model query based document play video starting 31 follow transcript 031 going talk language model going talk simplest language model called unigram language model happens useful model text retrieval finally class language model play video starting 47 follow transcript 047 language model probability distribution word sequences ill show play video starting 55 follow transcript 055 model gives sequence today wednesday probability 0001 give today wednesday small probability nongrammatical play video starting 111 follow transcript 111 probabilities given sentences sequences words vary lot depending model clearly context dependent ordinary conversation probably today wednesday popular sentences imagine context discussing apply math eigenvalue positive higher probability means represent topic text play video starting 142 follow transcript 142 model regarded probabilistic mechanism generating text called generating model mean imagine mechanism thats visualised stochastic system generate sequences words ask sequence send sequence device generate example today wednesday generated sequences example possibilities right play video starting 224 follow transcript 224 sense view data basically sample observed generating model model useful mainly quantify uncertainties natural language uncertainties come source simply ambiguity natural language discussed earlier lecture source dont complete understanding lack knowledge understand language case uncertainties show examples questions answer language model interesting applications different ways given john feels likely happy opposed habit word sequence words obviously useful speech recognition happy habit similar acoustic sound acoustic signals look language model know john feels happy likely john feels habit play video starting 335 follow transcript 335 example given observe baseball three times game news article likely sports obviously related text categorization information retrieval play video starting 348 follow transcript 348 given user interested sports news likely user baseball query clearly related query likelihood discussed previous lecture play video starting 42 follow transcript 402 lets look simplest language model called unigram language model case assume generate text generating word independently play video starting 414 follow transcript 414 means probability sequence words product probability word normally theyre independent right single word language make likely observe model havent language assumption necessarily true make assumption simplify model play video starting 441 follow transcript 441 model precisely n parameters n vocabulary size probability word probabilities sum 1 strictly speaking actually n1 parameters play video starting 5 follow transcript 500 text assumed assembled drawn word distribution play video starting 58 follow transcript 508 example ask device model stochastically generate words sequences giving sequence today wednesday gives word kinds words assemble words sequence allow compute probability today wednesday product three probabilities play video starting 537 follow transcript 537 asked model generate sequences actually allows compute probability sequences model needs n parameters characterize means specify probabilities words models behavior completely specified dont make assumption specify probabilities kinds combinations words sequences play video starting 611 follow transcript 611 making assumption makes easier estimate parameters lets specific example play video starting 619 follow transcript 619 show two unigram language models probabilities high probability words top play video starting 629 follow transcript 629 clearly suggests topic text mining high probability related topic second related health play video starting 639 follow transcript 639 ask question likely observe particular text two models suppose sample words form document lets say take distribution sample words words think generated making text mining word food small probability able show play video starting 73 follow transcript 703 general high probability words likely show play video starting 78 follow transcript 708 imagine general text looks text mining play video starting 712 follow transcript 712 fact small probability able actually generate actual text mining paper actually meaningful probability small play video starting 726 follow transcript 726 extreme case imagine able generate text mining paper accepted major conference case probability smaller nonzero probability assume words nonzero probability play video starting 747 follow transcript 747 similarly second topic imagine generate food nutrition paper doesnt mean generate paper text mining distribution play video starting 759 follow transcript 759 probability small smaller generating paper accepted major conference text mining play video starting 810 follow transcript 810 point keeping distribution play video starting 813 follow transcript 813 talk probability observing text texts higher probabilities play video starting 821 follow transcript 821 lets look problem different way suppose available particular document case abstract text mining table word counts total number words 100 question ask estimation question ask question model distribution generate text assuming text generated assembling words distribution play video starting 851 follow transcript 851 guess play video starting 854 follow transcript 854 decide probabilities text mining play video starting 91 follow transcript 901 suppose view second try think best guess play video starting 99 follow transcript 909 youre lot people guessed best guess text probability 10 100 ive text 10 times total 100 words simply normalize counts play video starting 927 follow transcript 927 thats fact word justified intuition consistent mathematical derivation called maximum likelihood estimator estimator assume parameter settings give observe data maximum probability means change probabilities probability observing particular text data smaller play video starting 955 follow transcript 955 simple formula basically look count word document divide total number words document document lens normalize frequency consequence course going assign zero probabilities unseen words observed word incentive assign nonzero probability approach take away probability mass observed words obviously wouldnt maximize probability particular observed text data question best estimate answer depends model find right estimator gives best model based particular data interested model explain content full paper abstract second thought right thing words body article zero probabilities theyre observed abstract going cover bit later class query likelihood model play video starting 1124 follow transcript 1124 lets take look possible uses language models simply represent topics show general english background texts text estimate language model model look play video starting 1142 follow transcript 1142 right top common words common words rare words bottom background language model represents frequency words english general background model lets look text time look computer science research papers play video starting 1211 follow transcript 1211 collection computer science research papers mentioned maximum likelihood estimator simply normalize frequencies play video starting 1220 follow transcript 1220 case distribution looks top looks similar words occur common words related computer science computer software text words example computer imagine probability smaller probability words common general english distribution characterizes topic corresponding text look smaller text play video starting 133 follow transcript 1303 case lets look text mining paper distribution expected occur top sooner text mining association clustering words relatively high probabilities contrast distribution text relatively small probability means based different text data different model model captures topic call document language model call collection language model later theyre retrieval function play video starting 1347 follow transcript 1347 lets look model statistically find words semantically related computer play video starting 1356 follow transcript 1356 find words thought lets take look text match computer take look documents contain word computer lets build language model words surprisingly common words top case language model gives conditional probability word context computer common words naturally high probabilities computer software relatively high probabilities model say words semantically related computer play video starting 1443 follow transcript 1443 ultimately wed rid common words play video starting 1452 follow transcript 1452 turns possible language model play video starting 1457 follow transcript 1457 suggest think know words common rid play video starting 157 follow transcript 1507 model tell think background language model precisely tells information tells common general background model know words common words general surprising observe context computer computer small probability general surprising computer probability true software play video starting 1544 follow transcript 1544 two models figure words related computer example simply take ratio group probabilities normalize topic language model probability word background language model take ratio top computer ranked followed software program words related computer occur frequently context computer frequently collection common words high probability fact ratio 1 related computer taking sample text contains computer dont occurrences general play video starting 1640 follow transcript 1640 shows simple language models limited analysis semantics play video starting 1648 follow transcript 1648 lecture talked language model basically probability distribution text talked simplest language model called unigram language model word distribution talked two uses language model represent topic document collection general discover word associations play video starting 1716 follow transcript 1716 lecture going talk language model design retrieval function play video starting 1723 follow transcript 1723 two additional readings textbook statistical natural language processing play video starting 1730 follow transcript 1730 second article survey statistical language models lot pointers research work music
play video starting follow transcript 000 sound play video starting 7 follow transcript 007 lecture query likelihood probabilistic retrieval model play video starting 14 follow transcript 014 lecture continue discussion probabilistic retrieval model particular going talk query light holder retrieval function play video starting 25 follow transcript 025 query light holder retrieval model idea model user likes document pose particular query play video starting 36 follow transcript 036 case imagine user likes particular document presidential campaign news assume user document basis impose query try retrieve document play video starting 57 follow transcript 057 imagine process works follows assume query generated assembling words document play video starting 110 follow transcript 110 example user pick word presidential document query word play video starting 120 follow transcript 120 user pick word campaign second query word play video starting 127 follow transcript 127 course assumption made user pose query user actually followed process different question assumption allowed characterize conditional probability play video starting 146 follow transcript 146 allows rely big table showed earlier play video starting 152 follow transcript 152 empirical data estimate probability play video starting 156 follow transcript 156 idea derive retrieval function implement program language play video starting 24 follow transcript 204 assumption made query word independent sample word basically obtained document play video starting 220 follow transcript 220 lets works exactly completing query likelihood play video starting 229 follow transcript 229 probability probability particular query sequence words make assumption word generated independently result probability query product probability query word play video starting 250 follow transcript 250 compute probability query word based assumption word picked document user mind know probability word relative frequency word document example probability presidential given document count presidential document divided total number words document document s assumptions actually simple formula retrieval rank documents play video starting 332 follow transcript 332 model work lets take look example documents suppose query presidential campaign formula top play video starting 345 follow transcript 345 score document simple count times presidential times campaigns 44 weve presidential twice thats 2 length document 4 multiplied 1 length document 4 probability campaign similarly probabilities two documents play video starting 413 follow transcript 413 look numbers formulas scoring documents make sense assume d3 d4 length looks nominal rank d4 d3 d2 expect looks did captures tf query state work try different query presidential campaign update problem problem think update documents mentioned update assumption user pick word document generate query probability obtaining word update 0 play video starting 517 follow transcript 517 causes problem cause documents zero probability generating query play video starting 525 follow transcript 525 fine zero probability d2 nonrelevant okay 0 d3 d4 longer distinguish whats cant distinguish d2 thats obviously desirable inaudible result think caused problem play video starting 552 follow transcript 552 examine assumptions made derive ranking function examine assumptions carefully realize caused problem take moment think think reason update zero probability fix think moment realize thats made assumption query word drawn document users mind order fix assume user drawn word necessarily document thats improved model improvement say drawing word document lets imagine user actually draw word document model show model assume document generated unigram language model model doesnt necessarily assign zero probability update fact assume model assign zero probability word thinking way generation process bit different user model mind particular document model estimated based document user generate query singular process pick word example presidential word campaign play video starting 729 follow transcript 729 difference time pick word update update doesnt occur document potentially generate query word update query updated 1 times 0 probabilities fix problem reasonable thinking user looking general way unique language model fixed document compute query likelihood make sum wide involved two steps compute model call document language model example ive two pulse models major based two documents given query data mining algorithms thinking compute likelihood query making independence assumptions probability product probability query word documents score two documents rank play video starting 837 follow transcript 837 thats basic idea query likelihood retrieval function generally ranking function look following assume query n words w1 wn scoring function ranking function probability observe query given user thinking document assume product probabilities individual words based independent assumption actually score document query log query likelihood second line play video starting 926 follow transcript 926 avoid having lot small probabilities mean multiply cause flow loose precision transforming value algorithm function maintain order documents avoid flow problem take longer transformation course product sum second line sum query words sum probability word given document play video starting 109 follow transcript 1009 rewrite sum different form play video starting 1014 follow transcript 1014 sum sum play video starting 1021 follow transcript 1021 query words query word sum sum possible words put counter word query essentially considering words query word query count 0 considering n words different form going take sample words vocabulary play video starting 1052 follow transcript 1052 course word occur multiple times query thats count play video starting 11 follow transcript 1100 part log probability word given document language model play video starting 118 follow transcript 1108 retrieval function actually know count word query thing dont know document language model play video starting 1117 follow transcript 1117 converted retrieval problem problem estimating document language model play video starting 1125 follow transcript 1125 compute probability query word given document play video starting 1132 follow transcript 1132 different estimation methods lead different ranking functions different way place document vector space leads different ranking function vector space model different ways estimate lead different ranking function query likelihood music
play video starting follow transcript 000 sound lecture smoothing language models play video starting 11 follow transcript 011 lecture going continue talking probabilistic retrieval model particular going talk smoothing language model query likelihood retrieval method play video starting 23 follow transcript 023 slide previous lecture ranking function based query likelihood play video starting 32 follow transcript 032 assume independence generating query word formula look following take sum query words sum log probability word given document document image model main task estimate document language model different methods estimating model lead different retrieval functions lecture going looking detail estimate language model obvious choice maximum likelihood estimate going normalize word frequencies document play video starting 124 follow transcript 124 estimate probability look play video starting 130 follow transcript 130 step function play video starting 135 follow transcript 135 means words frequency count identical problem freedom count different probability note words occurred document play video starting 152 follow transcript 152 0 probability know model assume earlier lecture assume simple word document formula clear play video starting 29 follow transcript 209 theres chance assembling word thats document know thats good play video starting 215 follow transcript 215 improve order assign 0 probability words observed document take away probability mass words observed document example take away probability mass extra probability mass words wont sum 1 probabilities sum 1 make transformation improve maximum likelihood estimated assigning non zero probabilities words observed data play video starting 31 follow transcript 301 smoothing smoothing improving estimate considering possibility author play video starting 313 follow transcript 313 asking write words document author written words think factor smoothed language model accurate representation actual topic imagine abstract research article lets say document abstract play video starting 339 follow transcript 339 assume words abstract probability 0 mean theres chance sampling word abstract formulated query imagine user interested topic subject user actually word thats chapter query obviously asked author write author written full text article smoothing language model attempt try recover model article course dont knowledge words observed abstract thats smoothing actually tricky problem lets talk smooth language model key question probability assigned unseen words play video starting 450 follow transcript 450 different ways play video starting 453 follow transcript 453 idea thats useful retrieval probability unseen word proportional probability given reference language model means dont observe word dataset going assume probability governed reference language model construct tell unseen words higher probability play video starting 522 follow transcript 522 case retrieval natural choice take collection language model reference language model say dont observe word document going assume probability word proportional probability word collection formally estimating probability word key document follows play video starting 548 follow transcript 548 word document probability counted maximum likelihood estimate p sub c word document going probability proportional probability word collection coefficient offer control amount probability mass assign unseen words play video starting 622 follow transcript 622 obviously probabilities sum 1 alpha sub d constrained way play video starting 629 follow transcript 629 plug smoothing formula query likelihood ranking function play video starting 637 follow transcript 637 formula sum query words written sum vocabulary sum words vocabulary count word query fact taking sample query words common way convenience transformations play video starting 718 follow transcript 718 sum query words play video starting 723 follow transcript 723 smoothing method assume words observed method different form probability name four foru going decompose sum two parts play video starting 738 follow transcript 738 sum query words matching document means sum words non zero probability document sorry non zero count word document occur document play video starting 82 follow transcript 802 course non zero count query query words matching document hand sum taking sum words query matching document play video starting 825 follow transcript 825 occur query due term dont occur document case words probability assumption smoothing words different probability play video starting 847 follow transcript 847 rewriting second sum play video starting 852 follow transcript 852 difference two sums basically sum sum query words play video starting 9 follow transcript 900 know original sum query words query words matched document play video starting 912 follow transcript 912 pretend actually query words take sum query words obviously sum extra terms sum play video starting 930 follow transcript 930 taking sum query words matched document order make equal subtract sum sum query words matching document play video starting 951 follow transcript 951 makes sense considering query words subtract query matched document give query matched document play video starting 105 follow transcript 1005 reverse process step play video starting 1012 follow transcript 1012 wonder thats different forms terms sums sum words matched query matching document term play video starting 1036 follow transcript 1036 sum set terms matched query terms document sum different play video starting 1049 follow transcript 1049 two sums clearly merged play video starting 1054 follow transcript 1054 form formula looks bottom play video starting 114 follow transcript 1104 note interesting formula combine two query words matching document sum play video starting 1119 follow transcript 1119 sum decomposing two parts two parts look simpler probabilities unseen words play video starting 1131 follow transcript 1131 formula interesting sum play video starting 1137 follow transcript 1137 match query terms play video starting 1141 follow transcript 1141 vector space model take sum play video starting 1146 follow transcript 1146 terms intersection query vector document vector play video starting 1151 follow transcript 1151 looks bit vector space model fact theres similarity explain slide music
play video starting follow transcript 000 sound play video starting 12 follow transcript 012 showed rewrite query holder function form looks formula slide make assumption smoothing language model based collection language model look rewriting actually give two benefits benefit helps better understand ranking function particular going show formula smoothing collection language model give tfidf weighting length normalization second benefit allows compute query holder efficiently particular main part formula sum match query terms play video starting 19 follow transcript 109 better take sum words smooth document damage model essentially non zero problem words new form formula easier score compute play video starting 127 follow transcript 127 interesting note term actually independent document goal rank documents query ignore term ranking going documents ignoring wouldnt affect order documents play video starting 149 follow transcript 149 sum play video starting 152 follow transcript 152 matched query term contribute weight play video starting 158 follow transcript 158 weight actually interesting looks tfidf weighting frequency word query vector space model take thought product word frequency query show sum play video starting 222 follow transcript 222 naturally part correspond vector element documented vector actually play video starting 235 follow transcript 235 encodes weight similar factor tfidf weight play video starting 241 follow transcript 241 ill examine part capturing tf part capturing idf weighting play video starting 251 follow transcript 251 pause video think play video starting 255 follow transcript 255 noticed p sub related term frequency sense word occurs frequently document s made probability tend larger means term tf weight noticed term denominator actually achieving factor idf popularity term collection play video starting 331 follow transcript 331 denominator probability collection larger weight actually smaller means popular term actually smaller weight precisely idf weighting play video starting 347 follow transcript 347 different form tf idf play video starting 351 follow transcript 351 remember idf logarithm documented frequency different play video starting 358 follow transcript 358 intuitively achieves similar effect interestingly related length libation play video starting 47 follow transcript 407 factor related document length formula play video starting 414 follow transcript 414 say term related idf weighting play video starting 419 follow transcript 419 collection probability turns term actually related document length normalization particular f sub d related document length encodes probability mass give unseen worlds play video starting 441 follow transcript 441 smoothing intuitively document long smoothing assume data large probably observed words author written document short r sub t expected large smoothing likey words written author term appears paralyze non document sub d tend longer larger long document note alpha sub d occurs actually necessary paralyzing long documents effect clear play video starting 531 follow transcript 531 later consider specific smoothing methods turns paralyze long documents tfidf weighting document length normalization formula vector space model play video starting 547 follow transcript 547 thats interesting observation means dont think specific way smoothing assume smooth collection memory model formula looks tfidf weighting documents length violation play video starting 68 follow transcript 608 whats interesting fixed form ranking function play video starting 614 follow transcript 614 heuristically put logarithm play video starting 619 follow transcript 619 fact think logarithm look assumptions made clear logarithm query scoring turned product sum logarithm probability thats logarithm play video starting 640 follow transcript 640 note heuristically implement tf weighting idf weighting dont necessary logarithm imagine drop logarithm tf idf weighting play video starting 655 follow transcript 655 whats nice problem risk modeling automatically given logarithm function thats basically fixed form formula did heuristically design case try drop logarithm model probably wont work keep logarithm play video starting 719 follow transcript 719 nice property problem risk modeling following assumptions probability rules formula automatically formula particular form case play video starting 734 follow transcript 734 heuristically design formula necessarily end having specific formula play video starting 741 follow transcript 741 summarize talked smoothing document imaging model give zero probability unseen words document thats good storing query unseen word play video starting 759 follow transcript 759 necessary general improve accuracy estimating model represent topic document general idea smoothing retrieval connecting memory model play video starting 817 follow transcript 817 give clue unseen words higher probability probability unseen word assumed proportional probability collection play video starting 829 follow transcript 829 assumption weve derive general ranking formula query likelihood effect tfidf weighting document length normalization rewriting scoring ranking function primarily based sum weights matched query terms vector space model actual ranking function given automatically probability rules assumptions made vector space model heuristically think form function address question exactly smooth document model exactly reference model based connection adjust probability maximum micro made topic batch music
play video starting follow transcript 000 sound play video starting 7 follow transcript 007 lecture specific smoothing methods language models probabilistic retrieval model play video starting 16 follow transcript 016 lecture continue discussion language models information retrieval particularly query likelihood retrieval method going talk specifically smoothing methods retrieval function play video starting 33 follow transcript 033 slide previous lecture show query likelihood ranking smoothing collection language model add having retrieval function looks following retrieval function based assumptions discussed sum matching query terms sum count term query weight term document play video starting 112 follow transcript 112 t f weight constant n play video starting 120 follow transcript 120 clearly implement function programming language figure variables particular going know estimate probability word exactly set alpha play video starting 140 follow transcript 140 order answer question think specific smoothing methods main topic lecture play video starting 148 follow transcript 148 going talk two smoothing methods simple linear interpolation fixed coefficient called jelinekmercer smoothing play video starting 21 follow transcript 201 idea actually simple picture shows estimate document language model maximum likelihood estimate gives word counts normalized total number words text idea method play video starting 222 follow transcript 222 maximize probability observed text result word network observed text going 0 probability play video starting 237 follow transcript 237 idea smoothing rely collection language model word going zero probability help decide nonzero probability assigned word note network nonzero probability approach linear interpolation maximum likelihood placement collection language model computed smoothing parameter lambda 0 1 smoothing parameter larger lambda smoothing mixing achieve goal assigning nonzero probabilities word network lets works words play video starting 332 follow transcript 332 example compute smooth probability text play video starting 337 follow transcript 337 maximum likelihood estimated gives 10 100 thats going play video starting 344 follow transcript 344 collection probability combine simple formula play video starting 353 follow transcript 353 word network zero probability getting nonzero probability value thats count going zero network part nonzero thats basically method works think easily alpha sub d smoothing method basically lambda thats remember coefficient probability word given collection language model okay smoothing method second similar tiein coefficient linear interpolation called dirichlet prior bayesian smoothing play video starting 454 follow transcript 454 face problem zero probability unseen word network play video starting 53 follow transcript 503 collection language model case going combine different ways formula interpolation maximum likelihood estimate collection language model jm smoothing method coefficient lambda fixed number dynamic coefficient form mu parameter nonnegative value set mu constant effect long document actually smaller coefficient play video starting 546 follow transcript 546 long document longer lengths coefficient actually smaller long document smoothing expect make sense fixed coefficient smoothing course part form two coefficients sum 1 way understand smoothing basically means dynamic coefficient interpolation play video starting 622 follow transcript 622 way understand formula easier remember thats side play video starting 633 follow transcript 633 easier rewrite smoothing method form form easily change made maximum likelihood estimate part normalize count document length form did add count word play video starting 71 follow transcript 701 mean basically related probability word collection play video starting 710 follow transcript 710 multiply parameter mu play video starting 714 follow transcript 714 combine count essentially adding pseudocounts observed text pretend word got pseudocount total count sum pseudocounts actual count word document play video starting 739 follow transcript 739 result total added pseudocounts take play video starting 750 follow transcript 750 words probability words sum 1 gives mu total number pseudocounts added play video starting 81 follow transcript 801 probabilities sum 1 case easily method essentially play video starting 813 follow transcript 813 add pseudocount data pretend actually augment data pseudo data defined collection language model result counts total counts word result word zero count lets say zero count nonzero count part method works lets take look specific example text 10 original count actually observe add pseudocount probability text form naturally probability network part whats alpha sub d play video starting 915 follow transcript 915 think pause video play video starting 920 follow transcript 920 youll notice part basically alpha sub d case alpha sub d depend document length depends document linear interpolation jm smoothing method constant music
play video starting follow transcript 000 sound play video starting 13 follow transcript 013 lets plug model masses ranking function okay general smoothing general ranking function smoothing subtraction play video starting 28 follow transcript 028 specific smoothing method jm smoothing method play video starting 33 follow transcript 033 lets whats value office d play video starting 40 follow transcript 040 whats value p sub c right decide order figure exact form ranking function figure course alpha lets ratio basically right probability c board top probability unseen war words basically 11 times basically alpha easy rewritten simple plug play video starting 128 follow transcript 128 whats value alpha think lambda right play video starting 138 follow transcript 138 happen plug value lambda say play video starting 147 follow transcript 147 depend document play video starting 150 follow transcript 150 ignored play video starting 153 follow transcript 153 right end having ranking function play video starting 2 follow transcript 200 case easy precisely vector space model part sum matched query terms element query map think element document play video starting 218 follow transcript 218 right thats document left element lets examine whats logarithm play video starting 230 follow transcript 230 plus going nonnegative log going least 1 right play video starting 239 follow transcript 239 parameter lambda parameter lets look tf clearly tf weighting play video starting 249 follow transcript 249 larger count higher weighting idf weighting given play video starting 258 follow transcript 258 docking lans relationship heuristics captured formula play video starting 34 follow transcript 304 whats interesting got weighting function automatically making various assumptions vector space model heuristic design order case note theres specific form form actually makes sense play video starting 326 follow transcript 326 right think denominator hm math document total number words multiplied probability word play video starting 338 follow transcript 338 given collection right actually interpreted expected account word going draw word connection model going draw number words document play video starting 359 follow transcript 359 expected account word w precisely given denominator play video starting 48 follow transcript 408 ratio basically comparing actual count play video starting 415 follow transcript 415 actual count word document expected count given product word fact following distribution clutch counter larger expected counter part ratio larger play video starting 437 follow transcript 437 thats actually interesting interpretation right natural intuitive makes lot sense play video starting 445 follow transcript 445 advantage probabilistic reasoning made explicit assumptions know precisely logarithm probabilities play video starting 5 follow transcript 500 formula intuitively makes lot sense tfidf weighting documenting play video starting 59 follow transcript 509 lets look dirichlet prior smoothing similar case jm smoothing case smoothing parameter mu thats different lambda format looks similar form function looks similar play video starting 534 follow transcript 534 linear operation play video starting 538 follow transcript 538 compute ratio find ratio equal play video starting 546 follow transcript 546 whats interesting comparison comparing actual count expected account world sampled meal worlds collection world probability note interesting dont docking lens lighter jms model right course plugged part play video starting 615 follow transcript 615 wonder docking lens interestingly docking lens alpha sub d plugged part result following function sum match query words play video starting 636 follow transcript 636 queer query time frequency play video starting 641 follow transcript 641 interpret element document vector longer single dot product right play video starting 650 follow transcript 650 part know n name query right means score function take sum query words adjustment score based document play video starting 711 follow transcript 711 clear documents lens modulation lens denominator longer document lower weight tf idf time form formula different previous jms intuitively implements tfidf waiting document lens rendition form function dictated probabilistic reasoning assumptions made disadvantages approach theres guarantee theres form formula actually work look geo function tfidf waiting document lens rendition example unclear sublinear transformation unfortunately logarithm function right sublinear transformation intentionally means theres guarantee end way suppose dont logarithm theres sublinear transformation discussed formula going work thats example gap formal model relevance model subject motion tied users play video starting 850 follow transcript 850 doesnt mean fix example imagine did logarithm right take risk going add add logarithm mean function longer proper risk model consequence modification longer predictable play video starting 915 follow transcript 915 thats example pm45 remains competitive open channel public risk models arrive better model pm25 play video starting 930 follow transcript 930 particular query derive model work consistently better dm 25 currently play video starting 940 follow transcript 940 interesting open question play video starting 943 follow transcript 943 summarize part weve talked two smoothing methods jelinekmercer fixed coefficient linear interpolation dirichlet prior add pseudo counts word adaptive interpolation coefficient larger shorter documents play video starting 105 follow transcript 1005 cases smoothing methods able reach retrieval function assumptions clearly articulate heuristic play video starting 1019 follow transcript 1019 explaining results show retrieval functions effective comparable bm 25 pm lens adultation major advantage probably smaller dont lot heuristic design play video starting 1040 follow transcript 1040 end naturally implemented tfidf weighting doc length normalization play video starting 1046 follow transcript 1046 functions precise ones smoothing parameter case course set smoothing parameter methods estimate parameters play video starting 1059 follow transcript 1059 overall shows probabilistic model follow different strategies vector space model end end uhwith retrievable functions look similar vector space model advantages having assumptions clearly stated form dictated probabilistic model concludes discussion query likelihood probabilistic model lets recall assumptions made order derive functions lecture basically made four assumptions listed assumption relevance modeled query likelihood play video starting 1149 follow transcript 1149 second assumption med query words generated independently allows decompose probability query product probabilities old words query play video starting 123 follow transcript 1203 third assumption made word document late probability proportional probability collection thats smoothing collection ama model finally made two assumptions smoothing jm smoothing dirichlet prior smoothing make four assumptions choice take form retrieval function earlier fortunately function nice property implements tfidf weighting document machine functions work sense functions heuristic compared vector space model play video starting 1250 follow transcript 1250 extensions basic model find discussion reference end lecture play video starting 134 follow transcript 1304 music
5 overview weeks lessons learn feedback techniques information retrieval rocchio feedback method vector space model mixture model feedback language models learn web search engines work web crawling web indexing links web pages leveraged score web pages time module take approximately 4 hours dedicated time complete videos assignments activities activities module listed assignments bold activity estimated time required 5 video lectures 2 hours 5 graded quiz 1 hour programming assignment 23 30 mins goals objectives actively engage learning experiences module able explain similarity differences three different kinds feedback relevance feedback pseudorelevance feedback implicit feedback explain rocchio feedback algorithm works explain kullbackleibler kl divergence retrieval function generalizes query likelihood retrieval function explain basic idea mixture model feedback explain main general challenges creating web search engine explain web crawler factors considered designing web crawler explain basic idea google file system gfs explain basic idea mapreduce build inverted index parallel explain links web leveraged improve search results explain pagerank algorithm works guiding questions develop answers following guiding questions completing readings working assignments relevance feedback pseudorelevance feedback implicit feedback rocchio work ensure original query terms sufficiently large weights feedback kldivergence retrieval function related query likelihood retrieval function basic idea twocomponent mixture model feedback general challenges building web search engine crawler implement simple crawler focused crawling incremental crawling pages higher priority recrawling incremental crawling inverted index doesn’t fit single machine what’s basic idea google file system gfs mapreduce work two key functions programmer needs implement programming mapreduce framework mapreduce build inverted index parallel anchor text useful improving search accuracy hub page authority page web pages tend receive high scores pagerank interpret pagerank perspective random surfer “walking” web exactly compute pagerank scores hits algorithm work additional readings resources c zhai s massung text data management analysis practical introduction information retrieval text mining acm book series morgan claypool publishers 2016 chapters 7 10 key phrases concepts keep eyes open following key terms phrases complete readings interact lectures topics help better understand content module relevance feedback pseudorelevance feedback implicit feedback rocchio feedback kullbackleiber divergence kldivergence retrieval function mixture language model scalability efficiency spams crawler focused crawling incremental crawling google file system gfs mapreduce link analysis anchor text pagerank tips success recommend following review video lectures number times gain solid understanding key questions concepts introduced possible tips suggestions peers class learning community help learn grow way helping address questions peers pose engaging we’ll learn better it’s good idea refer video lectures chapter readings weve read reference responses appropriate critique information presented take notes read materials watch lectures taking notes interacting material find easier remember understand notes you’ll find it’s easier complete assignments ahead favor take notes getting giving help getgive help following means learner help center opens new tab find information regarding specific technical problems example technical problems error messages difficulty submitting assignments problems video playback find answer documentation report problem coursera staff clicking contact link available topics page learner help center content issues opens new tab forum report errors lecture video content assignment questions answers assignment grading text links course pages content course materials university illinois staff community tas monitor forum respond issues mark completed item completed dislike report issue
play video starting follow transcript 000 sound lecture feedback text retrieval play video starting 12 follow transcript 012 lecture continue discussion text retrieval methods play video starting 18 follow transcript 018 particular going talk feedback text retrieval play video starting 24 follow transcript 024 diagram shows retrieval process play video starting 30 follow transcript 030 user type query play video starting 37 follow transcript 037 query retrieval engine search engine engine return results results issued user play video starting 49 follow transcript 049 user results user actually make judgements example user says good document useful good called relevance judgment relevance feedback weve got feedback information user based judgements useful system knowing exactly interesting user feedback module take input document collection try improve ranking typically involve updating query system render results accurately user called relevance feedback feedback based relevance judgements made users judgements reliable users generally dont make extra effort side involves extra effort user play video starting 157 follow transcript 157 theres form feedback called pseudo relevance feedback blind feedback called automatic feedback case user gotten inaudible fact dont invoke users theres user involved play video starting 214 follow transcript 214 simply assume top rank documents relevant lets say assumed top 10 relevant play video starting 225 follow transcript 225 assume documents learn improve query play video starting 234 follow transcript 234 wonder help simply assume top rank documents imagine top rank documents actually similar relevant documents relevant look relevant documents possible learn related terms query set fact recall talked language model analyze association learn related words word computer play video starting 39 follow transcript 309 did computer retrieve documents contain computer imagine query computer result documents contain computer take top n results match computer going count terms set going background language model terms frequent set frequent collection make contrast two find related terms word computer related words added original query expand query help bring documents dont necessarily match computer match words program software effective improving search result play video starting 418 follow transcript 418 course pseudorelevancy values completely unreliable arbitrarily set cut theres called implicit feedback case involve users dont ask users make judgments going observe user interacts search results case look clickthroughs user clicked user viewed user skipped user viewed play video starting 450 follow transcript 450 clue document useful user assume going snippet document text thats actually user actual document entry link saying web search broken doesnt matter user tries fetch document displayed text assume displayed text probably relevant interesting learn information called interesting feedback information update query important technique modern think google bing collect lot user activities serving observe documents click documents skip information valuable improve search engine play video starting 559 follow transcript 559 summarize talked three kinds feedback relevant feedback user makes explicit judgements takes user effort judgment information reliable talk pseudo feedback assume top brand marking relevant dont involve user actually return results user play video starting 624 follow transcript 624 third implicit feedback clickthroughs play video starting 629 follow transcript 629 involve users user doesnt make explicitly fault make judgement music
play video starting follow transcript 000 sound lecture feedback vector space model play video starting 12 follow transcript 012 lecture continue talking feedback text retrieval particularly going talk feedback vector space model play video starting 23 follow transcript 023 discussed case feedback task text retrieval system removed examples improved retrieval accuracy positive examples documents assume relevant charged relevant documents viewed users negative examples documents known nonrelevant documents skipped users play video starting 55 follow transcript 055 general method vector space model feedback modify query vector play video starting 14 follow transcript 104 place query vector better position make accurate play video starting 110 follow transcript 110 mean exactly think query vector mean vector elements general mean add new terms weight old terms assign weights new terms play video starting 129 follow transcript 129 result general query terms call query expansion play video starting 137 follow transcript 137 effective method vector space model feedback called rocchio feedback actually proposed decades ago play video starting 147 follow transcript 147 idea simple illustrate idea two dimensional display documents collection query vector query vector center documents query back narrative function find similar documents basically circle documents basically topranked documents process relevant documents relevant documents example relevant minuses negative documents play video starting 234 follow transcript 234 goal trying move query back position improve retrieval accuracy looking diagram think move query vector improve retrieval accuracy intuitively move query vector play video starting 258 follow transcript 258 think pause video play video starting 32 follow transcript 302 think picture realize order work case query vector close positive vectors possible means ideally place query vectors move query vector closer point play video starting 326 follow transcript 326 exactly point relevant documents rank top center relevant documents right draw circle youll relevant documents means move query vector centroid relevant document vectors play video starting 355 follow transcript 355 basically idea rocchio course consider centroid negative documents move away negative documents match talking moving vector closer vec away vectors means formula original query vector average basically centroid vector relevant documents take average vectors computing centroid vectors similarly average nonrelevant document essentially nonrelevant documents three parameters alpha beta gamma controlling amount movement add two vectors moving query vector closer centroid play video starting 53 follow transcript 503 add subtracted part move query vector away centroid main idea rocchio feedback done new query vector score documents new query vector reflect move original query vector relevant centroid vector away nonrelevant value play video starting 545 follow transcript 545 okay lets take look example example weve earlier deemed display actual documents showed vector representation documents five documents play video starting 64 follow transcript 604 read documents right theyre displayed red term vectors assumed weights lot terms zero weights course negative arguments two rocchio method compute centroid category lets look centroid vector positive documents simply easy add corresponding element thats take average going add corresponding elements take average end average vector two centroid two play video starting 710 follow transcript 710 lets look centroid negative documents basically going take average three elements corresponding elements three vectors end play video starting 726 follow transcript 726 rocchio feedback method going combine original query vector lets combine thats basically play video starting 738 follow transcript 738 parameter alpha controlling original query times weight thats beta control inference positive centroid weight thats 15 comes right goes negative weight gamma way come course negative centroid exactly terms term play video starting 822 follow transcript 822 new vector play video starting 825 follow transcript 825 going new query vector rank documents imagine happen right movement matches red documents better moved vector closer going penalize black documents non relevent documents precisely wanted feedback play video starting 850 follow transcript 850 course apply method practice potential problem play video starting 858 follow transcript 858 original query four terms zero play video starting 96 follow transcript 906 query explaining merging times non zero weights calculation involve terms play video starting 918 follow transcript 918 practice truncate matter retain terms highest weights play video starting 927 follow transcript 927 lets talk method practice play video starting 930 follow transcript 930 mentioned theyre truncated vector consider small number words highest weights centroid vector efficiency concern play video starting 941 follow transcript 941 negative examples nonrelevant examples tend useful especially compared positive examples play video starting 950 follow transcript 950 think play video starting 955 follow transcript 955 reason negative documents tend distract query directions take average doesnt tell exactly moving positive documents tend clustered point consistent direction means dont negative examples note cases difficult queries results negative negative feedback useful play video starting 1027 follow transcript 1027 thing avoid overfitting means keep relatively high weight original query terms sample feedback relatively small sample dont overly trust small sample original query terms important terms heightened user user decided terms important order prevent overfitting drifting prevent topic drifting due bias feed backing symbols generally keep pretty high weight original terms safe play video starting 1115 follow transcript 1115 especially true pseudo relevance feedback method relevance feedback pseudorelevance feedback case pseudofeedback prime beta set smaller value relevant examples assumed relevant theyre reliable relevance feedback case relevance feedback obviously larger value parameters set empirically play video starting 1145 follow transcript 1145 rocchio method usually robust effective popular method feedback music
play video starting follow transcript 000 sound lecture feedback language modeling approach play video starting 12 follow transcript 012 lecture continue discussion feedback text retrieval particular going talk feedback language modeling approaches play video starting 23 follow transcript 023 derive query likelihood ranking function making various assumptions play video starting 30 follow transcript 030 basic retrieval function formulas worked think feedback information bit awkward query likelihood perform feedback lot times feedback information additional information query assume query generated assembling words language model query likelihood method unnatural sample words form feedback documents result researchers proposed way generalize query likelihood function called kullbackleibler divergence retrieval model play video starting 115 follow transcript 115 model actually going make query likelihood retrieval function closer vector space model form language model regarded generalization query likelihood sense cover query likelihood special case play video starting 138 follow transcript 138 case feedback achieved simply query model estimation updating similar rocchio updates query vector play video starting 150 follow transcript 150 lets kldivergence retrieval model top query likelihood retrieval function play video starting 25 follow transcript 205 kldivergence called cross entropy retrieval model basically generalize frequency part language model basically difference given probabilistic model characterize user looking versus count query words play video starting 235 follow transcript 235 difference allows plug various different ways estimate estimated different ways feedback information called kldivergence interpreted matching kldivergence two distributions query model denoted distribution document language model smooth collection language model course going talk detail youll find references called cross entropy fact ignore terms kldivergence function end having actually cross entropy terms information theory play video starting 334 follow transcript 334 purposes two formulas look identical probability word given query language model play video starting 352 follow transcript 352 sum words document nonzero probability query model generalization sum matching query words play video starting 49 follow transcript 409 easily recover query likelihood retrieval function simply setting query model relative frequency word query play video starting 423 follow transcript 423 easy plug eliminate query length constant exactly equivalence thats kldivergence model regarded generalization query likelihood cover query likelihood special case allow play video starting 450 follow transcript 450 kldivergence model feedback picture shows estimate document language model estimate query language model compute kldivergence denoted d play video starting 59 follow transcript 509 basically means exactly vector space model compute vector document compute vector query compute distance vectors special forms probability distributions play video starting 527 follow transcript 527 results find feedback documents lets assume positive documents consider kinds documents rocchio going compute language model called feedback language model going vector computing centroid vector rocchio model combined original query model linear interpolation give update model rocchio parameter alpha control amount feedback set zero essentially feedback set full feedback ignore original query generally desirable right absolutely sure lot relevant documents query terms important play video starting 631 follow transcript 631 course main question compute theta f big question rest easy talk approaches approaches course approach based generative model im going show works generative mixture model picture shows model feedback model estimate play video starting 658 follow transcript 658 basis feedback documents lets say observing positive documents clicked documents users random documents judged users simply top ranked documents assume relevant play video starting 714 follow transcript 714 imagine compute centroid documents language model approach simply assume documents generated language model did normalize word frequency word distribution play video starting 736 follow transcript 736 question distribution good feedback imagine top ranked word think play video starting 748 follow transcript 748 words common words language model top ranked words actually common words good feedback adding lot words query interpolate original query model play video starting 88 follow transcript 808 good particular trying rid common words actually way background language model case learning associations words words related word computer way going talk approach principled approach case going say common words documents belong topic model right play video starting 850 follow transcript 850 assume words generated background language model generate words example maximum likelihood estimate note words generated model model forced assign high probabilities word occurs frequently note order reduce probability model model help explain word case appropriate background language model achieve goal model assign high probabilities common words play video starting 943 follow transcript 943 approach assume machine generating words work follows source control imagine flip coin decide distribution probability lambda coin shows head going background language model going sample word model probability 1 minus lambda going decide known topic model estimate going generate word make assumption thing model call mixture model two distributions mixed actually dont know distribution play video starting 1035 follow transcript 1035 think thing model play video starting 1042 follow transcript 1042 ask words give word random manner course word show depend distribution distribution addition depend lambda say lambda high going background distribution different words say lambda small going parameters model youre thinking way basically exactly did going maximum likelihood estimator adjust model estimate parameters basically going adjust parameter best explain data difference asking model known explain going ask model mixture model explain data got help background model doesnt assign high probabilities words result assign higher probabilities words common having high probability common play video starting 1211 follow transcript 1211 theyre common high probabilities maximum likelihood estimate method rare dont help background model result topic model assign high probabilities high probability words topic model common rare background play video starting 1243 follow transcript 1243 basically bit idea weighting allow achieve effect removing topic words meaningless feedback play video starting 1256 follow transcript 1256 mathematically compute likelihood local likelihood feedback documents play video starting 136 follow transcript 1306 note parameter lambda assume lambda denotes noise feedback document going lets say set parameter lets say 50 words noise 90 noise assumed fixed assume fixed probabilities parameters simple unigram language model n parameters n number words likelihood function look play video starting 1342 follow transcript 1342 similar global likelihood function logarithm theres sum sum consider two distributions depend lambda thats form play video starting 142 follow transcript 1402 mathematically function theta unknown variables function values known guy play video starting 1415 follow transcript 1415 probability distribution maximize log likelihood idea maximum likelihood estimate mathematical problem solve optimization problem essentially try theta values find gives thing maximum probability welldefined math problem play video starting 1440 follow transcript 1440 done obtain theta f interpolated original query model feedback play video starting 1450 follow transcript 1450 examples feedback model learned web document collection pseudofeedback top ten documents mixture model query airport security retrieve ten documents web database course pseudofeedback going feed mixture model ten document set play video starting 1521 follow transcript 1521 words learned approach probability word given feedback model cases play video starting 1531 follow transcript 1531 cases highest probability words relevant words query airport security example query words show high probabilities case naturally occur frequently top ranked documents beverage alcohol bomb terrorist relevant topic combined original query help accurately documents help bring documents mention words example airport bomb example play video starting 1618 follow transcript 1618 pseudofeedback works shows model works picks related words query whats interesting look two tables compare youll case lambda set small value common words means dont background model remember lambda confuses probability background model generate text dont rely background model topic model account common words set lambda high value background model explain words theres burden expanding common words feedback documents topic model result topic model discriminative contains relevant words common words play video starting 1721 follow transcript 1721 added original query achieve feedback play video starting 1728 follow transcript 1728 summarize lecture talked feedback language model approach general feedback learn examples examples assumed examples pseudoexamples assume top ten documents assumed relevant based user interactions feedback based clickthroughs implicit feedback talked three major feedback scenarios relevance feedback pseudo feedback implicit feedback talked rocchio feedback vector space model query model estimation feedback language model briefly talked mixture model basic idea play video starting 1819 follow transcript 1819 methods example relevance model effective model estimating query model read methods references play video starting 1832 follow transcript 1832 listed end lecture two additional readings book systematic review discussion language models information retrieval second important research paper thats relevance based language models effective way computing query model music
play video starting 7 follow transcript 007 lecture web search play video starting 11 follow transcript 011 lecture going talk important applications text retrieval web search engines lets look general challenges opportunities web search informational retrieval algorithms developed web born web born created best opportunity apply algorithms major application problem care naturally extensions classical search algorithms address new challenges encountered web search general challenges scalability challenge handle size web ensure completeness coverage information play video starting 13 follow transcript 103 serve users quickly answering queries thats major challenge web born scale search relatively small second problem theres quality information spams third challenge dynamics web new pages constantly create pages updated quickly makes harder keep indexed fresh challenges solve order deal high quality web searching play video starting 144 follow transcript 144 hand interesting opportunities leverage search results additional heuristics example play video starting 155 follow transcript 155 links leverage improve scoring talked vector space model general algorithms play video starting 25 follow transcript 205 applied search applications thats advantage hand dont take advantage special characteristics pages documents specific applications web search web pages linked obviously linking leverage challenges opportunities new techniques developed web search due web search parallel indexing searching address issue scalability particular googles imaging map reduce influential helpful aspect second techniques developing addressing problem spams spam detection prevent spam pages ranked high play video starting 34 follow transcript 304 techniques achieve robust ranking going lot signals rank pages easy spam search engine particular trick third line techniques link analysis techniques allow improve results leveraging extra information general web searching going multiple features ranking link analysis exploring kinds crawls layout anchor text describes link page heres picture showing basic search engine technologies basically web left user right side going help user access web information component crawler crawl pages second component indexer take pages create inverted index play video starting 410 follow transcript 410 third component retriever inverted index answer users query talking users browser search results given user browser show results allows user interact web going talk components going talk crawler called spider software robot crawling pages web build toy crawler relatively easy start set seed pages fetch pages web parse pages figure new links add priority que explore additional links able real crawler actually tricky complicated issues deal example robustness server doesnt respond theres trap generates dynamically generated webpages attract crawler keep crawling side fetch dynamic generated pages results issue crawling courtesy dont overload particular server crawling requests respect robot exclusion protocol handle different types files images pdf files kinds formats web consider url extension cgi scripts internal references javascripts page create challenges ideally recognize redundant pages dont duplicate pages finally interested discover hidden urls urls linked page truncate url shorter path able additional pages play video starting 627 follow transcript 627 major crawling strategies general breadthfirst common naturally balances sever load keep probing particular server requests play video starting 642 follow transcript 642 parallel crawling natural task easy parallelize variations crawling task interesting variation called focused crawling case going crawl pages particular topic example pages automobiles right typically going start query query results major search engine start results gradually crawl channel crawling find new channels people created people probably creating new pages time challenging new pages actually linked old pages probably find recrawling old pages interesting challenges solved finally face scenario incremental crawling repeated crawling right lets say build web search engine crawl lot data web cracked data future crawl updated pages general dont recrawl right necessary play video starting 816 follow transcript 816 case goal minimize resource overhead minimum resources update pages play video starting 827 follow transcript 827 actually interesting research question open research question arent standard algorithms established task play video starting 847 follow transcript 847 general imagine learn past experience play video starting 853 follow transcript 853 two major factors consider page updated frequently quote page page static page hasnt changed months probably dont recrawl everyday unlikely changed frequently hand sports score page gets updated frequently recrawl multiple times factor consider page frequently accessed users means high utility page important ensure page refresh compared page fetched users page changed lot probably necessary crawl page least urgent maintain freshness frequently accessed page users summarize web search important applications text retrieval new challenges particularly scalability efficiency quality information new opportunities particularly rich link information layout play video starting 1017 follow transcript 1017 crawler essential component web search applications general find two scenarios initial crawling complete crawling play video starting 1030 follow transcript 1030 web general search engine focused crawling target type pages play video starting 1038 follow transcript 1038 scenario thats incremental updating crawl data incremental crawling case optimize resource try minimum resource inaudible play video starting 1054 follow transcript 1054 music
play video starting follow transcript 000 sound play video starting 7 follow transcript 007 lecture web indexing play video starting 11 follow transcript 011 lecture continue talking web search going talk create web scale index play video starting 24 follow transcript 024 crawl web weve got lot web pages step indexer create inverted index play video starting 36 follow transcript 036 general information retrieval techniques creating index talked previous lectures new challenges solve web scale indexing two main challenges scalability efficiency index large actually fit single machine single disk store data virtual machines play video starting 16 follow transcript 106 data large beneficial process data parallel produce index quickly address challenges google made number innovations google file system thats general file system help programmers manage files stored cluster machines play video starting 132 follow transcript 132 second mapreduce general software framework supporting parallel computation play video starting 138 follow transcript 138 hadoop known open source implementation mapreduce applications play video starting 150 follow transcript 150 architecture google file system play video starting 153 follow transcript 153 uses simple centralized management mechanism manage specific locations files maintains file namespace look table know exactly file stored play video starting 211 follow transcript 211 application client talk gfs master obtains specific locations files process play video starting 222 follow transcript 222 gfs file obtained specific location files application client talk specific servers data actually sits directly avoid involving node network play video starting 246 follow transcript 246 file system stores files machines system great fixed sizes chunks data files separated play video starting 3 follow transcript 300 chunks chunk 64 mb pretty big thats appropriate large data processing chunks replicated ensure reliability programmer doesnt worry taken care file system application perspective programmer normal file programmer doesnt know exactly stored invoke high level operators process file play video starting 339 follow transcript 339 feature data transfer directly application chunk servers efficient sense play video starting 351 follow transcript 351 top google file system google proposed mapreduce general framework parallel programming useful support task building inverted index play video starting 46 follow transcript 406 framework play video starting 412 follow transcript 412 hiding lot lowlevel features program result programmer make minimum effort create application run large cluster parallel play video starting 428 follow transcript 428 low level details hidden framework specific network communications load balancing task executed details hidden programmer play video starting 447 follow transcript 447 nice feature built fault tolerance server broken server tasks finished mapreduce mapper know task done automatically dispatches task servers job program doesnt worry heres mapreduce works input data separated number key value pairs exactly value depend data actually fairly general framework allow partition data different parts part processed parallel play video starting 537 follow transcript 537 key value pair send map function program right map function course play video starting 545 follow transcript 545 map function process key value pair generate number key value pairs course new key usually different old key thats given map input key value pairs output map function outputs map functions collected play video starting 612 follow transcript 612 sorting based key result values associated key grouped weve got pair key separate values attached key play video starting 631 follow transcript 631 reduce function play video starting 636 follow transcript 636 course reduce function handle different key send output values multiple reduce functions handling unique key play video starting 652 follow transcript 652 reduce function process input key set values produce set key values output output values corrected form final output play video starting 712 follow transcript 712 general framework mapreduce programmer needs write map function reduce function actually taken care mapreduce framework program needs minimum work framework input data partitioned multiple parts processing parallel map process reach reduced stage reduced im inaudible process play video starting 755 follow transcript 755 different keys associated values parallel achieves play video starting 85 follow transcript 805 achieves purpose parallel processing large data set lets take look simple example thats word counting play video starting 816 follow transcript 816 input containing words output generate number occurrences word word count play video starting 828 follow transcript 828 know counting useful example assess popularity word large collection useful achieving factor idf wading search play video starting 842 follow transcript 842 solve problem natural thought task done parallel simply counting different parts file parallel end combine counts thats precisely idea mapreduce play video starting 92 follow transcript 902 parallelize lines input file play video starting 97 follow transcript 907 specifically assume input map function play video starting 914 follow transcript 914 key value pair represents line number string line line example key word word four words line key value pair map function map function count words line play video starting 941 follow transcript 941 case course four words world gets count output slide map function map function simple look pseudocode looks right side simply needs iterate words line collect function play video starting 109 follow transcript 1009 means send word count collector collector try sort key value pairs different map functions right function simple programmer specifies function way process part data play video starting 1031 follow transcript 1031 course second line handled different map function produce single output okay output map functions send collector collector internal grouping sorting stage collected match pairs pair word count line pairs sort based key word collect counts word bye play video starting 119 follow transcript 1109 similarly words hadoop hello word attached number values number counts play video starting 1120 follow transcript 1120 counts represent occurrences solve word different lights got new pair key set values pair fed reduce function reduce function finish job counting total occurrences word ready got puzzle accounts needs simply add reduce function simple counter iterate words youll array accumulate accounts right finally output p proto account thats precisely output program play video starting 1212 follow transcript 1212 ready similar building invert index think output index got dictionary basically got count whats missing document specific frequency counts words documents modify slightly actually able index parallel heres way case assume input map function pair key denotes document id value denoting screen document words document map function similar word campaign example simply groups counts word document generate set key value pairs key word value count word document plus document id easily add document id later inverted index keep formation map function keep track reduce function later similarly document d2 processed way end sorting mechanism group key java associated documents match key documents java occurred play video starting 144 follow transcript 1404 counts counts java documents collected fed reduce function reduce function got input looks inverted index entry word documents contain word frequencies word documents simply concatenate play video starting 1437 follow transcript 1437 continuous chunk data done written file system basically reduce function going minimal work play video starting 1449 follow transcript 1449 pseudocode inaudible thats construction two functions procedure map procedure reduce programmer specify two functions program top map reduce basically described case map going count occurrences word associativearray output counts document id reduce function hand simply concatenates input given put single entry key simple mapreduce function allow construct inverted index large scale data processed different machines program doesnt take care details play video starting 1612 follow transcript 1612 parallel index construction web search play video starting 1620 follow transcript 1620 summarize web scale indexing requires new techniques standard traditional indexing techniques mainly store index multiple machines usually done filing system google file system file system secondly requires creating index parallel large takes long time create index documents parallel faster done mapreduce framework play video starting 1657 follow transcript 1657 note gfs mapreduce frameworks general support applications play video starting 177 follow transcript 1707 music
play video starting follow transcript 000 sound lecture link analysis web search lecture going talk web search particularly focusing link analysis results improve search main topic lecture look ranking algorithms web search play video starting 32 follow transcript 032 previous lecture talked create index index improve ranking pages web standard ir models applied fact important building blocks improve supporting web search arent sufficient mainly following reasons web tend different information needs example people search webpage entry page different traditional library search people primarily interested collecting literature information query called navigational queries purpose navigate particular type page queries benefit link information secondly documents additional information web pages web format lot clues layout title link information provided opportunity extra context information document improve scoring finally information quality varies lot means consider factors improve range algorithm give robust way rank pages making harder spammer manipulate signal improve ranking page play video starting 210 follow transcript 210 result people made number major extensions ranking algorithms play video starting 216 follow transcript 216 line exploit links improve scoring play video starting 223 follow transcript 223 thats main topic lecture play video starting 226 follow transcript 226 people proposed algorithms exploit loudest implicit feedback information form click throughs thats course category feedback techniques machine general web search ranking algorithms based machine learning algorithms combine kinds features based standard virtual models bm25 talked inaudible score different parts documents additional features based content matching link information useful additional scoring signals lets look links detail web snapshot part web lets say links link different pages case look center description link thats pointing document right side description text called anchor text play video starting 344 follow transcript 344 think text actually useful provides extra description page points example wants bookmark amazoncom page person say biggest online bookstore link amazon right description similar user type query box looking page thats useful managing pages suppose types query online bookstore biggest online bookstore right query match anchor text page actually provides evidence matching page thats pointed amazon entry page match anchor text describes anchor page actually provides good evidence elements page pointed anchor text useful look bottom part picture patterns links links indicate utility document example right side youll page received inlinks means pages pointing page shows page useful play video starting 521 follow transcript 521 left side page points pages director page allow actually lot pages play video starting 532 follow transcript 532 call case authority page second case half page means link information help intuit extra text matching additional scores webpage characterize likely page hub likely page authority play video starting 555 follow transcript 555 people course proposed ideas leverage link information googles pagerank main technique early days good example algorithm capture page popularity basically score authority intuitions links citations literature think page pointing page similar paper citing paper course page cited assume page useful general play video starting 635 follow transcript 635 thats good intuition play video starting 638 follow transcript 638 pagerank essentially take advantage intuition implement principal approach intuitively essentially citation counting link counting improves simple idea two ways consider indirect citations means dont look links look pages pointing pages lot inlinks means lot sense credit pages pointing pointed pages dont inlinks dont thats idea getting indirect citation right understand idea looking research papers youre cited lets say ten papers ten papers workshop papers papers influential right play video starting 749 follow transcript 749 youve got ten inlinks thats good cited ten papers attracted lot citations play video starting 81 follow transcript 801 case consider indirect links page idea good pseudo citations play video starting 813 follow transcript 813 assume basically page having number zero pseudo citation count essentially trying imagine virtual links link pages actually pseudo citations play video starting 834 follow transcript 834 reason allow solve problem elegantly linear algebra technique think best way understand pagerank think computer probability random surfer visiting webpage music
play video starting follow transcript 000 music play video starting 9 follow transcript 009 lets take look detail random surfing model page assume random surfer page visit small graph thats course simplification complicated web lets say four documents d1 d2 d3 d4 lets assume random surfer random walker pages random surfer decide randomly jumping page follow link visit page play video starting 56 follow transcript 056 random surfer d1 play video starting 11 follow transcript 101 probability random surfer follow links two outlinks pointing d3 pointing d4 random surfer pick two reach d3 d4 assumes random bore random surfing decide ignore actual links simply randomly jump page web able reach pages theres link actually page play video starting 146 follow transcript 146 assume random surfing model imagine random surfer surfing ask question likely average surfer actually reach particular page d1 d2 d3 thats average probability visiting particular page probability precisely page ranker computes page rank score document average probability surfer visits particular page intuitively basically capture inlink account page lot inlinks higher chance visited opportunities having server follow link come page play video starting 241 follow transcript 241 random surfing model actually captures id counting inlinks note considers interacting links page point lot inlinks mean random surfer likely reach increase chance visiting nice way capture indirect direct links mathematically compute problem order take look problem computing lets take look transition metrics metrics values indicating likely random surfer page rule stands starting page example rule indicate probability going four pages d1 2 non 0 entries 12 look graph d1 pointing d3 d4 link d1 d2 weve got 0s 2 columns 05 d3 d4 general m matrix m sub ij probability going di dj obviously rule values sum 1 surfer precisely pages transition metric compute probability surfer visiting page play video starting 444 follow transcript 444 look surf model basically play video starting 450 follow transcript 450 compute probability reaching page follows left hand side probability play video starting 52 follow transcript 502 visiting page dj time plus 1 time point right hand side equation involves probability page di time t play video starting 521 follow transcript 521 subscript t indicates thats probability server document time t equation basically captures two possibilities reaching dj time t plus 1 two possibilities random surfing following link explained play video starting 553 follow transcript 553 part captures probability random surfer reach page following link random surfer chooses strategy probability 1 minus alpha assume factor 1 minus alpha main party realist sum possible pages surfer time t play video starting 623 follow transcript 623 n pages sum possible n pages sum product two probabilities probability surfer di time t thats p sub t di transition probability di dj order reach dj page surfer di time t follow link di dj probability probability di time t multiplied probability going page target page dj second part similar sum difference transition probability uniform transition probability 1 n part captures probability reaching page random jumping play video starting 732 follow transcript 732 form exactly allows pagerank essentially assumed smoothing transition matrix think 1 n coming transition matrix elements 1 n uniform matrix clearly essentially merge two parts form imagine theres different metrics thats combination m uniform metrics m 1 n sense pagerank uses idea smoothing ensuring theres zero entry transition matrix course time dependent calculation probabilities imagine compute average probabilities average probabilities probably sets file equation considering time index lets drop time index assume equal play video starting 842 follow transcript 842 give equations page equation look variables equations precisely n variables play video starting 858 follow transcript 858 basically means system play video starting 94 follow transcript 904 n equations n variables linear equations basically problem boils solve system equations show equations metric form vector p equals matrix transpose matrix multiplied vector play video starting 932 follow transcript 932 remember knowledge youve learned linear algebra realize precisely equation eigenvector multiply metrics vector value matter solved iterative algorithm play video starting 954 follow transcript 954 equations back basically taken previous slide youll relation page ran sports different pages iterative approach power approach simply start s randomly initialized vector p repeatedly update p multiplying metrics p factor play video starting 1031 follow transcript 1031 show concrete example assume alpha 02 example show slide original transition matrix includes graph actual links smoothing transition metrics uniform transition metrics representing random jumping combine liner interpolation form metric essentially imagine web looks captured theyre virtual links pages page initialize p vector computed updating p vector metrics multiplication play video starting 1136 follow transcript 1136 rewrite metric multiplication play video starting 1142 follow transcript 1142 terms individual equations youll play video starting 1146 follow transcript 1146 basically updating formula particular pages page score compute value updated score d1 basically multiply rule column take third product two give value value play video starting 1216 follow transcript 1216 updated vector started initial values guys revise scores generate new set scores updating formula play video starting 1233 follow transcript 1233 repeatedly apply converges matrix theres 0 values guaranteed converge play video starting 1244 follow transcript 1244 point pagerank scores pages typically sets initial values 1 n play video starting 1255 follow transcript 1255 interestingly updating formula interpreted propagating scores graph look formula compare graph imagine able interpret essentially propagating scores graph hope imagine values initialized pages values say thats 1 4 going metrics update scores look equation basically going combine scores pages possibly lead reaching page look pages pointing page combine score propagate sum scores document d1 look scores present probability random surfer visiting pages reached d1 propagation simulate probability reaching page d1 two interpretations matrix multiplication repeat multiplying metrics think propagating scores repeatedly web practice combination pagerank score actually efficient matrices fast ways transform equation avoid actually literally computing values elements play video starting 1456 follow transcript 1456 normalize equation give different form equation ranking pages change play video starting 156 follow transcript 1506 results potential problem zerooutlink problem play video starting 1510 follow transcript 1510 case page outlink probability pages sum 1 basically probability reaching page page sum 1 mainly lost probability mass assume theres probability surfer try follow links link follow possible solution simply page specific damping factor easily fix play video starting 1546 follow transcript 1546 basically thats say alpha 10 page outlink case surfer randomly jump page trying follow link play video starting 1559 follow transcript 1559 extensions pagerank extension topicspecific pagerank note pagerank doesnt merely query information make pagerank specific example top specific page rank simply assume surfer bored surfer randomly jumping page web hes going jump pages relevant query example query sports assume random jumping going randomly jump sports page buy pagerank topic sports know current theory sports specialized pagerank score rank documents better generic pagerank score pagerank channel applications network analysis particularly example social networks imagine compute pagerank scores social network link indicate friendship relation meaningful scores people music
play video starting follow transcript 000 sound talked pagerank way capture assault play video starting 14 follow transcript 014 looked examples hub interesting algorithm called hits going compute scores authorities hubs intuitions pages widely cited good authorities pages cite pages good hubs think interesting idea algorithm hits going reinforcement mechanism help improve scoring hubs authorities heres idea assumed good authorities cited good hubs play video starting 58 follow transcript 058 means cited pages good hub scores inquiry says youre authority similarly good hubs point good authorities pointed lot good authority pages hubs score increased literally reinforced pointed good hubs pointed good authorities good hubs score authority scores improved pointing good hub algorithms general applications graph network analysis briefly heres works construct matrix time going construct adjacent matrix going normalize values theres link theres 1 theres link thats 0 graph going define hubs score page sum authority scores pages appoints play video starting 28 follow transcript 208 hub depends pointing lot good authority pages thats says equation second equation define authorities page sum hub scores pages appoint good authority depend pages pointing good hubs forms iterative reinforcement mechanism play video starting 238 follow transcript 238 three questions written metrics format hub vector equal product adjacency matrix authority vector basically equation similarly second equation returned authority vector equal product transpose multiplied hub vector different ways expressing equations whats interesting look matrix form plug authority equation actually eliminated authority vector completely equations hubs scores play video starting 334 follow transcript 334 hubs score vector equal multiplied transpose multiplied hub score similarly transformation equation authorities frame problem computing hubs authorities actually eliminate obtain equation play video starting 359 follow transcript 359 difference page random matrix actually multiplication adjacency matrix transpose different page rank play video starting 411 follow transcript 411 mathematically computing problem hits typically initialize values lets say 1 values iteratively apply equations essentially equivalent multiply metrics transpose play video starting 434 follow transcript 434 arrows exactly pagerank adjacency matrix normalized iteration going normalize allow control growth value grow larger larger basically hits play video starting 458 follow transcript 458 computer hubs scores authority scores pages scores branching pagerank scores play video starting 59 follow transcript 509 summarize lecture link informations useful particular anchor text useful increase text representation page talk pagerank page anchor two major link analysis algorithms generate scores web pages ranking function note pagerank hits general algorithms applications analyzing graphs networks music
6 overview weeks lessons learn machine learning combine multiple scoring factors optimize ranking documents web search learning rank learn techniques recommender systems called filtering systems contentbased recommendationfiltering collaborative filtering chance review text retrieval content time module take approximately 7 hours dedicated time complete videos assignments activities activities module listed assignments bold activity estimated time required 6 video lectures 2 hours 6 graded quiz 1 hour programming assignment 24 4 hours goals objectives actively engage learning experiences module able explain extend retrieval system perform contentbased information filtering recommendation explain linear utility function evaluate information filtering system explain basic idea collaborative filtering explain memorybased collaborative filtering algorithm works guiding questions develop answers following guiding questions completing readings working assignments contentbased information filtering linear utility function evaluate filtering system set coefficients linear utility function extend retrieval system perform contentbased information filtering explorationexploitation tradeoff betagamma threshold learning algorithm work basic idea collaborative filtering memorybased collaborative filtering algorithm work “cold start” problem collaborative filtering additional readings resources c zhai s massung text data management analysis practical introduction information retrieval text mining acm book series morgan claypool publishers 2016 chapters 10 section 104chapters 11 key phrases concepts keep eyes open following key terms phrases complete readings interact lectures topics help better understand content module contentbased filtering collaborative filtering betagamma threshold learning linear utility user profile explorationexploitation tradeoff memorybased collaborative filtering cold start tips success recommend following review video lectures number times gain solid understanding key questions concepts introduced possible tips suggestions peers class learning community help learn grow way helping address questions peers pose engaging we’ll learn better it’s good idea refer video lectures chapter readings weve read reference responses appropriate critique information presented take notes read materials watch lectures taking notes interacting material find easier remember understand notes you’ll find it’s easier complete assignments ahead favor take notes getting giving help getgive help following means learner help center opens new tab find information regarding specific technical problems example technical problems error messages difficulty submitting assignments problems video playback find answer documentation report problem coursera staff clicking contact link available topics page learner help center content issues opens new tab forum report errors lecture video content assignment questions answers assignment grading text links course pages content course materials university illinois staff community tas monitor forum respond issues mark completed item completed dislike report issue
play video starting follow transcript 000 music play video starting 7 follow transcript 007 lecture learning rank lecture going continue talking web search particular going talk machine learning combine different features improve ranking function play video starting 22 follow transcript 022 question address lecture combine features generate single ranking function optimize search results previous lectures talked number ways rank documents talked retrieval models bm25 query light code generate based course matching documents query talked link based approaches page rank play video starting 59 follow transcript 059 give additional scores help improve ranking play video starting 13 follow transcript 103 question combine features potentially features ranking useful ranking webpages improve accuracy improve robustness ranking function easy spammer perturb features promote page play video starting 127 follow transcript 127 general idea learning rank machine learning combine features optimize weights different features generate optimal ranking function play video starting 140 follow transcript 140 assume given query document pair q d define number features features vary content based features score document respect query retrieval function bm25 query light hold punitive commands machine pl2 etcetera link based score page rank score application retrieval models ink text page types descriptions links point page play video starting 229 follow transcript 229 clues document relevant play video starting 235 follow transcript 235 feature url tilde indicator home page entry page play video starting 248 follow transcript 248 features combined generate ranking function question course combine approach simply hypothesize probability document isnt relevant query function features hypothesize play video starting 311 follow transcript 311 probability relevance related features particular form function parameters parameters control influence different features final relevance course assumption assumption makes sense big question thats empirically evaluate function play video starting 345 follow transcript 345 hypothesizing relevance related features particular way combine features generate potential powerful ranking function robust ranking function naturally question estimate parameters know features higher weight features lower weight task training learning approach training data data charted users know relevant judgments know documents ranked high queries information based real judgments users approximated click information assume clicked documents better skipped documents clicked documents relevant skipped documents nonrelevant general fit hypothesize ranking function training data meaning try optimize retrieval accuracy training data adjust parameters play video starting 59 follow transcript 509 optimize performance functioning training data play video starting 516 follow transcript 516 terms measures map ndcg play video starting 520 follow transcript 520 training date look table tuples tuple three elements query document judgement looks relevance judgement talked evaluation retrieval systems music
play video starting follow transcript 000 music play video starting 6 follow transcript 006 lets take look specific method thats based regression different methods fact simplest methods explain idea simple play video starting 26 follow transcript 026 approach simply assume relevance document respect query related linear combination features xi denote feature xi q d feature features play video starting 55 follow transcript 055 assume features combined linear manner play video starting 13 follow transcript 103 feature controlled parameter beta parameter thats weighting parameter larger value mean feature higher weight contribute scoring function specific form function actually involves transformation probability relevance probability relevance know probability relevance range 0 1 play video starting 136 follow transcript 136 assumed scoring function related linear combination linear regression value linear combination easily 1 transformation map 0 1 range range real values verify play video starting 210 follow transcript 210 allows connect probability variance 0 1 linear combination arbitrary features rewrite probability function equation probability relevance play video starting 235 follow transcript 235 right hand side form form clearly nonnegative involves linear combination features clear value actually negative linear combination equation value large mean value small probability large thats expect basically mean combination gives high value documents likely irrelevant hypothesis necessarily best hypothesis simple way connect features probability relevance play video starting 340 follow transcript 340 combination function task estimate parameters function cache applied knowing beta values harder apply function play video starting 358 follow transcript 358 lets estimate beta values right lets take look simple example play video starting 48 follow transcript 408 example three features bm25 score document query pagerank score document depend query topicsensitive pagerank depend query general pagerank doesnt depend query bm25 score anchor test document feature values particular document query pair play video starting 441 follow transcript 441 case document d1 judgment says relevant play video starting 448 follow transcript 448 heres training instance feature values case relevant oversimplified case two instances sufficient illustrate point maximum likelihood estimator actually estimate parameters play video starting 513 follow transcript 513 basically going predict relevance status document based feature values given observed feature values play video starting 528 follow transcript 528 predict relevance course prediction function hypothesize probability relevance related features way going values beta predict relevance mean predicting relevance mean case d1 expression right give high values fact hope gave value close 1 relevant document play video starting 614 follow transcript 614 hand second case d2 hope value small right nonrelevant document lets mathematically expressed similar expressing probability document talking probability words talking probability relevance 1 0 whats probability document relevant feature values play video starting 654 follow transcript 654 expression plug xis thats exactly replaced xis specific values example 07 goes 011 goes different feature values combine particular way beta values unknown gives probability document relevant assume model okay maximize probability relevant document second document compute probability prediction nonrelevant mean compute 1 minus expression expression actually probability relevance compute nonrelevance relevance 1 minus probability relevance okay expression probability predicting two relevance values 1 0 equation probability observing 1 observing 0 play video starting 844 follow transcript 844 course probability depends beta values play video starting 850 follow transcript 850 goal adjust beta values make thing reach maximum make large possible means going compute beta parameter values maximize likelihood expression means look function going betas make large possible make large possible equivalent say make part small possible play video starting 930 follow transcript 930 precisely play video starting 934 follow transcript 934 training know beta values function welldefined beta values known completely specified new query new document simply compute features pair formula generate ranking score scoring function rank documents particular query thats basic idea learning rank music
play video starting follow transcript 000 sound munster learning algorithms regression based approaches generally attempt direct optimizer retrieval method play video starting 16 follow transcript 016 map ndcg play video starting 19 follow transcript 019 note optimization object function previous slide directly related retrieval measure play video starting 31 follow transcript 031 maximizing prediction zero dont necessarily optimize ranking documents imagine prediction bad lets say 05 middle zero two documents ranking wrong larger value e2 e1 play video starting 1 follow transcript 100 wont good retrieval perspective function bad contrast case predicted values 09 objective function error larger didnt order two documents correct thats actually better result new advanced approaches try correct problem course challenge optimization problem harder solve researchers posed solutions problem read references end know approaches learning ranked approaches general accounts applied ranking problems retrieval problem people recommender systems computational advertising summarization probably encounter applications play video starting 211 follow transcript 211 summarize lecture talked machine learning combine features ranking results play video starting 222 follow transcript 222 actually machine learning play video starting 225 follow transcript 225 information retrieval started decades ago example rocchio feedback approach talked earlier machine learning approach prior relevance feedback recent machine learning driven changes environment applications retrieval systems play video starting 252 follow transcript 252 freedom availability lot training data form critical available data lot useful knowledge relevance machine learning methods applied leverage list secondly freedom combining features features available web naturally improved scoring combining improve robustness ranking desired combating spams modern search engines machine learning techniques combine features optimize ranking major feature commercial engines google bing play video starting 356 follow transcript 356 topic learning rank active research topic community expect new results development years play video starting 412 follow transcript 412 additional readings give information learning rank works advanced methods play video starting 425 follow transcript 425 music
play video starting follow transcript 000 sound play video starting 7 follow transcript 007 lecture future web search play video starting 12 follow transcript 012 lecture going talk possible future trends web search intelligent information retrieval systems general play video starting 24 follow transcript 024 order improve accuracy search engine important consider special cases information particular trend specialized customized search engines called vertical search engines play video starting 46 follow transcript 046 vertical search engines expected effective current general search engines assume users special group users common information search engine customized ser users play video starting 17 follow transcript 107 customization possible personalization search personalized play video starting 115 follow transcript 115 better understanding users play video starting 120 follow transcript 120 restrictions domain advantages handling documents better understanding documents example particular words ambiguous domain bypass problem ambiguity play video starting 138 follow transcript 138 trend expect search engine able learn time lifetime learning lifelong learning course attractive means search engine selfimprove people search engine better better happening search engines learn inaudible feedback users quality search engine allows popular queries typed users allow better sort feature play video starting 221 follow transcript 221 third trend integration bottles information access search navigation recommendation filtering combined form fullfledged information management system beginning course talked push versus pull different modes information access modes combined play video starting 248 follow transcript 248 similarly pull mode querying browsing combined fact basically today inaudible search endings querying browsing clicking links weve got information recommended cases information recommended advertising future imagine seamlessly integrate system multimode information access convenient people play video starting 323 follow transcript 323 trend systems try searches support user tasks reason people search solve problem make decision perform task example consumers search opinions products order purchase product good product case beneficial support workflow purchasing product choosing product play video starting 356 follow transcript 356 era common search engines good support example look reviews buy click button shopping site directly done good task support tasks example researchers find realm literature site literature theres support finishing task writing paper general think opportunities wait following slides ill talking bit specific ideas thoughts hopefully help imagining new application possibilities relevant currently working general think intelligent system especially intelligent information system specified three nodes connect three triangle able specify information system call datauserservice triangle basically three questions ask serving data managing service play video starting 524 follow transcript 524 right help basically specify system play video starting 530 follow transcript 530 different ways connect depending connect different systems give examples top different kinds users left side different types data information bottom different service functions imagine connect different ways example connect web pages support search browsing thats web search right play video starting 62 follow transcript 602 connect uiuc employees organization documents enterprise documents support search browsing thats enterprise search connect scientist literature information kinds service search browsing alert new random documents mining analyzing research trends task support decision support example able support automatically generating related work section research paper closer task support right imagine literature assistant connect online shoppers blog articles product reviews play video starting 653 follow transcript 653 help people improve shopping experience example data mining capabilities analyze reviews compare products compare sentiment products task support decision support product buy connect customer service people emails customers play video starting 722 follow transcript 722 imagine system analysis emails find major complaints customers imagine system task support automatically generating response customer email intelligently attach promotion message appropriate detect thats positive message complaint take opportunity attach promotion information complaint able play video starting 759 follow transcript 759 automatically generate generic response tell customer expect detailed response later trying help people improve productivity play video starting 815 follow transcript 815 shows opportunities lot restricted imagination picture shows trend technology characterizes intelligent information system three angles center theres triangle connects keyword queries search bag words representation means current search engines basically provides search support users model users based keyword queries sees data bag words representation simple approximation actual information documents thats current system connects three nodes simple way provides basic search function doesnt understand user doesnt understand information documents showed trends push node advanced function think user node right keyword queries look user search history model user completely understand users task environment task context information okay pushing personalization complete user model major direction research order build intelligent information systems document side bag words implementation entity relation representation means recognize peoples names relations locations feasible todays natural processing technique google reason initiative knowledge graph havent heard good step direction level initiating robust manner larger scale enable search engine better service future knowledge representation add inference rules search engine intelligent play video starting 1049 follow transcript 1049 calls largescale semantic analysis feasible vertical search engines easier make progress particular domain service side search support information access general play video starting 117 follow transcript 1107 search way access information recommender systems push pull different ways access random information going access help people digest information information found step analysis information data mining find patterns convert text information real knowledge application actionable knowledge decision making knowledge help user improve productivity finishing task example decisionmaking task right trend basically dimension anticipate future intelligent information systems intelligent interactive task support emphasize interactive important optimize combined intelligence users system help users natural way dont assume system human user machine collaborate intelligent way efficient way combined intelligence high general minimize users overall effort solving problem play video starting 1242 follow transcript 1242 big picture future intelligent information systems hopefully insights make innovations top handled today music
course project overview introduction course project give students handson experience developing novel information retrieval andor text mining tools allow students potentially apply knowledge skills learned course solve realworld problem group work encouraged required oneperson team maximum size team 5 members avoid challenges efficient coordination work team members team larger size possible subject approval instructor typical reason larger team project natural task division team members frequent interactions coordination team members minimum despite large size team possible collaboration multiple project teams strongly encouraged minimize amount work team expertise resource sharing generate “combined impact” eg team develop crawler team develops search engine details submit step found httpsdocsgooglecomdocumentd1ukglwsrgph2phjvdioys3mskbp3lwhsdm3oqjccwiedituspsharing grading criteria project graded based following weighting scheme corresponding three stages work 1 team search formation 2 proposal development 3 project result submission team members receive grade provided member made sufficient effort least 20 hours quality time work project team formation 5 student required form team oct 27 2023 team shall designate team members team leader responsible submitting andor uploading course project deliverables project proposal 5 project team required submit roughly onepage project proposal oct 27 2023 graded based completion progress report 5 project team required submit short progress report nov 21 2023 listing progress made remaining tasks challengesissues faced graded based completion software code submission documentation 65 due dec 8 2023 project team asked submit produced source code reasonable documentation documentation cover software software implemented 65 grade distributed follows 45 source code submission 20 documentation submission graded based completion software usage tutorial presentation 20 due dec 08 2023 10 grading based completion remaining 10 based result testing software graders course project work graded primarily based effort followed guidelines completed required tasks receive least 90 total points project encourage students pay attention time management set realistic goals actually completed end semester remaining 10 based software works fully functioning software given 10 buggy software software missing functions result losing 10 grade completion functioning software emphasized due potential dependency multiple projects contributing larger project eg team produce crawler crawl data team build search engine proposal progress report final submission peergraded tas review peer reviews make sure 1 reviews fair 2 submissions satisfy requirements peergrading instructions peergrading grading project proposals progress reports final submissions later semester receive email cmt inviting reviewer make announcement emails peer grading begin soon submission deadlines passed proposal peergrading done oct 28 1200 cstoct 31 1200am cst progress report peergrading done nov 22 1200 cstnov 28 1159 pm cst final submissions peergrading done dec 8 1200 cstdec 15 1159 pm cst please finish gradings time project reviewed least 2 students student review 23 projects comments scores guide assign final scores projects please grade carefully honestly appreciate help managing grading large class hope process good learning experience specific instructions announced later instructions 1 form team 5 form teams groups 5 members highly discouraged team needs designate member team team leader team leader responsible submitting andor uploading course project deliverables 1 form 2 proposal 3 presentation 4 code 2 pick topic write proposal 5 picking project topic students able topic select topic list suggested topics writing project proposal project team required write onepage proposal actually depth topic proposal due end 10 proposal names email addresses team members member designated project coordinatorleader team please make sure indicate project coordinator responsible coordination project work team communication instructor ta team needs help detailed instructions required content proposal provided 4 short set questions answered proposal long questions addressed applicable proposal long couple sentences question sufficient 3 peerreview project proposals student review progress reports 12 groups feedbacksuggestions tas peer assessments make sure proposals satisfies requirements listed google doc 4 work project try reuse existing tools possible minimize amount work sacrificing goal discuss problems issues teammates classmates campuswire leverage campuswire collaborate consistent course policy strongly encourage help course work maximize gain new knowledge skills minimizing work possible best help consider documenting work regularly way lot things written end semester 5 submit progress report 5 team submit short report detailing 1 progress made 2 remaining tasks 3 challengesissues faced graders tas instructor help suggestions based report continue working project final submission 6 peerreview progress reports student review progress reports 12 groups feedbacksuggestions 7 software code submission documentation 65 team submit software code produced project written documentation documentation consist following elements 1 overview function code 2 documentation software implemented sufficient detail basic understanding code future extension improvement 3 documentation usage software documentation usages apis detailed instructions install run software applicable 4 brief description contribution team member case multiperson team note team responsibility figure contribute group project act proactively timely manner group coordinator assigned task opportunity make task failed accomplish general members team grade project documentation submission indicates members superficially participated project actual work case discount grade expected spend least 20 hours seriously work course project minimum time spent preparing documentation 65 grade distributed follows 45 source code submission 20 documentation submission 20 documentation submission includes 5 overview functions 10 implementation documentation 5 usage documentation strict length requirement documentation 8 software usage tutorial presentation 20 end semester project team asked submit short tutorial presentation eg voiced ppt presentation explain developed software presentation 1 sufficient instructions install software applicable 2 sufficient instructions software 3 least example case allow grader provided case test software strict length requirement video submission target 510 minutes presentation shorter 5 minutes unlikely detailed help users understand software longer video 10 minutes long impatient users feel free produce longer presentation needed tutorial presentation graded based 1 completion presentation 10 2 result testing software graders 10 software passes test working expected full points given points deducted 10 allocated “result testing software graders” 9 peerreview project code documentation presentations student review final project submissions 23 groups feedbacksuggestions mark completed item completed dislike report issue
7 overview 7 12 lectures based text mining analytics mooc weeks lessons receive overview natural language processing techniques text representation foundation kinds textmining applications word association mining particular focus mining two basic forms word associations paradigmatic relations time module take approximately 11 hours dedicated time complete videos assignments activities activities module listed required assignments bold activity estimated time required 7 video lectures 2 hours 7 graded quiz 1 hour exam 1 2 hours programming assignment 3 6 hours goals objectives actively engage learning experiences module able explain basic concepts natural language processing explain different ways represent text data explain two basic types word associations mine paradigmatic relations text data guiding questions develop answers following guiding questions watching video lectures computer order understand natural language sentence ambiguity natural language processing nlp difficult computers bagofwords representation wordbased representation robust representations derived syntactic semantic analysis text paradigmatic relation syntagmatic relation general idea discovering paradigmatic relations text general idea discovering syntagmatic relations text term frequency transformation computing similarity context bm25 term frequency transformation work inverse document frequency idf weighting computing similarity context additional readings resources following readings optional c zhai s massung text data management analysis practical introduction information retrieval text mining acm morgan claypool publishers 2016 chapters 14 chapter 13 chris manning hinrich schütze foundations statistical natural language processing mit press cambridge ma 1999 chapter 5 collocations chengxiang zhai exploiting context identify lexical atoms statistical view linguistic context proceedings international interdisciplinary conference modelling context context97 rio de janeiro brazil feb 46 1997 pp 119129 shan jiang chengxiang zhai random walks adjacency graphs mining lexical relations big text data proceedings ieee bigdata conference 2014 pp 549554 key phrases concepts keep eyes open following key terms phrases complete readings interact lectures topics help better understand content module part speech tagging syntactic analysis semantic analysis ambiguity text representation especially bagofwords representation context word context similarity paradigmatic relation syntagmatic relation tips success recommend following review video lectures number times gain solid understanding key questions concepts introduced possible tips suggestions peers class learning community help learn grow way helping address questions peers pose engaging we’ll learn better it’s good idea refer video lectures chapter readings weve read reference responses appropriate critique information presented take notes read materials watch lectures taking notes interacting material find easier remember understand notes you’ll find it’s easier complete assignments ahead favor take notes getting giving help getgive help following means learner help center opens new tab find information regarding specific technical problems example technical problems error messages difficulty submitting assignments problems video playback find answer documentation report problem coursera staff clicking contact link available topics page learner help center content issues opens new tab forum report errors lecture video content assignment questions answers assignment grading text links course pages content course materials university illinois staff community tas monitor forum respond issues mark completed item completed dislike report issue
play video starting follow transcript 000 sound lecture give overview text mining analytics play video starting 13 follow transcript 013 lets define term text mining term text analytics title course called text mining analytics play video starting 25 follow transcript 025 two terms text mining text analytics actually roughly play video starting 32 follow transcript 032 going distinguish going interchangeably reason chosen terms title subtle difference look two phrases literally play video starting 52 follow transcript 052 mining emphasizes process gives error rate medical view problem analytics hand emphasizes result play video starting 17 follow transcript 107 having problem mind going look text data help solve problem play video starting 116 follow transcript 116 treat two terms roughly play video starting 121 follow transcript 121 think literature probably find going distinguish course play video starting 129 follow transcript 129 text mining text analytics mean turn text data high quality information actionable knowledge play video starting 142 follow transcript 142 cases play video starting 145 follow transcript 145 problem dealing lot text data hope turn text data useful raw text data play video starting 157 follow transcript 157 distinguish two different results highquality information actionable knowledge play video starting 25 follow transcript 205 boundary two clear play video starting 29 follow transcript 209 say bit play video starting 212 follow transcript 212 two different angles result text field mining play video starting 219 follow transcript 219 case high quality information refer concise information topic play video starting 228 follow transcript 228 easier humans digest raw text data example face lot reviews product play video starting 238 follow transcript 238 concise form information concise summary major opinions features product positive lets say battery life laptop play video starting 253 follow transcript 253 results useful help people digest text data play video starting 259 follow transcript 259 minimize human effort consuming text data sense play video starting 36 follow transcript 306 output actually knowledge emphasize utility information knowledge discover text data play video starting 318 follow transcript 318 actionable knowledge decision problem actions take play video starting 324 follow transcript 324 example able determine product appealing better choice shocking decision play video starting 338 follow transcript 338 outcome called actionable knowledge consumer take knowledge make decision act case text mining supplies knowledge optimal decision making two clearly distinguished dont necessarily make distinction play video starting 46 follow transcript 406 text mining related text retrieval essential component text mining systems play video starting 415 follow transcript 415 text retrieval refers finding relevant information large amount text data play video starting 424 follow transcript 424 ive taught separate mooc text retrieval search engines play video starting 431 follow transcript 431 discussed various techniques text retrieval play video starting 436 follow transcript 436 taken mooc find overlap play video starting 442 follow transcript 442 useful know background text retrieval understanding topics text mining play video starting 451 follow transcript 451 taken mooc fine mooc text mining analytics going repeat key concepts relevant text mining theyre high level explain relation text retrieval text mining play video starting 512 follow transcript 512 text retrieval useful text mining two ways text retrieval preprocessor text mining meaning help turn big text data relatively small amount relevant text data whats needed solving particular problem play video starting 536 follow transcript 536 sense text retrieval helps minimize human effort play video starting 543 follow transcript 543 text retrieval needed knowledge provenance roughly corresponds interpretation text mining turning text data actionable knowledge find patterns text data actionable knowledge generally verify knowledge looking original text data users text retrieval support back original text data interpret pattern better understand analogy verify pattern reliable high level introduction concept text mining relationship text mining retrieval play video starting 632 follow transcript 632 lets talk text data special data play video starting 639 follow transcript 639 interesting view text data data generated humans subjective sensors play video starting 653 follow transcript 653 slide shows analogy text data nontext data humans subjective sensors physical sensors network sensor thermometer play video starting 716 follow transcript 716 general sensor monitor real world way sense signal real world report signal data various forms example thermometer watch temperature real world report temperature particular format play video starting 744 follow transcript 744 similarly geo sensor sense location report location specification example form longitude value latitude value network sends monitor network traffic activities network reported digital format data similarly think humans subjective sensors observe real world perspective humans express observed form text data sense human actually subjective sensor sense whats happening world express whats observed form data case text data looking text data way advantage able integrate types data thats needed data mining problems play video starting 856 follow transcript 856 looking general problem data mining play video starting 92 follow transcript 902 general dealing lot data world related problem general dealing nontext data text data course nontext data usually produced physical senses nontext data different formats play video starting 927 follow transcript 927 numerical data categorical relational data multimedia data video speech play video starting 936 follow transcript 936 non text data important problems text data important contain lot symmetrical content contain knowledge users especially preferences opinions users play video starting 101 follow transcript 1001 treating text data data observed human sensors treat data framework data mining problem basically turn data turn data actionable knowledge take advantage change real world course better means data mining problem basically taking lot data input giving actionable knowledge output data mining module number different mining algorithms different kinds data generally different algorithms mining data play video starting 1056 follow transcript 1056 example video data require computer vision understand video content facilitate effective mining lot general algorithms applicable kinds data algorithms course useful particular data generally develop special algorithm course cover specialized algorithms particularly useful mining text data music
play video starting 6 follow transcript 006 lecture textual representation lecture going discuss textual representation discuss natural language processing allow represent text different ways lets take look example sentence represent sentence different ways represent sentence string characters true languages store computer store natural language sentence string characters general way representing text approach represent text data unfortunately representation help semantic analysis needed applications text mining reason recognizing words string going keep spaces ascii symbols count whats frequent character english text correlation characters cant analyze semantics general way representing text represent natural language text try bit natural language processing word segmentation obtain representation text form sequence words identify words dog chasing level representation certainly lot things mainly words basic units human communication natural language powerful identifying words example easily count frequent words document collection words form topics combine related words words positive words negative sentiment analysis representing text data sequence words opens lot interesting analysis possibilities level representation slightly general string characters languages chinese actually easy identify word boundaries language text sequence characters space youll rely special techniques identify words language course make mistakes segmenting words sequence words representation robust string characters english easy obtain level representation time play video starting 4 follow transcript 400 naturally language processing add part speech tags count example frequent nouns nouns associated verbs opens bit interesting opportunities analysis note plus sign representing text sequence part speech tags dont necessarily replace original word sequence written add additional way representing text data data represented sequence words sequence part speech tags enriches representation text data enables interesting analysis play video starting 5 follow transcript 500 pausing sentence obtain syntactic structure course open interesting analysis example writing styles correcting grammar mistakes semantic analysis able recognize dog animal recognize boy person playground location analyze relations example dog chasing boy boy playground add entities relations entity relation recreation level interesting things example count easily frequent person thats mentioning collection news articles mention person tend mentioning person useful representation related knowledge graph heard google semantic way representing text data robust sequence words syntactical analysis easy identify entities right types make mistakes relations harder find make mistakes makes level representation robust useful move logical condition predicates inference rules inference rules infer interesting derived facts text thats useful unfortunately level representation robust make mistakes cant time kinds sentences finally speech acts add level repetition intent saying sentence case request knowing allow analyze interesting things observer author sentence whats intention saying whats scenarios actions made level analysis interesting picture shows move generally sophisticated natural language processing techniques unfortunately techniques require human effort accurate means mistakes add texts levels representing deeper analysis language tolerate errors means necessary combine deep analysis shallow analysis based example sequence words right side youll arrow points indicate representation text closer knowledge representation mind solving lot problems desirable represent text level knowledge easily extract knowledge thats purpose textmining tradeoff deeper analysis errors give direct knowledge extracted text shallow analysis robust wouldnt actually give necessary deeper representation knowledge say text data generated humans meant consumed humans result text data analysis textmining humans play important role loop meaning optimize collaboration humans computers sense okay computers able compute accurately representation text data patterns extracted text data interpreted humans humans guide computers accurate analysis annotating data providing features guide machine learning programs make work effectively
play video starting follow transcript 000 sound explained different text representation tends enable different analysis play video starting 16 follow transcript 016 particular gradually add deeper analysis results represent text data open interesting representation play video starting 29 follow transcript 029 opportunities analysis capacities table summarizes column shows text representation second visualizes generality representation meaning representation accurately text data third column shows enabled analysis techniques play video starting 56 follow transcript 056 final column shows examples application achieved level representation lets take look stream text processed stream processing algorithms robust general play video starting 115 follow transcript 115 interesting applications level example compression text doesnt necessarily know word boundaries knowing word boundaries actually help play video starting 128 follow transcript 128 word base repetition important level representation general relatively robust indicating lot analysis techniques word relation analysis topic analysis sentiment analysis applications enabled analysis example thesaurus discovery discovering related words topic opinion related applications abounded example people interesting knowing major topics covered collection texts case research literature scientists know important research topics today customer service people know major complaints customers mining email messages business intelligence people interested understanding consumers opinions products competitors products figure winning features products play video starting 243 follow transcript 243 general applications enabled representation level play video starting 253 follow transcript 253 moving gradually add additional representations adding syntactical structures enable course syntactical graph analysis graph mining algorithms analyze syntactic graphs applications related representation example stylistic analysis generally requires syntactical structure representation play video starting 322 follow transcript 322 generate structure based features features help classify text objects different categories looking structures classification accurate example classify articles play video starting 345 follow transcript 345 different categories corresponding different authors figure k authors actually written article generally look syntactic structures play video starting 43 follow transcript 403 add entities relations enable techniques knowledge graph answers information network answers general analysis enable applications entities play video starting 422 follow transcript 422 example discovery knowledge opinions real world entities play video starting 428 follow transcript 428 level representation integrate scaled resources play video starting 437 follow transcript 437 finally add logical predicates enable large inference course useful integrating analysis scattered knowledge play video starting 450 follow transcript 450 example add ontology top play video starting 454 follow transcript 454 extracted information text make inferences play video starting 459 follow transcript 459 good example application enabled level representation knowledge assistant biologists program help biologist manage relevant knowledge literature research problem understanding functions genes play video starting 522 follow transcript 522 computer make inferences hypothesis biologist interesting example gene function intelligent program read literature extract relevant facts compiling information extracting logic system actually track thats answers researchers questioning genes related functions play video starting 557 follow transcript 557 order support level application logical representation course covering techniques mainly based word based representation play video starting 612 follow transcript 612 techniques general robust thats widely various applications play video starting 621 follow transcript 621 fact virtually text mining applications level representation techniques support analysis text level play video starting 635 follow transcript 635 obviously levels combined combined order support sophisticated applications summarize major takeaway points text representation determines mining algorithms applied multiple ways represent text strings words syntactic structures entityrelation graphs knowledge predicates different representations general combined real applications extent example accurate representations syntactic structures state partial structures strictly recognize entities great general play video starting 734 follow transcript 734 different levels combined enable richer analysis powerful analysis play video starting 742 follow transcript 742 course focuses wordbased representation techniques advantage general robust applicable natural language thats big advantage approaches rely fragile natural language processing techniques secondly require manual effort require manual effort thats important benefit means apply directly application play video starting 820 follow transcript 820 third techniques actually surprisingly powerful effective form implications play video starting 829 follow transcript 829 course explained play video starting 834 follow transcript 834 effective partly words invented humans basically units communications play video starting 845 follow transcript 845 actually sufficient representing kinds semantics play video starting 853 follow transcript 853 makes wordbased representation powerful finally wordbased representation techniques enable representation combined sophisticated approaches play video starting 914 follow transcript 914 theyre competing music
play video starting follow transcript 000 sound lecture word association mining analysis lecture going talk mine associations words text example knowledge natural language mine text data play video starting 33 follow transcript 033 heres outline going talk word association explain discovering relations useful finally going talk general ideas mine word associations general two word relations basic play video starting 56 follow transcript 056 called paradigmatic relation syntagmatic relation b paradigmatic relation substituted means two words paradigmatic relation semantic class syntactic class general replace affecting understanding sentence means valid sentence example cat dog two words paradigmatic relation class animal general replace cat dog sentence sentence valid sentence make sense play video starting 158 follow transcript 158 similarly monday tuesday paradigmatical relation play video starting 24 follow transcript 204 second relation called syntagmatical relation play video starting 210 follow transcript 210 case two words relation combined b syntagmatic relation combined sentence means two words semantically related play video starting 230 follow transcript 230 example cat sit related cat sit play video starting 238 follow transcript 238 similarly car drive related semantically combined convey meaning general replace cat sit sentence car drive sentence valid sentence meaning sentence meaningless different paradigmatic relation two relations fact fundamental play video starting 317 follow transcript 317 generalized capture basic relations units arbitrary sequences definitely generalized describe relations items language b dont words phrases example play video starting 337 follow transcript 337 complex phrases nonphrase think general problem sequence mining think units sequence data think paradigmatic relation relations applied units tend occur singular locations sentence sequence data elements general occur similar locations relative neighbors sequence syntagmatical relation hand related cooccurrent elements tend show sequence play video starting 433 follow transcript 433 two complimentary basic relations words interested discovering automatically text data discovering worded relations applications play video starting 447 follow transcript 447 relations directly useful improving accuracy nlp tasks part knowledge language know two words synonyms example help lot tasks play video starting 55 follow transcript 505 grammar learning done techniques learn paradigmatic relations form classes words syntactic classes example learn syntagmatic relations able know rules putting larger expression based component expressions learn structure play video starting 539 follow transcript 539 word relations useful applications text retrieval mining example search text retrieval word associations modify query introduce additional related words query make query effective play video starting 61 follow transcript 601 called query expansion play video starting 65 follow transcript 605 related words suggest related queries user explore information space play video starting 612 follow transcript 612 application word associations automatically construct top map browsing words nodes associations edges user navigate word play video starting 628 follow transcript 628 find information information space play video starting 633 follow transcript 633 finally word associations compare summarize opinions example interested understanding positive negative opinions iphone 6 order look words strongly associated feature word battery positive versus negative reviews syntagmatical relations help show detailed opinions product play video starting 716 follow transcript 716 discover associations automatically intuitions lets look paradigmatic relation play video starting 729 follow transcript 729 essentially take advantage similar context play video starting 734 follow transcript 734 simple sentences cat dog generally occur similar context definition paradigmatic relation play video starting 749 follow transcript 749 right side extracted expressly context cat dog small sample text data play video starting 8 follow transcript 800 ive taken away cat dog sentences context play video starting 88 follow transcript 808 course different perspectives look context play video starting 813 follow transcript 813 example look words occur left part context call left context words occur cat dog case clearly dog cat similar left context play video starting 841 follow transcript 841 generally say cat cat say dog dog makes similar left context play video starting 853 follow transcript 853 similarly look words occur cat dog call right context similar case course extreme case eats play video starting 98 follow transcript 908 general youll words course cant follow cat dog play video starting 917 follow transcript 917 look general context words sentence sentences word play video starting 927 follow transcript 927 general context similarity two words play video starting 935 follow transcript 935 suggestion discover paradigmatic relation looking similarity context words example think following questions similar context cat context dog play video starting 956 follow transcript 956 contrast similar context cat context computer play video starting 102 follow transcript 1002 intuitively imagine context cat context dog similar context cat context computer means case similarity value high play video starting 1021 follow transcript 1021 context cat dog second similarity context cat computer low having paradigmatic relationship imagine words occur computer general different words occur cat play video starting 1046 follow transcript 1046 basic idea covering paradigmatic relation play video starting 1052 follow transcript 1052 syntagmatic relation going explore correlated occurrences based definition syntagmatic relation play video starting 113 follow transcript 1103 sample text play video starting 116 follow transcript 1106 interested knowing words correlated verb eats words eats play video starting 1116 follow transcript 1116 look right side slide ive taken away two words eats play video starting 1127 follow transcript 1127 ive taken away word left word right sentence play video starting 1135 follow transcript 1135 ask question words tend occur left eats play video starting 1143 follow transcript 1143 words tend occur right eats play video starting 1149 follow transcript 1149 thinking question help discover syntagmatic relations syntagmatic relations essentially captures correlations play video starting 123 follow transcript 1203 important question ask syntagmatical relation eats occurs words tend occur play video starting 1216 follow transcript 1216 question words tend cooccur meaning eats tend words play video starting 1229 follow transcript 1229 dont eats probably dont words play video starting 1236 follow transcript 1236 intuition help discover syntagmatic relations play video starting 1241 follow transcript 1241 consider example play video starting 1244 follow transcript 1244 helpful occurrence eats predicting occurrence meat play video starting 1249 follow transcript 1249 right right knowing eats occurs sentence generally help predict meat occurs eats occur sentence increase chance meat occur play video starting 138 follow transcript 1308 contrast look question bottom helpful occurrence eats predicting occurrence text play video starting 1317 follow transcript 1317 eats text related knowing eats occurred sentence doesnt help predict weather text occurs sentence contrast question eats meat play video starting 1335 follow transcript 1335 helps explain intuition methods discovering syntagmatic relations mainly capture correlation occurrences two words play video starting 1350 follow transcript 1350 summarize general ideas discovering word associations following play video starting 1356 follow transcript 1356 paradigmatic relation present word context compute context similarity going assume words high context similarity paradigmatic relation play video starting 1414 follow transcript 1414 syntagmatic relation count times two words occur context sentence paragraph document going compare cooccurrences individual occurrences play video starting 1433 follow transcript 1433 going assume words high cooccurrences relatively low individual occurrences syntagmatic relations attempt occur dont usually occur note paradigmatic relation syntagmatic relation actually closely related paradigmatically related words tend syntagmatic relation word tend associated word suggests join discovery two relations general ideas implemented different ways course wont cover cover least methods effective discovering relations music
play video starting follow transcript 000 sound lecture paradigmatics relation discovery lecture going talk discover particular word association called paradigmatical relation play video starting 25 follow transcript 025 definition two words paradigmatically related share similar context occur similar positions text naturally idea discovering relation look context word try compute similarity contexts play video starting 50 follow transcript 050 example context word cat play video starting 55 follow transcript 055 taken word cat context remaining words sentences contain cat play video starting 19 follow transcript 109 thing word dog play video starting 113 follow transcript 113 general capture context try assess similarity context cat context word dog play video starting 124 follow transcript 124 question formally represent context define similarity function play video starting 133 follow transcript 133 note context actually contains lot words regarded pseudo document imagine document different ways looking context example look word occurs word cat call context left1 context right case words big cetera words occur left word cat say cat cat big cat cat cetera similarly collect words occur right word cat call context right1 words eats ate cetera generally look words window text word cat lets say take window 8 words word cat call context window8 play video starting 249 follow transcript 249 course words left right bag words general represent context play video starting 31 follow transcript 301 word based representation actually give interesting way define perspective measuring similarity look similarity left1 words share words left context ignored words general context gives perspective measure similarity similarly right1 context capture narrative perspective left1 right1 course allow capture similarity strict criteria play video starting 349 follow transcript 349 general context contain adjacent words eats nonadjacent words saturday tuesday words context play video starting 45 follow transcript 405 flexibility allows match similarity different ways useful capture similarity base general content give loosely related paradigmatical relations words immediately left right word likely capture words related syntactical categories semantics play video starting 441 follow transcript 441 general idea discovering paradigmatical relations compute similarity context two words example measure similarity cat dog based similarity context general combine kinds views context similarity function general combination similarities different context course assign weights different similarities allow focus particular context naturally application specific main idea discovering pardigmatically related words computer similarity context lets exactly compute similarity functions answer question useful think bag words representation vectors vector space model play video starting 548 follow transcript 548 familiar information retrieval textual retrieval techniques realize vector space model frequently modeling documents queries search find convenient model context word paradigmatic relation discovery idea approach view word vocabulary defining dimension high dimensional space n words total vocabulary n dimensions illustrated bottom frequency vector representing context eats occurred 5 times context ate occurred 3 times cetera vector placed vector space model general represent pseudo document context cat vector d1 word dog give different context d2 measure similarity two vectors viewing context vector space model convert problem paradigmatical relation discovery problem computing vectors similarity play video starting 720 follow transcript 720 two questions address compute vector compute xi yi play video starting 731 follow transcript 731 question compute similarity play video starting 735 follow transcript 735 general approaches solve problem developed information retrieval work matching query vector document vector adapt ideas compute similarity context documents purpose lets look plausible approach try match similarity context based expected overlap words call eowc play video starting 817 follow transcript 817 idea represent context word vector word weight thats equal probability randomly picked word document vector word words xi defined normalized account word wi context interpreted probability actually pick word d1 randomly picked word play video starting 856 follow transcript 856 course xis sum normalized frequencies play video starting 92 follow transcript 902 means vector actually probability distribution words play video starting 910 follow transcript 910 vector d2 computed way give two probability distributions representing two contexts play video starting 924 follow transcript 924 addresses problem compute vectors lets define similarity approach simply define similarity dot product two vectors defined sum products play video starting 941 follow transcript 941 corresponding elements two vectors play video starting 946 follow transcript 946 interesting similarity function actually nice interpretation dot product fact gives probability two randomly picked words two contexts identical means try pick word context try pick word context ask question identical two contexts similar expect frequently two words picked two contexts identical different chance identical words picked two contexts small intuitively makes sense right measuring similarity contexts play video starting 1041 follow transcript 1041 take look exact formulas interpreted probability two randomly picked words identical play video starting 1057 follow transcript 1057 stare formula check whats sum basically case gives probability overlap particular word wi xi gives probability pick particular word d1 yi gives probability picking word d2 pick word two contexts identical pick right thats possible approach eowc extracted overlap words context assess approach work course ultimately test approach real data gives semantically related words play video starting 1157 follow transcript 1157 give paradigmatical relations analytically analyze formula bit make sense right formula give higher score overlap two contexts thats exactly analyze formula carefully potential problems specifically two potential problems favor matching frequent term matching distinct terms play video starting 1236 follow transcript 1236 dot product element high value element shared contexts contributes lot overall sum play video starting 1251 follow transcript 1251 make score higher case two vectors actually lot overlap different terms term relatively low frequency desirable course desirable cases case intuitively prefer case match different terms context confidence saying two words occur similar context rely term thats bit questionable robust play video starting 1334 follow transcript 1334 second problem treats word equally right match word matching word eats intuitively know matching isnt surprising occurs matching strong evidence matching word eats doesnt occur frequently problem approach play video starting 1413 follow transcript 1413 chapter going talk address problems music
play video starting 5 follow transcript 005 lecture continue discussing paradigmatical relation discovery earlier introduced method called expected overlap words context method represent context word vector represents probability word context measure similarity theproduct interpreted probability two randomly picked words two contexts identical discussed two problems method favors matching frequent term matching distinct terms put emphasis matching term second treats word equally common word contribute equally content word eats going talk solve problems specifically going introduce retrieval heuristics text retrieval heuristics effectively solve problems problems occur text retrieval match query document vector address problem sublinear transformation tone frequency dont raw frequency count term represent context transform form wouldnt emphasize raw frequency address synchronous problem put weight rare terms reward matching realworld heuristic called idf term weighting text retrieval idf stands inverse document frequency going talk two heuristics detail lets talk tf transformation convert raw count word document weight reflects belief important word document denoted tf wd thats yaxis general ways map lets look simple way mapping case going say nonzero counts mapped zero count mapped zero mapping frequencies mapped two values zero mapping function flat line naive frequency words actually advantage emphasizing matching words context allow frequency word dominate matching approach taken earlier expected overlap count approach linear transformation basically take y x raw count representation created problem talked emphasize matching frequent term matching frequent term contribute lot lot interesting transformations two extremes generally form sublinear transformation example possibility take logarithm raw count give curve looks case high frequency counts high counts penalize bit curve sublinear curve brings weight high counts prevents terms dominating scoring function play video starting 448 follow transcript 448 interesting transformation called bm25 transformation effective retrieval transformation form looks k plus multiplied x divided x plus k k parameter x count raw count word transformation interesting actually extreme extreme varying k interesting upper bound k plus case puts strict constraint high frequency terms weight exceed k plus vary k simulate two extremes k set zero roughly 01 vector set k large value behave linear transformation transformation function effective transformation function text retrieval makes sense problem setup talked solve problem overemphasizing frequency term lets look second problem penalize popular terms matching surprising occurs matching eats count lot address problem case idf weighting thats commonly retrieval idf stands inverse document frequency document frequency means count total number documents contain particular word show idf measure defined logarithm function number documents match term document frequency k number documents containing word document frequency m total number documents collection idf function giving higher value lower k meaning rewards rare term maximum value log m plus thats word occurred context thats rare term rare term collection lowest value k reaches maximum m low value close zero fact course measure search naturally collection case collection context collect words collection say word thats popular collection general low idf depending dataset construct context vectors different ways end term frequent original dataset frequent collective context documents add heuristics improve similarity function heres way ways possible reasonable way adapt bm25 retrieval model paradigmatical relation mining play video starting 914 follow transcript 914 case define document vector containing elements representing normalized bm25 values normalization function take sum words normalize weight word sum weights words ensure xis sum vector similar vector actually similar word distribution xis sum weight bm25 word defined compare old definition normalized count right document lens total counts words context document thats bm25 transformation introduced course extra occurrence count achieve sublinear normalization introduced parameter k parameter generally nonactive number zero possible controls upper bound controls extent simulates linear transformation parameter parameter b zero parameter control lens normalization case normalization formula average document lens computed taking average lenses documents collection case lenses context documents considering average documents constant given collection actually affecting effect parameter b constant kept constant thats retrieval give stabilized interpretation parameter b purpose constant affecting lens normalization parameter b definition new way define document vectors compute vector d2 way difference highfrequency terms lower weights help control inference highfrequency terms idea added scoring function means introduce weight matching term recall sum indicates possible words overlap two contexts xi yi probabilities picking word contexts indicates likely match word idf give importance matching word common word worth rare word emphasize matching rare words modification new function likely address two problems interestingly approach discover syntagmatic relations general rebrand context term vector likely terms high weights terms low weights depending assign weights terms able weights discover words strongly associated candidate word context lets take look term vector detail xi defined normalized weight bm25 weight reflects frequent word occurs context cant say frequent term context correlated candidate word common words occur frequently context apply idf weighting reweight terms based idf means words common penalized highest weighted terms common terms lower idfs terms terms frequent context frequent collection clearly words tend occur context candidate word example cat reason highly weighted terms idea weighted vector assumed candidates syntagmatic relations course byproduct approach discovering paradigmatic relations lecture going talk discover syntagmatic relations clearly shows relation discovering two relations discovered joint manner leveraging associations summarize main idea discovering paradigmatic relations collect context candidate word form pseudo document typically represented bag words compute similarity corresponding context documents two candidate words take highly similar word pairs treat having paradigmatic relations words share similar contexts different ways implement general idea talked approaches specifically talked text retrieval models help design effective similarity function compute paradigmatic relations specifically bm25 idf weighting discover paradigmatic relation approaches represent state art text retrieval techniques finally syntagmatic relations discovered byproduct discover paradigmatic relations
8 overview weeks lessons learn word association mining particular focus mining basic form word association syntagmatic relations start learning topic analysis focus techniques mining topic text time module take approximately 35 hours dedicated time complete videos assignments activities activities module listed required assignments bold activity estimated time required 8 video lectures 2 hours 8 graded quiz 1 hour mp24 submission grading 30 mins goals objectives actively engage learning experiences module able explain basic concepts probability entropy conditional entropy mutual information explain ways discovering syntagmatic paradigmatic relations explain basic idea bayesian estimation theory guiding questions develop answers following guiding questions watching video lectures entropy random variables entropy function reach minimum maximum respectively conditional entropy relation conditional entropy hxy entropy hx larger conditional entropy discovering syntagmatic relations mutual information ixy related entropy hx conditional entropy hxy what’s minimum value ixy symmetric x y mutual information ixy reach minimum given x y ixy reach maximum mutual information useful discovering syntagmatic relations conditional entropy topic define task topic mining analysis computationally what’s input what’s output heuristically solve problem topic mining analysis treating term topic main problems approach benefits representing topic word distribution statistical language model unigram language model compute probability sequence words given unigram language model maximum likelihood estimate unigram language model given text article basic idea bayesian estimation prior distribution posterior distribution related bayes rule additional readings resources following readings optional c zhai s massung text data management analysis practical introduction information retrieval text mining acm morgan claypool publishers 2016 chapters 13 17 key phrases concepts keep eyes open following key terms phrases complete readings interact lectures topics help better understand content module entropy conditional entropy mutual information topic coverage topic language model generative model unigram language model word distribution background language model parameters probabilistic model likelihood bayes rule maximum likelihood estimation prior posterior distributions bayesian estimation inference maximum posteriori map estimate prior model posterior mode tips success recommend following review video lectures number times gain solid understanding key questions concepts introduced possible tips suggestions peers class learning community help learn grow way helping address questions peers pose engaging we’ll learn better it’s good idea refer video lectures chapter readings weve read reference responses appropriate critique information presented take notes read materials watch lectures taking notes interacting material find easier remember understand notes you’ll find it’s easier complete assignments ahead favor take notes getting giving help getgive help following means learner help center opens new tab find information regarding specific technical problems example technical problems error messages difficulty submitting assignments problems video playback find answer documentation report problem coursera staff clicking contact link available topics page learner help center content issues opens new tab forum report errors lecture video content assignment questions answers assignment grading text links course pages content course materials university illinois staff community tas monitor forum respond issues mark completed item dislike report issue
play video starting follow transcript 000 sound lecture syntagmatic relation discovery entropy lecture going continue talking word association mining particular going talk discover syntagmatic relations going start introduction entropy basis designing measures discovering relations play video starting 32 follow transcript 032 definition syntagmatic relations hold words correlated cooccurrences means word occurs context tend occurrence word play video starting 48 follow transcript 048 take specific example ask question eats occurs words tend occur play video starting 11 follow transcript 101 looking sentences left words occur eats cat dog fish right take look right side show eats words question predict words occur left right play video starting 128 follow transcript 128 right force think words associated eats associated eats tend occur context eats play video starting 138 follow transcript 138 specifically prediction problem take text segment sentence paragraph document ask question particular word present absent segment play video starting 154 follow transcript 154 right ask word w w present absent segment play video starting 22 follow transcript 202 whats interesting words actually easier predict words play video starting 210 follow transcript 210 take look three words meat unicorn think easier predict play video starting 220 follow transcript 220 think moment conclude play video starting 224 follow transcript 224 easier predict tends occur say sentence play video starting 231 follow transcript 231 unicorn relatively easy unicorn rare rare bet doesnt occur sentence play video starting 242 follow transcript 242 meat terms frequency makes harder predict possible occurs sentence segment accurately play video starting 253 follow transcript 253 occur sentence lets study problem formally play video starting 32 follow transcript 302 problem formally defined predicting value binary random variable denote x sub w w denotes word random variable associated precisely word play video starting 318 follow transcript 318 value variable 1 means word present 0 means word absent naturally probabilities 1 0 sum 1 word present absent segment play video starting 335 follow transcript 335 theres choice play video starting 338 follow transcript 338 intuition concept earlier formally stated follows random random variable difficult prediction play video starting 349 follow transcript 349 question quantitatively measure randomness random variable x sub w play video starting 356 follow transcript 356 general quantify randomness variable thats measure called entropy measure introduced information theory measure randomness x connection information scope course play video starting 417 follow transcript 417 purpose treat entropy function function defined random variable case binary random variable definition easily generalized random variable multiple values play video starting 432 follow transcript 432 function form looks theres sum possible values random variable sum value product probability play video starting 445 follow transcript 445 random variable equals value log probability play video starting 453 follow transcript 453 note negative sign play video starting 456 follow transcript 456 entropy general nonnegative mathematically proved play video starting 52 follow transcript 502 expand sum equation looks second explicitly plugged two values 0 1 0 log 0 generally define 0 log 0 undefined play video starting 528 follow transcript 528 entropy function function give different value different distributions random variable play video starting 537 follow transcript 537 clearly depends probability random variable taking value 1 0 plot function probability random variable equal 1 play video starting 556 follow transcript 556 function looks play video starting 61 follow transcript 601 two ends means probability x play video starting 67 follow transcript 607 equals 1 small large entropy function low value 05 middle reaches maximum play video starting 620 follow transcript 620 plot function probability x play video starting 625 follow transcript 625 taking value 0 function show exactly curve imagine thats play video starting 642 follow transcript 642 two probabilities symmetric completely symmetric play video starting 648 follow transcript 648 interesting question think general x entropy reach maximum minimum particular think special cases example case random variable play video starting 78 follow transcript 708 takes value 1 probability 1 play video starting 716 follow transcript 716 theres random variable play video starting 719 follow transcript 719 equally likely taking value zero case probability x equals 1 05 play video starting 730 follow transcript 730 higher entropy play video starting 734 follow transcript 734 easier look problem thinking simple example play video starting 740 follow transcript 740 coin tossing play video starting 743 follow transcript 743 think random experiments tossing coin play video starting 748 follow transcript 748 gives random variable represent result head tail define random variable x sub coin 1 coin shows head 0 coin shows tail play video starting 89 follow transcript 809 compute entropy random variable entropy indicates difficult predict outcome play video starting 822 follow transcript 822 coin toss play video starting 825 follow transcript 825 think two cases fair coin completely fair coin shows head tail equally likely two probabilities half right equal half play video starting 844 follow transcript 844 extreme case completely biased coin coin shows heads completely biased coin play video starting 854 follow transcript 854 lets think entropies two cases plug values entropies follows fair coin entropy reaches maximum thats 1 play video starting 911 follow transcript 911 completely biased coin 0 intuitively makes lot sense fair coin difficult predict play video starting 922 follow transcript 922 completely biased coin easy predict say head head time curve follows fair coin corresponds middle point uncertain completely biased coin corresponds end point probability 10 entropy 0 lets entropy word prediction lets think problem predict w present absent segment think three words particularly think entropies play video starting 106 follow transcript 1006 assume high entropy words harder predict play video starting 1011 follow transcript 1011 quantitative way tell word harder predict play video starting 1020 follow transcript 1020 look three words meat unicorn clearly expect meat higher entropy unicorn fact look entropy close zero occurs completely biased coin play video starting 1044 follow transcript 1044 entropy zero play video starting 1048 follow transcript 1048 music
play video starting follow transcript 000 sound lecture syntagmatic relation discovery conditional entropy lecture going continue discussion word association mining analysis play video starting 18 follow transcript 018 going talk conditional entropy useful discovering syntagmatic relations earlier talked entropy capture easy predict presence absence word play video starting 34 follow transcript 034 address different scenario assume know text segment question suppose know eats occurred segment help predict presence absence water meat particular know presence eats helped predict presence meat play video starting 12 follow transcript 102 frame entrophy mean interested knowing knowing presence eats reduce uncertainty meats reduce entrophy random variable corresponding presence absence meat ask question know absents eats play video starting 128 follow transcript 128 help predict presence absence meat play video starting 134 follow transcript 134 questions addressed concept called conditioning entropy explain concept lets look scenario know segment probabilities indicating word meat occurs doesnt occur segment entropy function looks slide play video starting 23 follow transcript 203 suppose know eats present know value random variable denotes eats play video starting 212 follow transcript 212 change probabilities conditional probabilities look presence absence meat play video starting 221 follow transcript 221 given know eats occurred context result replace probabilities corresponding conditional probabilities entropy function conditional entropy play video starting 237 follow transcript 237 equation conditional entropy conditional presence eats play video starting 252 follow transcript 252 essentially entropy function probabilities condition play video starting 34 follow transcript 304 tells entropy meat known eats occurring segment play video starting 314 follow transcript 314 course define conditional entropy scenario dont eats know did occur segment entry condition entropy capture instances meat condition putting different scenarios completed definition conditional entropy follows play video starting 339 follow transcript 339 basically going consider scenarios value eats zero gives probability eats equal zero basically eats present absent course conditional entropy meat particular scenario play video starting 45 follow transcript 405 expanded entropy following equation play video starting 415 follow transcript 415 involvement conditional probabilities play video starting 421 follow transcript 421 general discrete random variables x y play video starting 427 follow transcript 427 conditional entropy larger entropy variable x basically upper bound conditional entropy means knowing information segment able increase uncertainty reduce uncertainty intuitively makes sense know information help make prediction hurt prediction case play video starting 55 follow transcript 505 whats interesting think whats minimum possible value conditional entropy know maximum value entropy x play video starting 517 follow transcript 517 minimum think play video starting 522 follow transcript 522 hope reach conclusion minimum possible value zero interesting think situation achieve play video starting 534 follow transcript 534 lets conditional entropy capture syntagmatic relation play video starting 539 follow transcript 539 course conditional entropy gives directly way measure association two words tells extent predict word given know presence absence word look intuition conditional entropy capturing syntagmatic relations useful think special case listed conditional entropy word given play video starting 619 follow transcript 619 listed conditional entropy middle play video starting 633 follow transcript 633 value play video starting 636 follow transcript 636 means know meat occurs sentence hope predict meat occurs sentence course 0 theres incident anymore know word occurs segment know answer prediction zero thats conditional entropy reaches minimum play video starting 76 follow transcript 706 lets look cases play video starting 79 follow transcript 709 case knowing trying predict meat case knowing eats trying predict meat think smaller doubt smaller entropy means easier prediction play video starting 731 follow transcript 731 think higher smaller play video starting 736 follow transcript 736 uncertainty case doesnt tell meat knowing occurrence doesnt help reduce entropy stays fairly close original entropy meat case eats eats related meat knowing presence eats absence eats help predict meat occurs help reduce entropy meat expect sigma term smaller entropy play video starting 821 follow transcript 821 means stronger association meat eats play video starting 829 follow transcript 829 know w meat conditional entropy reach minimum 0 words reach maximum thats stuff related meat example close maximum entropy meat play video starting 859 follow transcript 859 suggests conditional entropy mining syntagmatic relations hours look follows play video starting 910 follow transcript 910 word w1 going enumerate overall words w2 compute conditional entropy w1 given w2 play video starting 922 follow transcript 922 thought candidate ascending order conditional entropy favor world small entropy meaning helps predict time word w1 going take top ring candidate words words potential syntagmatic relations w1 play video starting 941 follow transcript 941 note threshold find words stresser number top candidates take absolute value conditional entropy play video starting 955 follow transcript 955 allow mine strongly correlated words particular word w1 play video starting 106 follow transcript 1006 algorithm help mine strongest k syntagmatical relations entire collection order ensure conditional entropies comparable different words case discovering mathematical relations targeted word w1 compare conditional entropies play video starting 1034 follow transcript 1034 w1 given different words case comparable play video starting 1041 follow transcript 1041 right conditional entropy w1 given w2 conditional entropy w1 given w3 comparable play video starting 1051 follow transcript 1051 measure hard predict w1 think two pairs share w2 condition try predict w1 w3 conditional entropies actually comparable think question comfortable different outer bounds right outer bounds precisely entropy w1 entropy w3 different upper bounds compare way address problem play video starting 1138 follow transcript 1138 later discuss mutual information solve problem music
play video starting follow transcript 000 sound lecture syntagmatic relation discovery mutual information play video starting 13 follow transcript 013 lecture going continue discussing syntagmatic relation discovery particular going talk concept information series called mutual information discover syntagmatic relations talked problem conditional entropy conditional entropy computed different pairs words comparable makes harder cover strong synagmatic relations globally corpus going introduce mutual information concept information series allows normalize conditional entropy make comparable different pairs play video starting 14 follow transcript 104 particular mutual information order find ixy matches entropy reduction x obtained knowing y specifically question interested entropy x obtain knowing y play video starting 127 follow transcript 127 mathematically defined difference original entropy x condition y x given y play video starting 137 follow transcript 137 defined reduction entropy y knowing x play video starting 148 follow transcript 148 normally two conditional interface h x given y entropy y given x equal interestingly reduction entropy knowing actually equal quantity called mutual information order buy function interesting properties nonnegative easy understand original entropy play video starting 222 follow transcript 222 going lower possibility reduced conditional entropy words conditional entropy exceed original entropy knowing information help potentially hurt predicting x play video starting 241 follow transcript 241 signal property symmetric additional entropy symmetrical mutual information third property reaches minimum zero two random variables completely independent means knowing tell property verified simply looking equation reaches 0 conditional entropy x inaudible y exactly original entropy x means knowing did help x y completely independent play video starting 332 follow transcript 332 fix x rank different ys conditional entropy give order ranking based mutual information function hx fixed x fixed ranking based mutual entropy exactly ranking based conditional entropy x given y mutual information allows compare different pairs x y mutual information general general useful play video starting 410 follow transcript 410 examine intuition mutual information syntagmatical relation mining play video starting 417 follow transcript 417 question ask forcing relation mining eats occurs words tend occur play video starting 425 follow transcript 425 question framed mutual information question words high mutual information eats computer missing information eats words play video starting 439 follow transcript 439 basically base conditional words strongly associated eats high point words related lower mutual information give example mutual information eats meats meats eats information symmetrical expected higher mutual information eats knowing help predictor similar knowing eats help predicting easily mutual information word largest equal entropy word case reduction maximum knowing allows predict completely conditional entropy zero mutual information reaches maximum going larger equal machine volume eats words words picking word computer picking eats word information larger computation eats play video starting 616 follow transcript 616 look compute mute information order play video starting 625 follow transcript 625 different form mutual information mathematically rewrite mutual information form slide essentially formula computes called kldivergence divergence term information theory measures divergence two distributions play video starting 650 follow transcript 650 look formula sum combinations different values two random variables sum mainly comparison two joint distributions numerator joint actual observed joint distribution two random variables play video starting 712 follow transcript 712 bottom part denominator interpreted expected joint distribution two random variables independent two random variables independent joined distribution equal product two probabilities play video starting 735 follow transcript 735 comparison tell two variables independent independent expect two play video starting 744 follow transcript 744 numerator different denominator mean two variables independent helps measure association play video starting 756 follow transcript 756 sum simply take consideration combinations values two random variables case random variable two values zero four combinations look form mutual information shows mutual information matches divergence actual joint distribution expected distribution independence assumption larger divergence higher mutual information play video starting 833 follow transcript 833 look exactly probabilities involved formula mutual information play video starting 841 follow transcript 841 probabilities involve easy verify basically inaudible probabilities corresponding presence absence word w1 two probabilities play video starting 92 follow transcript 902 sum word present absent segment similarly second word two probabilities representing presence absences word y play video starting 921 follow transcript 921 finally lot joined probabilities represent scenarios cooccurrences two words play video starting 934 follow transcript 934 sum two words four possible scenarios occur case variables value occurs two scenarios play video starting 951 follow transcript 951 two cases random variables equal zero finally scenario occurs two variables taking value zero play video starting 107 follow transcript 1007 probabilities involved calculation mutual information play video starting 1016 follow transcript 1016 know calculate probabilities easily calculate mutual information play video starting 1024 follow transcript 1024 interesting know actually relations constraint probabilities two right previous slide marginal probabilities words sum constraint says two words four scenarios cooccurrency additional constraints listed bottom play video starting 1058 follow transcript 1058 example means add probabilities observe two words occur probabilities word occurs second word occur exactly probability word observed words word observed word observed two scenarios depending second word observed probability captures scenario second word actually observed captures second scenario second word observed word easy equations follow reasoning play video starting 1146 follow transcript 1146 equations allow compute probabilities based probabilities simplify computation play video starting 1155 follow transcript 1155 specifically know probability word present case know know probability presence second word easily compute absence probability right easy equation take care computation probabilities presence absence word lets look inaudible distribution assume available probability occurred easy actually compute rest probabilities based play video starting 1246 follow transcript 1246 specifically example equation compute probability word occurred second word did know probabilities boxes similarly equation compute probability observe second word word finally probability calculated equation known known known right easier calculate calculated play video starting 1326 follow transcript 1326 slide shows know compute three probabilities boxes naming presence word cooccurence words segment music
play video starting follow transcript 000 sound play video starting 6 follow transcript 006 general empirical count events observed data estimate probabilities commonly technique called maximum likelihood estimate simply normalize observe accounts compute probabilities follows estimating probability water current segment simply normalize count segments contain word lets take look data right side list hypothesizes data segments segments words occur indicated ones columns cases occur column column zero course cases words occur zeros estimating probabilities simply collect three counts play video starting 120 follow transcript 120 three counts count w1 thats total number segments contain word w1 ones column w1 count ones segment count word 2 count ones second column give total number segments contain w2 third count words occur time going count sentence columns ones play video starting 156 follow transcript 156 give total number segments w1 w2 counts normalize counts n total number segments give probabilities compute original information small problem zero counts case dont zero probability data small sample general believe potentially possible inaudible avoid context address problem technique called smoothing thats basically add small constant counts dont zero probability case best way understand smoothing imagine actually observed data actually pretend observed pseudosegments illustrated top right side slide pseudosegments contribute additional counts words event zero probability particular introduce four pseudosegments weighted quarter represent four different combinations occurrences word event combination least count least nonzero count pseudosegment actual segments observe okay havent observed combinations specifically 05 comes two ones two pseudosegments weighted quarter add 05 similar 005 comes single pseudosegment indicates two words occur play video starting 49 follow transcript 409 course denominator add total number pseudosegments add case added four pseudosegments weighed quarter total sum thats denominator youll play video starting 425 follow transcript 425 basically concludes discussion compute four syntagmatic relation discoveries play video starting 436 follow transcript 436 summarize syntagmatic relation generally discovered measuring correlations occurrences two words weve introduced three concepts information theory entropy measures uncertainty random variable x conditional entropy measures entropy x given know y mutual information x y matches entropy reduction x due knowing y entropy reduction y due knowing x three concepts actually useful applications thats spent time explain detail particular useful discovering syntagmatic relations particular mutual information principal way discovering relation allows values computed different pairs words comparable rank pairs discover strongest syntagmatic collection documents note relation syntagmatic relation discovery inaudible relation discovery discussed possibility bm25 achieve waiting terms context potentially suggest candidates syntagmatic relations candidate word mutual information discover syntagmatic relations represent context mutual information weights give way represent context word cat words cluster words compare similarity words based context similarity provides way term weighting paradigmatic relation discovery summarize part word association mining introduce two basic associations called paradigmatic syntagmatic relations fairly general apply items language units dont words phrases entities play video starting 711 follow transcript 711 introduced multiple statistical approaches discovering mainly showing pure statistical approaches visible variable discovering relations combined perform joint analysis approaches applied text human effort based counting words actually discover interesting relations words play video starting 744 follow transcript 744 different ways defining context segment lead interesting variations applications example context narrow words word sentence paragraphs differing contexts allows discover different flavors paradigmatical relations similarly counting cooccurrences lets say visual information discover syntagmatical relations define segment segment defined narrow text window longer text article give different kinds associations discovery associations support applications information retrieval text data mining recommended readings know topic book chapter collocations relevant topic lectures second article various statistical measures discover lexical atoms phrases noncompositional example hot dog dog thats hot play video starting 98 follow transcript 908 blue chip chip thats blue paper discussion techniques discovering phrases play video starting 917 follow transcript 917 third new paper unified way discover paradigmatical relations syntagmatical relations random works word graphs sound
play video starting follow transcript 000 sound lecture topic mining analysis going talk motivation task definition play video starting 17 follow transcript 017 lecture going talk different mining task play video starting 23 follow transcript 023 road map covered mining knowledge language discovery word associations paradigmatic relations syntagmatic relations play video starting 39 follow transcript 039 starting lecture going talk mining knowledge content mining trying discover knowledge main topics text play video starting 56 follow transcript 056 call topic mining analysis play video starting 59 follow transcript 059 lecture going talk motivation task definition lets look concept topic topic understand think actually easy formally define roughly speaking topic main idea discussed text data think theme subject discussion conversation different granularities example talk topic sentence topic article aa topic paragraph topic research articles research library right different grand narratives topics obviously different applications play video starting 146 follow transcript 146 applications require discovery topics text theyre analyzed examples example interested knowing twitter users talking today talking nba sports talking international events interested knowing research topics example interested knowing current research topics data mining different five years ago involves discovery topics data mining literatures discover topics todays literature past make comparison interested knowing people products iphone 6 dislike involves discovering topics positive opinions iphone 6 negative reviews interested knowing major topics debated 2012 presidential election play video starting 259 follow transcript 259 discovering topics text analyzing going talk lot techniques general view topic knowledge world text data expect discover number topics topics generally description world tells world product person play video starting 329 follow transcript 329 nontext data context analyzing topics example know time associated text data locations text data produced authors text sources text meta data context variables associated topics discover context variables help analyze patterns topics example looking topics time able discover theres trending topic topics fading away play video starting 415 follow transcript 415 soon looking topics different locations know insights peoples opinions different locations play video starting 426 follow transcript 426 thats mining topics important lets look tasks topic mining analysis general involve discovering lot topics case k topics know topics covered documents extent example document topic 1 covered lot topic 2 topic k covered small portion play video starting 458 follow transcript 458 topics covered document two hand covered topic 2 did cover topic 1 covers topic k extent right generally two different tasks subtasks discover k topics collection text laid k topics okay major topics text second task figure documents cover topics extent formally define problem follows input collection n text documents denote text collection c denote text article d generally input number topics k techniques automatically suggest number topics techniques discuss useful techniques specify number topics play video starting 614 follow transcript 614 output k topics discover order theta sub theta sub k play video starting 624 follow transcript 624 generate coverage topics document d sub denoted pi sub j play video starting 633 follow transcript 633 pi sub ij probability document d sub covering topic theta sub j obviously document set values indicate extent document covers topic play video starting 648 follow transcript 648 assume probabilities sum document wont able cover topics topics discussed discovered question define theta sub define topic problem completely defined define exactly theta play video starting 716 follow transcript 716 lectures going talk different ways define theta music
play video starting 6 follow transcript 006 lecture probabilistic topic models topic mining analysis play video starting 13 follow transcript 013 lecture going continue talking topic mining analysis play video starting 18 follow transcript 018 going introduce probabilistic topic models play video starting 22 follow transcript 022 slide earlier discussed problems term topic solve problems intuitively words describe topic address problem lack expressive power words describe topic describe complicated topics address second problem introduce weights words allows distinguish subtle differences topics introduce semantically related words fuzzy manner finally solve problem word ambiguity split ambiguous word disambiguate topic play video starting 115 follow transcript 115 turns done probabilistic topic model thats going spend lot lectures talk topic basic idea improve replantation topic distribution older replantation replanted topic word term phrase going word distribution describe topic sports going word distribution theoretical speaking words vocabulary play video starting 154 follow transcript 154 example high probability words sports game basketball football play star sports related terms course give nonzero probability word trouble related sports general related topic play video starting 218 follow transcript 218 general imagine non zero probability words words read small probabilities probabilities sum play video starting 231 follow transcript 231 forms distribution words play video starting 236 follow transcript 236 intuitively distribution represents topic assemble words distribution tended words ready dispose play video starting 248 follow transcript 248 special case probability mass concentrated entirely word sports basically degenerates symbol foundation topic word play video starting 34 follow transcript 304 distribution topic representation general involve words describe topic model differences semantics topic similarly model travel science respective distributions distribution travel top words attraction trip flight play video starting 331 follow transcript 331 science scientist spaceship telescope genomics know science related terms doesnt mean sports related terms necessarily zero probabilities science general imagine words zero probabilities particular topic words small probabilities play video starting 358 follow transcript 358 words shared topics say shared means probability threshold word occurring topics case mark black travel example occurred three topics different probabilities highest probability travel topic 005 smaller probabilities sports science makes sense similarly star occurred sports science reasonably high probabilities actually related two topics replantation addresses three problems mentioned earlier uses multiple words describe topic allows describe fairly complicated topics second assigns weights terms model differences semantics bring related words model topic third probabilities word different topics disintegrate sense word text decode underlying topic address three problems new way representing topic course problem definition refined slightly slight similar youve added refinement topic topic word distribution word distribution know probabilities sum words vocabulary constraint constraint topic coverage pis pi sub ijs sum document play video starting 559 follow transcript 559 solve problem lets look problem computation problem clearly specify input output illustrate side input course text data c collection generally assume know number topics k hypothesize number try bind k topics dont know exact topics exist collection v vocabulary set words determines units treated basic units analysis cases words basis analysis means word unique play video starting 647 follow transcript 647 output consist set topics represented theta theta word distribution play video starting 656 follow transcript 656 know coverage topics document thats pi ijs play video starting 77 follow transcript 707 given set text data compute distributions coverages slide play video starting 718 follow transcript 718 course different ways solving problem theory write inaudible program solve problem going introduce general way solving problem called generative model fact general idea principle way statistical modeling solve text mining problems dimmed picture order show generation process idea approach actually design model data design probabilistic model model data generated course based assumption actual data arent necessarily generating way gave probability distribution data slide given particular model parameters denoted lambda template actually consists parameters interested parameters general control behavior probability risk model meaning set parameters different values give data points higher probabilities case course text mining problem precisely topic mining problem following plans theta word distribution snd set pis document n documents n sets pis set pi pi values sum say pretend word distributions coverage numbers generate data distributions model data way assume data actual symbols drawn model depends parameters interesting question play video starting 932 follow transcript 932 think parameters total obviously n multiplied k parameters pis k theta theta actually set probability values right distribution words leave exercise figure exactly parameters set model fit model data meaning estimate parameters infer parameters based data words adjust parameter values give data set maximum probability depending parameter values data points higher probabilities interested parameter values give data set highest probability illustrate problem picture x axis illustrate lambda parameters dimensional variable oversimplification obviously suffices show idea y axis shows probability data observe probability obviously depends setting lambda thats varies change value lambda interested find lambda star play video starting 115 follow transcript 1105 maximize probability observed data play video starting 1110 follow transcript 1110 estimate parameters parameters note precisely hoped discover text data wed treat parameters actually outcome output data mining algorithm general idea generative model text mining design model parameter values fit data fit data recover parameter value specific parameter value output algorithm treat actually discovered knowledge text data varying model course discover different knowledge summarize introduced new way representing topic representing word distribution advantage multiple words describe complicated topicit allow assign weights words variations semantics talked task topic mining answers define topic distribution importer clashing text articles number topics vocabulary set output set topics word distribution coverage topics document formally represented theta pi two constraints parameters constraints worded distributions worded distribution probability words sum 1 words vocabulary second constraint topic coverage document document allowed recover topic set topics discovering coverage k topics sum document introduce general idea generative model text mining idea design model model generation data simply assume generative way model embed parameters interested denoted lambda play video starting 1336 follow transcript 1336 infer likely parameter values lambda star given particular data set play video starting 1343 follow transcript 1343 take lambda star knowledge discovered text problem play video starting 1350 follow transcript 1350 adjust design model parameters discover various kinds knowledge text later lectures music
play video starting follow transcript 000 sound lecture overview statistical language models cover proper models special cases lecture going give overview statical language models models general models cover probabilistic topic models special cases statistical language model play video starting 31 follow transcript 031 statistical language model basically probability distribution word sequences example distribution gives today wednesday probability 001 give today wednesday nongrammatical sentence small probability play video starting 54 follow transcript 054 similarly sentence eigenvalue positive probability 00001 distribution clearly context dependent depends context discussion word sequences higher probabilities sequence words different probability different context play video starting 120 follow transcript 120 suggests distribution actually categorize topic play video starting 126 follow transcript 126 model regarded probabilistic mechanism generating text play video starting 133 follow transcript 133 means view text data data observed model reason call model generating model given model assemble sequences words example based distribution slide matter say assemble sequence today wednesday relative high probability sequence item value positive smaller probability occasionally today wednesday probability small play video starting 224 follow transcript 224 general order categorize distribution specify probability values different sequences words obviously impossible specify impossible enumerate possible sequences words practice simplify model way simplest language model called unigram language model case simply text generated generating word independently play video starting 32 follow transcript 302 general words generated independently make assumption significantly simplify language play video starting 312 follow transcript 312 basically probability sequence words w1 wn product probability word play video starting 324 follow transcript 324 model parameters number words vocabulary assume n words n probabilities word 1 assume text sample drawn word distribution means going draw word time eventually text play video starting 353 follow transcript 353 example try assemble words distribution wednesday today play video starting 46 follow transcript 406 words eigenvalue small probability etcetera actually compute probability sequence model specify probabilities words independence specifically compute probability today wednesday play video starting 434 follow transcript 434 product probability today probability probability wednesday example show fake numbers multiply numbers probability todays wednesday n probabilities word actually characterize probability situation kinds sequences words simple model ignore word order fact problems speech recognition care order words turns sufficient tasks involve topic analysis thats interested model generally two problems think given model likely observe data points interested sampling process estimation process think parameters model given observe data going talk moment lets talk sampling show two examples water distributions unigram language models higher probabilities words text mining association separate play video starting 610 follow transcript 610 signals topic text mining assemble words distribution tend words occur text mining contest play video starting 623 follow transcript 623 case ask question probability generating particular document likely text looks text mining paper course text generate drawing words distribution unlikely coherent probability generating attacks mine inaudible publishing top conference nonzero assuming word zero probability distribution means essentially generate kinds text documents meaningful text documents play video starting 77 follow transcript 707 second distribution show bottom different high probabilities food inaudible healthy inaudible etcetera clearly indicates different topic case probably health sample word distribution probability observing text mining paper small play video starting 732 follow transcript 732 hand probability observing text looks food nutrition paper high relatively higher play video starting 741 follow transcript 741 means given particular distribution different text lets look estimation problem case going assume observed data know exactly text data looks case lets assume text mining paper fact abstract paper total number words 100 ive counts individual words play video starting 812 follow transcript 812 ask question likely play video starting 817 follow transcript 817 language model generate text data assuming text observed language model whats best guess language model play video starting 830 follow transcript 830 okay problem estimate probabilities words ive play video starting 837 follow transcript 837 think guess play video starting 840 follow transcript 840 guess text small probability relatively large probability play video starting 848 follow transcript 848 query guess probably dependent times observed word text data right think moment guessed text probability 10 100 ive observed text 10 times text total 100 words similarly mining 5 100 query relatively small probability observed 1 100 right intuitively reasonable guess question best guess best estimate parameters play video starting 937 follow transcript 937 course order answer question define mean best case turns guesses best sense called maximum likelihood estimate best thing give observer data maximum probability play video starting 101 follow transcript 1001 meaning change estimate slightly probability observed text data smaller called maximum likelihood estimate music
play video starting follow transcript 000 music lets talk problem bit specifically lets talk two different ways estimating parameters called maximum likelihood estimate mentioned bayesian estimation maximum likelihood estimation define best meaning data likelihood reached maximum formally given expression define estimate arg max probability x given theta play video starting 46 follow transcript 046 arg max means actually function turn argument gives function maximum value adds value value arg max value function argument made function reaches maximum case value arg max theta theta makes probability x given theta reach maximum estimate due makes sense useful seeks premise best explains data problem data small data points small data points sample small trust data entirely try fit data biased case text data lets say observed 100 words did contain word related text mining maximum likelihood estimator give word zero probability giving nonzero probability take away probability mass observer word obviously optimal terms maximizing likelihood observer data play video starting 211 follow transcript 211 zero probability unseen words reasonable especially distribution characterize topic text mining way address problem actually bayesian estimation actually look data prior knowledge parameters assume prior belief parameters case course play video starting 247 follow transcript 247 going look data look prior play video starting 254 follow transcript 254 prior defined p theta means impose preference thetas play video starting 36 follow transcript 306 bayes rule play video starting 312 follow transcript 312 combine likelihood function prior give play video starting 323 follow transcript 323 posterior probability parameter full explanation bayes rule things related bayesian reasoning scope course gave brief introduction general knowledge useful bayes rule basically defined allows write conditional probability x given y terms conditional probability y given x two probabilities different order two variables play video starting 49 follow transcript 409 rule making inferences variable lets take look assume px encodes prior belief x means observe data thats belief x believe x values higher probability play video starting 440 follow transcript 440 probability x given y conditional probability posterior belief x belief x values observed y given observed y believe x believe values higher probabilities play video starting 59 follow transcript 509 two probabilities related regarded probability play video starting 519 follow transcript 519 observed evidence y given particular x think x hypothesis prior belief hypothesis observed y update belief updating formula based combination prior play video starting 548 follow transcript 548 likelihood observing y x true play video starting 557 follow transcript 557 detour bayes rule case interested inferring theta values prior includes prior knowledge parameters play video starting 615 follow transcript 615 data likelihood tell parameter value explain data posterior probability combines play video starting 630 follow transcript 630 represents compromise two preferences case maximize posterior probability find theta maximize posterior probability estimator called maximum posteriori map estimate play video starting 655 follow transcript 655 estimator general estimator maximum likelihood estimator define prior noninformative prior meaning uniform theta values preference basically back maximum likelihood estimated case mainly going determined likelihood value play video starting 728 follow transcript 728 informative prior bias different values map estimator allow incorporate problem course define prior play video starting 744 follow transcript 744 free lunch solve problem knowledge knowledge knowledge ideally reliable estimate necessarily accurate maximum likelihood estimate play video starting 81 follow transcript 801 lets look bayesian estimation detail play video starting 88 follow transcript 808 show theta values dimension value thats simplification course interested variable theta optimal prior prior tells variables likely believe example values likely values places play video starting 842 follow transcript 842 prior theta likelihood case theta tells values theta likely means loose syllables best expand theta play video starting 91 follow transcript 901 combine two posterior distribution thats compromise two say inbetween look interesting point made point represents mode prior means likely parameter value prior observe data play video starting 925 follow transcript 925 point maximum likelihood estimator represents theta gives theta maximum probability play video starting 932 follow transcript 932 point interesting posterior mode play video starting 938 follow transcript 938 likely value theta given posterior represents good compromise prior mode maximum likelihood estimate play video starting 951 follow transcript 951 general bayesian inference interested distribution parameter additives theres distribution values p theta given x play video starting 109 follow transcript 1009 problem bayesian inference play video starting 1014 follow transcript 1014 infer posterior regime infer interesting quantities depend theta show f theta interesting variable compute order compute value know value theta bayesian inference treat theta uncertain variable think possible variables theta estimate value function f extracted value f posterior distribution theta given observed evidence x play video starting 1058 follow transcript 1058 special case assume f theta equal theta case expected value theta thats basically posterior mean gives point theta posterior mode gives way estimate parameter play video starting 1124 follow transcript 1124 general illustration bayesian estimation influence later useful topic mining inject sum prior knowledge topics summarize weve language model basically probability distribution text called generative model text data simplest language model unigram language model basically word distribution play video starting 1154 follow transcript 1154 introduced concept likelihood function probability data given model play video starting 122 follow transcript 1202 function important play video starting 125 follow transcript 1205 given particular set parameter values function tell x data point higher likelihood higher probability play video starting 1216 follow transcript 1216 given data sample x function determine parameter values maximize probability observed data maximum livelihood estimate play video starting 1231 follow transcript 1231 talk bayesian estimation inference case define prior parameters p theta interested computing posterior distribution parameters proportional prior likelihood play video starting 1248 follow transcript 1248 distribution allow infer derive theta music
play video starting follow transcript 000 sound lecture continued discussion probabilistic topic models lecture going continue discussing probabilistic models going talk simple case interested mining topic document play video starting 30 follow transcript 030 simple setup interested analyzing document trying discover topic simplest case topic model input longer k number topics know topic collection document output longer coverage assumed document covers topic 100 main goal discover world probabilities single topic play video starting 114 follow transcript 114 think generating model solve problem start thinking data going model perspective going model data data representation going design specific model generating data perspective perspective means take particular angle looking data model right parameters discovering knowledge thinking microfunction write microfunction capture formally likely data point obtained model play video starting 25 follow transcript 205 likelihood function parameters function argue interest estimating parameters example maximizing likelihood lead maximum likelihood estimated estimator parameters output mining hours means take estimating parameters knowledge discover text lets look steps simple case later look procedure complicated cases data case document sequence words word denoted x sub model unigram language model word distribution hope denote topic thats goal parameters words vocabulary case m play video starting 39 follow transcript 309 convenience going theta sub denote probability word w sub play video starting 320 follow transcript 320 obviously theta sub sum 1 play video starting 324 follow transcript 324 likelihood function look probability generating document given model assume independence generating word probability document product probability word play video starting 342 follow transcript 342 word repeated occurrences rewrite product different form play video starting 352 follow transcript 352 line rewritten formula product unique words vocabulary w sub 1 w sub m different previous line product different positions words document play video starting 415 follow transcript 415 transformation introduce counter function denotes count word document similarly count words n document words repeated occurrences word did occur document play video starting 441 follow transcript 441 zero count corresponding term disappear useful form writing likelihood function later pay attention familiar notation change product different words vocabulary end course theta sub express likelihood function look going find theta values probabilities words maximize likelihood function lets take look maximum likelihood estimate problem closely play video starting 532 follow transcript 532 line copied previous slide likelihood function play video starting 538 follow transcript 538 goal maximize likelihood function find easy play video starting 547 follow transcript 547 maximize local likelihood original likelihood purely mathematical convenience logarithm transformation function sum product constraints probabilities sum makes easier take derivative needed finding optimal solution function please take look sum form function later general topic models sum words vocabulary sum count word document macroed logarithm probability play video starting 655 follow transcript 655 lets solve problem play video starting 658 follow transcript 658 point problem purely mathematical problem going find optimal solution constrained maximization problem objective function likelihood function constraint probabilities sum way solve problem lagrange multiplier approace play video starting 724 follow transcript 724 command scope course lagrange multiplier useful approach give brief introduction interested play video starting 739 follow transcript 739 approach construct lagrange function function combine objective function term encodes constraint introduce lagrange multiplier lambda additional parameter idea approach turn constraint optimization sense unconstrained optimizing problem interested optimizing lagrange function play video starting 819 follow transcript 819 recall calculus optimal point achieved derivative set zero necessary condition sufficient partial derivative respect theta equal part comes derivative logarithm function lambda simply taken set zero easily theta sub related lambda way play video starting 96 follow transcript 906 know theta sum plug constraint allow solve lambda play video starting 916 follow transcript 916 net sum counts allows solve optimization problem eventually find optimal setting theta sub look formula turns actually intuitive normalized count words document ns sum counts words document mess obtained thats intuitive intuition maximize data assigning probability mass possible observed words notice general result maximum likelihood raised estimator general estimator normalize counts counts done particular way later basically analytical solution optimization problem general likelihood function complicated going able solve optimization problem having closed form formula numerical algorithms going cases later imagine maximum likelihood estimator estimate topic single document d lets imagine document text mining paper looks top high probability words tend common words functional words english followed content words characterize topic text mining end probability words related topic extraneously mentioned document topic representation ideal right high probability words functional words characterizing topic question rid common words play video starting 1159 follow transcript 1159 topic module going talk probabilistic models rid common words music
technology review information cs410 technology review 4credit students cs410 technology review technology review assignment designed students opportunity materials covered course lectures learn interesting courserelated cuttingedge technology topic covered lecture assignment student required write short review article chosen topic student list suggested topics instructor tas student propose topic list subject approval instructor topic technology review three broad topic categories related general topic “text data retrieval analysis” 1 useful software toolkits processing text data building text data applications 2 emerging new applications text retrieval analysis 3 new techniques text retrieval analysis list specific topics provided students students propose additional topics interesting subject approval instructor review cover toolkitapplicationtechnique indepth compare multiple toolkitsapplicationstechniques former allowed toolkitapplicationtechnique sufficiently complex justify devoting entire review case review novel content exist existing literature webpages offer unique informationknowledge learn review please make sure check review topic devote time complete review find existing review topic write topic make sure take different perspective existing review add new content top existing review extending way technology review completed individually graded based completion following two tasks 1 topic proposal student required select topic provided topic list propose topic deadline topic selection deadline technology review submission deadline inspiration list topics students httpsdocsgooglecomspreadsheetsd1hwayxd82fcitn9eg3ymw6ckq6l1vasbtywpapbywmpcedituspsharing opens new tab sample topics provided httpsdocsgooglecomspreadsheetsd1yekm8hjbyrghiudvzv9s3zzu5hdteto6yecivposedituspsharing opens new tab 2 review submission student required submit complete technology review end 11 nov 6 2021 review coherent storyline intro body conclusion cite relevant references least 2 pages deadline set earlier time course project code submission give students opportunity read relevant reviews especially toolkits finishing projects mark completed item completed dislike report issue
9 overview weeks lessons learn topic analysis depth mixture models work expectationmaximization em algorithm estimate parameters mixture model basic topic model probabilistic latent semantic analysis plsa latent dirichlet allocation lda extends plsa time module take approximately 35 hours dedicated time complete videos assignments activities activities module listed required assignments bold activity estimated time required 9 video lectures 2 hours 9 graded quiz 1 hour project proposal team formation submission grading 30 mins goals objectives actively engage learning experiences module able explain mixture unigram language model background language mixture help “absorb” common words english explain plsa mine analyze topics text explain general idea generative model text mining explain compute probability observing word mixture model plsa explain basic idea em algorithm works explain main difference lda plsa guiding questions develop answers following guiding questions watching video lectures mixture model general compute probability observing particular word mixture model general form expression probability maximum likelihood estimate component word distributions mixture model behave sense “collaborate” andor “compete” fixed background word distribution force discovered topic word distribution reduce probability common noncontent words basic idea em algorithm estep typically mstep typically two steps typically apply bayes rule em converge global maximum plsa parameters plsa model number affected size data set mined adjust standard plsa incorporate prior topic word distribution lda different plsa shared two models additional readings resources following readings optional c zhai s massung text data management analysis practical introduction information retrieval text mining acm morgan claypool publishers 2016 chapter 17 blei d 2012 probabilistic topic models communications acm 55 4 77–84 doi 10114521338062133826 qiaozhu mei xuehua shen chengxiang zhai automatic labeling multinomial topic models proceedings acm kdd 2007 pp 490499 doi10114512811921281246 yue lu qiaozhu mei chengxiang zhai 2011 investigating task performance probabilistic topic models empirical study plsa lda information retrieval 14 2 april 2011 178203 doi 101007s1079101091419 key phrases concepts keep eyes open following key terms phrases complete readings interact lectures topics help better understand content module mixture model component model constraints probabilities probabilistic latent semantic analysis plsa expectationmaximization em algorithm estep mstep hidden variables hill climbing local maximum latent dirichlet allocation lda tips success recommend following review video lectures number times gain solid understanding key questions concepts introduced possible tips suggestions peers class learning community help learn grow way helping address questions peers pose engaging we’ll learn better it’s good idea refer video lectures chapter readings weve read reference responses appropriate critique information presented take notes read materials watch lectures taking notes interacting material find easier remember understand notes you’ll find it’s easier complete assignments ahead favor take notes getting giving help getgive help following means learner help center opens new tab find information regarding specific technical problems example technical problems error messages difficulty submitting assignments problems video playback find answer documentation report problem coursera staff clicking contact link available topics page learner help center content issues opens new tab forum report errors lecture video content assignment questions answers assignment grading text links course pages content course materials university illinois staff community tas monitor forum respond issues mark completed item completed dislike report issue
play video starting 6 follow transcript 006 lecture mixture model estimation lecture going continue discussing probabilistic topic models particular going talk estimate parameters mixture model lets look motivation mixture model hope effect background words topic word distribution idea assume text data actually contain two kinds words background topic word distribution interested order solve problem factoring background words set mixture model follows going assume know parameters values parameters mixture model word distribution theta sub d target case customizing probably model embedded unknown variables interested going simplify things going assume knowledge powerful way customizing model particular imagine assumed dont know background word distribution case goal affect precisely high probability background words assume background model fixed problem adjust theta sub d order maximize probability observed document assume parameters known designed modal heuristically try factor background words unclear maximum likelihood estimator actually end having word distribution common words having smaller probabilities case turns answer yes set probabilistic modeling way maximum likelihood estimator end having word distribution common words factored background distribution understand useful examine behavior mixture model going look simple case order understand interesting behaviors mixture model observed patterns actually generalizable mixture model general easier understand behavior simple case specifically case lets assume probability choosing two models exactly going flip fair coin decide model going assume precisely words text obviously naive oversimplification actual text useful examine behavior special case assume background model gives probability 09 word text 01 lets assume data extremely simple document two words text lets write likelihood function case whats probability text whats probability hope point able write probability text basically sum two cases case corresponds water distribution accounts two ways generating text case probability choosing model 05 multiplied probability observing text model similarly probability form different exactly probabilities naturally likelihood function product two easy understand whats probability word important understand whats exactly probability observing word mixture model interesting question optimize likelihood notice two variables precisely two probabilities two words text given theta sub d assumed parameters known question simple algebra question simple expression two variables hope values two variables maximize function exercises simple algebra problems note two probabilities sum theres constraint constraint course set probabilities maximum value maximize cant text sum cant give probability question allocate probability mass two words think useful look formula moment intuitively order set probabilities maximize value function look interesting behavior two component models collaborating maximize probability observed data dictated maximum likelihood estimator theyre competing way particular competing words tend bet high probabilities different words avoid competition sense gain advantage competition looking objective function constraint two probabilities look formula intuitively feel set probability text larger intuition wellsupported mathematical fact sum two variables constant product maximum equal fact know algebra plug mean make two probabilities equal make equal consider constraint easily solve problem solution probability text 09 probability 01 probability text larger probability case distribution clearly background model assign high probability low probability text look equation obviously interaction two distributions particular order make equal probability assigned theta sub d higher word smaller probability given background obvious examining equation background part weak text small order compensate make probability text thats given theta sub d larger two sides balanced fact general behavior mixture model distribution assigns high probability word distribution tend opposite basically discourage distributions balance account words means background model fixed assign high probabilities background words encourage unknown topic word distribution assign smaller probabilities common words put probability mass content words explained background model meaning small probability background model text
play video starting follow transcript 000 sound lecture probabilistic latent semantic analysis plsa play video starting 12 follow transcript 012 lecture going introduce probabilistic latent semantic analysis called plsa basic topic model useful topic models models general mine multiple topics text documents prsa basic topic models lets examine power email detail show sample article blog article hurricane katrina play video starting 48 follow transcript 048 show simple topics example government response flood city new orleans donation background play video starting 59 follow transcript 059 article words distributions play video starting 15 follow transcript 105 example theres criticism government response followed discussion flooding city donation cetera background words mixed play video starting 118 follow transcript 118 overall topic analysis try decode topics text segment topics figure words distribution figure topics know theres topic government response theres topic flood city tasks top model play video starting 142 follow transcript 142 discovered topics color words separate different topics lot things summarization segmentation topics clustering sentences formal definition problem mining multiple topics text slide earlier lecture input collection number topics vocabulary set course text data play video starting 216 follow transcript 216 output two kinds topic category characterization theta theta word distribution second topic coverage document pi sub js tell document covers topic extent hope generate output useful applications play video starting 242 follow transcript 242 idea plsa actually similar two component mixture model introduced difference going two topics essentially illustrate generate text multiple topics naturally cases probabilistic modelling figure likelihood function ask question whats probability observing word mixture model look picture compare picture earlier difference added topics play video starting 326 follow transcript 326 topic background topic topics specifically k topics topics assume exist text data consequence switch choosing topic multiway switch two way switch think flipping coin multiple ways flip coin decide talk background background lambda sub b versus nonbackground 1 minus lambda sub b gives probability actually choosing nonbackground topic made decision make decision k distributions k way switch characterized pi sum play video starting 431 follow transcript 431 difference designs bit complicated decide distribution rest going generate word distributions play video starting 446 follow transcript 446 lets look question likelihood whats probability observing word distribution think weve problem times recall generally sum different possibilities generating word lets look word generated background mode probability word generated background model lambda multiplied probability word background mode model right two things happen chosen background model thats probability lambda sub b second actually obtained word w background thats probability w given theta sub b play video starting 540 follow transcript 540 okay similarly figure probability observing word topic topic theta sub k notice heres product three terms thats choice topic theta sub k happens two things happen decide talk background thats probability 1 minus lambda sub b second actually theta sub k k topics thats probability theta sub k pi play video starting 617 follow transcript 617 similarly probability generating word second topic topic end probability observing word sum cases stress important formula know key understanding topic models lot mixture models make sure understand probability play video starting 649 follow transcript 649 w sum terms play video starting 656 follow transcript 656 likelihood function interested knowing parameters right estimate parameters firstly lets put complete likelihood function plsa line shows probability word illustrated previous slide important formula play video starting 722 follow transcript 722 lets take closer look actually commands important parameters lambda sub b represents percentage background words play video starting 732 follow transcript 732 believe exist text data known value set empirically play video starting 741 follow transcript 741 second background language model typically assume known large collection text text available estimate world distribution play video starting 752 follow transcript 752 stop formula cough excuse two interesting parameters important parameters pis coverage topic document play video starting 811 follow transcript 811 word distributions characterize topics play video starting 818 follow transcript 818 line simply plug calculate probability document familiar form sum count word document log probability bit complicated two component components sum involves terms line likelihood collection similar accounting documents collection play video starting 852 follow transcript 852 unknown parameters two kinds coverage word distributions useful exercise think exactly parameters play video starting 95 follow transcript 905 unknown parameters try think question help understand model detail allow understand output generate plsa analyze text data precisely unknown parameters play video starting 924 follow transcript 924 obtained likelihood function worry parameter estimation play video starting 932 follow transcript 932 usual think maximum likelihood estimator constrained optimization problem collection text parameters estimate two constraints two kinds constraints word distributions play video starting 951 follow transcript 951 words probabilities thats sum distribution topic coverage distribution document cover precisely k topics probability covering topic sum 1 point basically defined applied math problem figure solutions optimization problem theres function variables figure patterns variables make function reach maximum music
play video starting follow transcript 000 sound play video starting 8 follow transcript 008 compute maximum estimate em algorithm e step introduce hidden variables topics hidden variable z topic indicator take two values specifically take k plus values b noting background locate denote k topics right play video starting 36 follow transcript 036 e step recall augmented data predicting values hidden variable going predict word word come k plus distributions equation allows predict probability word w document d generated topic zero sub j play video starting 13 follow transcript 103 bottom predicted probability word generated background note document d index word word particular topic actually depends document pis pis tied document document potentially different pis right pis affect prediction pis depends document play video starting 138 follow transcript 138 give different guess word different documents thats desirable play video starting 146 follow transcript 146 cases bayes rule explained basically assessing likelihood generating word division theres normalize play video starting 157 follow transcript 157 m step recall m step take advantage inferred z values split counts collected right counts reestimate parameters case reestimate coverage probability reestimated based collecting words document play video starting 222 follow transcript 222 thats count word document sum words going look extent word belongs play video starting 234 follow transcript 234 topic theta sub j part guess step play video starting 240 follow transcript 240 tells likely word actually theta sub j multiply discounted count thats located topic theta sub j normalize topics distribution topics indicate coverage similarly bottom estimated probability word topic case exact count discounted account tells extend allocate word inaudible normalization different case interested word distribution simply normalize words different contrast normalize amount topics useful take comparison two play video starting 337 follow transcript 337 give different distributions tells improve parameters play video starting 348 follow transcript 348 explained formula maximum estimate based allocated word counts inaudible phenomena actually general phenomena em algorithms mstep general computer expect account event based estep result count four particular normalize typically terms computation em algorithm actually keep accounting various events normalize thinking way concise way presenting em algorithm actually helps better understand formulas im going detail algorithm initialize unknown perimeters randomly right case interested coverage perimeters pis awarded distributions inaudible randomly normalize initialization step repeat likelihood converges know likelihood converges compute likelihood step compare current likelihood previous likelihood doesnt change going say stopped right play video starting 519 follow transcript 519 step going estep mstep estep going augment data predicting hidden variables case hidden variable z sub d w indicates word w d topic background topic topic look estep formulas essentially actually normalizing counts sorry probabilities observing word distribution basically prediction word topic zero sub j based probability selecting theta sub j word distribution generate word multiply probability observing word distribution play video starting 617 follow transcript 617 proportional implementation em algorithm keep counter quantity end normalizes normalization topics probability play video starting 636 follow transcript 636 mstep going collect play video starting 643 follow transcript 643 allocated account topic play video starting 647 follow transcript 647 split words topics play video starting 650 follow transcript 650 going normalize different ways obtain real estimate example normalize topics reestimate pi coverage renormalize based words give word distribution play video starting 710 follow transcript 710 useful think algorithm way implemented variables keep track quantities case play video starting 723 follow transcript 723 normalize variables make distribution play video starting 732 follow transcript 732 did put constraint intentionally leave exercise whats normalizer slightly different form essentially general envisioning em algorithms accumulate counts various counts normalize play video starting 81 follow transcript 801 summarize introduced plsa model mixture model k unigram language models representing k topics play video starting 811 follow transcript 811 added predetermined background language model help discover discriminative topics background language model help attract common terms play video starting 823 follow transcript 823 select maximum estimate cant discover topical knowledge text data case plsa allows discover two things k worded distributions representing topic proportion topic document play video starting 841 follow transcript 841 detailed characterization coverage topics documents enable lot photo analysis example aggregate documents particular pan period assess coverage particular topic time period allow generate temporal chains topics aggregate topics covered documents associated particular author categorize topics written author addition cluster terms cluster documents fact topic regarded cluster term clusters higher probability words regarded play video starting 929 follow transcript 929 belonging cluster represented topic similarly documents clustered way assign document topic cluster thats covered document remember pis indicate extent topic covered document assign document topical cluster highest pi play video starting 957 follow transcript 957 general useful applications technique play video starting 103 follow transcript 1003 music
play video starting 7 follow transcript 007 lecture latent dirichlet allocation lda lecture going continue talking topic models particular going talk extension plsa lda latent dirichlet allocation plan lecture cover two things extend plsa prior knowledge allow sense usercontrolled plsa doesnt apply listen data listen needs second extend plsa generative model fully generative model led development latent dirichlet allocation lda lets talk plsa prior knowledge practice apply plsa analyze text data additional knowledge inject guide analysis standard plsa going blindly listen data maximum inaudible going fit data insight data useful user expectations topics analyze example expect retrieval models topic information retrieval interesting aspects battery memory looking opinions laptop user particularly interested aspects user knowledge topic coverage know topic definitely covering document covering document example tags topic tags assigned documents tags treated topics document account generated topics corresponding tags assigned document document assigned tag going say way topic generate document document generated topics corresponding assigned tags question incorporate knowledge plsa turns elegant way incorporate knowledge priors models recall bayesian inference prior data estimate parameters precisely happen case maximum posteriori estimate called map estimate formula given basically maximize posteriori distribution probability combination likelihood data prior happen going estimate listens data listens prior preferences prior denoted p lambda encode kinds preferences constraints example encode having precise background topic encoded prior say prior parameters nonzero parameters contain topic equivalent background language model words cases going say prior says impossible probability models think zero prior example prior force particular choice topic probability number example force document d topic probability half prevent topic generating document say third topic generating document d set pi zero topic prior favor set parameters topics assign high probability particular words case going say impossible strongly favor distributions example later map computed similar em algorithm maximum likelihood estimate modifications parameters reflect prior preferences estimate special form prior code conjugate prior functional form prior similar data result combine two consequence basically convert inference prior inference having additional pseudo data two functional forms combined effect data convenient computation mean conjugate prior best way define prior look specific example suppose user particularly interested battery life laptop analyzing reviews prior says distribution contain distribution assign high probability battery life say distribution concentrated battery life prior says distributions similar map estimate conjugate prior original prior original distribution based preference difference em reestimate words distributions going add additional counts reflect prior pseudo counts defined based probability words prior battery obviously high pseudo counts similarly life high pseudo counts words zero pseudo counts probability zero prior controlled parameter mu going add mu probability w given prior distribution connected accounts reestimate word distribution step changed change happening connect counts words believe generated topic force distribution give probabilities words adding pseudo counts fact artificially inflated probabilities make distribution add pseudo counts denominator total sum pseudo counts added words make gamma distribution intuitively reasonable way modifying em theoretically speaking works computes map estimate useful think two specific extreme cases mu inaudible picture think happen set mu zero essentially remove prior mu sense indicates strengths prior happen set mu positive infinity say prior strong going listen data end case going make distributions fixed prior mu infinitive basically dominate fact going set precise distribution case distribution background language model fact way impose prior force distribution exactly give background distribution case force distribution entirely focus battery life course work attract words affect accuracy counting topics battery life practice mu set course way impose prior impose constraints example set parameters constantly zero needed example set pis zero mean allow topic participate generating document reasonable course prior analogy strongly suggests
10 overview weeks lessons learn text clustering basic concepts main clustering techniques evaluate text clustering start learning text categorization related text clustering predefined categories viewed predefining clusters time module take approximately 3 hours dedicated time complete videos assignments activities activities module listed required assignments bold activity estimated time required 10 video lectures 2 hours 10 graded quiz 1 hour goals objectives actively engage learning experiences module able explain concept text clustering useful explain hierarchical agglomerative clustering kmeans clustering work explain evaluate text clustering explain concept text categorization useful explain naïve bayes classifier works guiding questions develop answers following guiding questions watching video lectures clustering applications clustering text mining analysis hierarchical agglomerative clustering work singlelink completelink averagelink work computing group similarity three ways computing group similarity least sensitive outliers data evaluate clustering results text categorization applications text categorization training data categorization look naïve bayes classifier work logarithm scoring function naïve bayes additional readings resources following readings optional c zhai s massung text data management analysis practical introduction information retrieval text mining acm morgan claypool publishers 2016 chapters 14 15 manning chris d prabhakar raghavan hinrich schütze introduction information retrieval cambridge cambridge university press 2007 chapters 1316 yang yiming evaluation statistical approaches text categorization inf retr 1 12 1999 6990 doi 101023a1009982220290 key phrases concepts keep eyes open following key terms phrases complete readings interact lectures topics help better understand content module clustering document clustering term clustering clustering bias perspective similarity hierarchical agglomerative clustering kmeans direction evaluation clustering indirect evaluation clustering text categorization topic categorization sentiment categorization email routing spam filtering naïve bayes classifier smoothing tips success recommend following review video lectures number times gain solid understanding key questions concepts introduced possible tips suggestions peers class learning community help learn grow way helping address questions peers pose engaging we’ll learn better it’s good idea refer video lectures chapter readings weve read reference responses appropriate critique information presented take notes read materials watch lectures taking notes interacting material find easier remember understand notes you’ll find it’s easier complete assignments ahead favor take notes getting giving help getgive help following means learner help center opens new tab find information regarding specific technical problems example technical problems error messages difficulty submitting assignments problems video playback find answer documentation report problem coursera staff clicking contact link available topics page learner help center content issues opens new tab forum report errors lecture video content assignment questions answers assignment grading text links course pages content course materials university illinois staff community tas monitor forum respond issue mark completed item dislike report issue
11 overview weeks lessons continue learning various methods text categorization particularly discriminative qualifiers learn sentiment analysis opinion mining detailed introduction particular technique sentiment classification ordinal regression time module take approximately 4 hours dedicated time complete videos assignments activities activities module listed required assignments bold activity estimated time required 11 video lectures 2 hours 11 graded quiz 1 hour goals objectives actively engage learning experiences module able explain basic ideas logistic regression knearest neighbors knn knn works explain evaluate categorization results explain tasks opinion mining sentiment analysis important tasks application perspective explain sentiment analysis done text categorization techniques straightforward application regular text categorization techniques adequate give examples simple complex features characterizing text data explain nlp enable complex features generated text guiding questions develop answers following guiding questions watching video lectures what’s general idea logistic regression classifier related naïve bayes conditions logistic regression cover naïve bayes special case twocategory categorization what’s general idea knearest neighbor classifier work evaluate categorization results compute classification accuracy precision recall f score harmonic mean f better arithmetic mean precision recall what’s difference macro micro averaging interesting frame categorization problem ranking problem opinion different factual statement what’s opinion holder what’s opinion target what’s goal opinion mining sentiment analysis similar different text categorization task topic categorization unigram features generally insufficient accurate sentiment classification what’s concern complex features frequent substructures parse trees commonly features represent text data additional readings resources following readings optional c zhai s massung text data management analysis practical introduction information retrieval text mining acm morgan claypool publishers 2016 chapters 15 18 yang yiming evaluation statistical approaches text categorization inf retr 1 12 1999 6990 doi 101023a1009982220290 bing liu sentiment analysis opinion mining morgan claypool publishers 2012 bo pang lillian lee opinion mining sentiment analysis foundations trends information retrieva l 212 pp 1–135 2008 key phrases concepts keep eyes open following key terms phrases complete readings interact lectures topics help better understand content module generative classifier discriminative classifier training data logistic regression knearest neighbor classifier classification accuracy precision recall f measure macroaveraging microaveraging opinion holder opinion target sentiment opinion representation sentiment classification features ngrams frequent patterns overfitting tips success recommend following review video lectures number times gain solid understanding key questions concepts introduced possible tips suggestions peers class learning community help learn grow way helping address questions peers pose engaging we’ll learn better it’s good idea refer video lectures chapter readings weve read reference responses appropriate critique information presented take notes read materials watch lectures taking notes interacting material find easier remember understand notes you’ll find it’s easier complete assignments ahead favor take notes getting giving help getgive help following means learner help center opens new tab find information regarding specific technical problems example technical problems error messages difficulty submitting assignments problems video playback find answer documentation report problem coursera staff clicking contact link available topics page learner help center content issues opens new tab forum report errors lecture video content assignment questions answers assignment grading text links course pages content course materials university illinois staff community tas monitor forum respond issues mark completed item dislike report issue
play video starting follow transcript 000 sound lecture discriminative classifiers text categorization play video starting 13 follow transcript 013 lecture going continue talking text categorization cover discriminative approaches slide discussion naive bayes classifier naive bayes classifier tries model generation text data categories actually bayes rule eventually rewrite scoring function slide scoring function basically weighted combination lot word features feature values word counts feature weights log probability ratios word given two distributions play video starting 57 follow transcript 057 scoring function actually general scoring function general present text data feature vector course features dont words features signals mentioned precisely similar logistic regression lecture going introduce discriminative classifiers try model conditional distribution labels given data directly bayes rule compute interactively naive bayes general idea logistic regression model dependency binary response variable y predictors denoted x changed notation x future values play video starting 27 follow transcript 207 recall previous slides fi represent future values play video starting 213 follow transcript 213 notation x factor common introduce discriminative algorithms x input vector n features feature value x sub model dependency binary response variable features categorization problem two categories theta 1 theta 2 y value denote two categories y 1 means category document class theta 1 goal model conditional property y given x directly opposed model generation x y case naive bayes advantage approach allow features words vector modeling generation vector plug signals potentially advantageous text categorization specifically logistic regression assume functional form y depending x following closely related log odds introduced naive bayes log probability ratio two categories previous slide play video starting 357 follow transcript 357 meant case naive bayes compute words eventually reached formula looks play video starting 412 follow transcript 412 actually assume explicitly model probability y given x play video starting 429 follow transcript 429 directly function features play video starting 437 follow transcript 437 specifically assume ratio probability y equals 1 probability y equals 0 function x play video starting 454 follow transcript 454 right function x linear combination feature values controlled theta values play video starting 52 follow transcript 502 know probability y equals zero minus probability y equals written way log ratio play video starting 522 follow transcript 522 logistic regression basically assuming probability y equals 1 okay x dependent linear combination features possible ways assuming dependency particular form useful nice properties play video starting 547 follow transcript 547 rewrite equation actually express probability y given x terms x getting rid logarithm functional form called logistical function transformation x y play video starting 68 follow transcript 608 right side xs map range values 0 10 thats precisely probability play video starting 624 follow transcript 624 function form looks play video starting 628 follow transcript 628 basic idea logistic regression useful classifier lot classification tasks text categorization play video starting 641 follow transcript 641 cases model interested estimating parameters fact machine running programs set model set object function model file step compute parameter values general going adjust parameter values optimize performance classify training data case assume training data xi yi pair basically future vector x known label x y 1 0 case interested maximize conditional likelihood play video starting 731 follow transcript 731 conditional likelihood basically model given observe x moderate x going model note conditional probability y given x precisely wanted classification likelihood function product training cases case model probability observing particular training case given particular xi likely observe corresponding yi course yi 1 0 fact function found vary depending yi 1 0 1 taking form thats basically logistic regression function 0 0 different form thats play video starting 848 follow transcript 848 thats 1 minus probability y1 right play video starting 855 follow transcript 855 easily key point function form depends observer yi 1 different form 0 think maximize probability basically going probability high possible label 1 means document probability 1 document going maximize value whats going happen actually make value small possible sums 1 maximize equivalent minimize play video starting 948 follow transcript 948 basically maximize conditional likelihood going basically try make prediction training data accurate possible play video starting 10 follow transcript 1000 occasion compute maximum likelihood data basically youll find beta value set beta values maximize conditional likelihood play video starting 1012 follow transcript 1012 gives standard optimization problem case solved ways newtons method popular way solve problem methods end look set data values beta values way find scoring function help classify document play video starting 1039 follow transcript 1039 whats function beta values known compute xi document plug values give estimated probability document category play video starting 1059 follow transcript 1059 okay logistical regression lets introduce discriminative classifier called knearest neighbors general say approaches thorough introduction clearly scope course take machine learning course read machine learning know basic introduction commonly classifiers text calculation second classifier called knearest neighbors approach going estimate conditional probability label given data different way idea keep training examples text object classify going find k examples training set similar text object basically find neighbors text objector training data set found neighborhood found object close object interested classifying lets say found knearest neighbors thats method called knearest neighbors going assign category thats common neighbors basically going allow neighbors vote category objective interested classifying play video starting 1233 follow transcript 1233 means particular category category theyre going say current object category play video starting 1243 follow transcript 1243 approach improved considering distance neighbor current object basically assume closed neighbor say category subject give neighbor influence vote take away votes based distances play video starting 136 follow transcript 1306 general idea look neighborhood try assess category based categories neighbors intuitively makes lot sense mathematically regarded way directly estimate theres conditional probability label given data p y given x play video starting 1328 follow transcript 1328 im going explain intuition moment proceed emphasize similarity function order work note naive base class five did similarity function logistical regression did talk similarity function explicitly require similarity function similarity function actually good opportunity inject insights features basically effective features make objects category look similar distinguishing objects different categories design similarity function closely tied design features logistical regression classifiers lets illustrate knn works suppose lot training instances ive colored differently show different categories suppose new object center classify approach work finding neighbors lets think special case finding neighbor closest neighbor play video starting 1453 follow transcript 1453 case lets assume closest neighbor box filled diamonds going say object category diamonds lets say going say going assign category text object lets look possibility finding larger neighborhood lets think four neighbors play video starting 1526 follow transcript 1526 case going lot solid field boxes red pink right case going notice four neighbors three neighbors different category take vote conclude object actually different category illustrates nearest neighbor works illustrates potential problems classifier basically results depend k ks important parameter optimize intuitively imagine lot neighbors object wed okay lot neighbors help decide categories decision reliable hand find neighbor right votes hand try find neighbors actually risk getting neighbors similar instance actually away try neighbors neighbors neighbors arent necessarily helpful similar object parameter set empirically typically optimize parameter cross validation basically youre going separate training data two parts youre going part actually help parameter k parameters class files youre going assume number works training actually best future data play video starting 1723 follow transcript 1723 mentioned knn actually regarded estimate conditional problem y given x thats put category discriminative approaches key assumption made approach distribution label given document probability category given example probability theta given document d locally smooth means going assume probability documents region r suppose draw neighborhood going assume neighborhood data instances similar going assume conditional distribution label given data roughly different going assume probability c doc given d similar thats key assumption thats actually important assumption allow lot machinery reality true course depend define similarity neighborhood largely determined similarity function similarity function captures objects follow similar distributions assumptions okay similarity function capture obviously assumption problem classifier accurate play video starting 1859 follow transcript 1859 okay lets proceed assumption saying order estimate probability category given document try estimate probability category given entire region benefit course bringing additional data points help estimate probability play video starting 1922 follow transcript 1922 precisely idea knn basically known categories documents region estimate probability given formula count topics region normalize total number documents region numerator c theta r counter documents region r category theta training document know categories simply count times times signs denominator total number training documents region gives rough estimate categories popular neighborhood going assign popular category data object falls region music
play video starting 7 follow transcript 007 sound lecture continued discussion discriminative classifiers text categorization lecture going introduce discriminative classifier called support vector machine svm popular classification method effective text categorization play video starting 31 follow transcript 031 introduce classifier lets think simple case two categories two topic categories 01 02 classify documents two categories going represent document feature factor x play video starting 53 follow transcript 053 idea classifier design linear separator play video starting 59 follow transcript 059 youll similar regression right going say sign function value positive going say objective category going say category 2 makes 0 decision boundary categories play video starting 128 follow transcript 128 generally hiding marginal space 0 corresponds hyper plain play video starting 138 follow transcript 138 ive simple case two dimensional space x1 x2 case corresponds line play video starting 151 follow transcript 151 line defined three parameters beta zero beta beta two play video starting 22 follow transcript 202 line heading direction shows increase x1 x2 increase know beta beta two different assigns negative positive play video starting 220 follow transcript 220 lets assume beta negative beta two positive play video starting 228 follow transcript 228 interesting examine data instances two sides slide data instance visualized circles class diamonds class play video starting 243 follow transcript 243 question take point ask question whats value expression classifier data point play video starting 255 follow transcript 255 think basically going evaluate value function play video starting 31 follow transcript 301 values positive going say category negative going category two intuitively line separates two categories expect points side positive points side negative question assumption mentioned lets examine particular point play video starting 327 follow transcript 327 think sine expression play video starting 331 follow transcript 331 examine sine simply look expression compare lets say play video starting 342 follow transcript 342 value line lets compare point play video starting 348 follow transcript 348 identical x1 higher value x2 play video starting 354 follow transcript 354 lets look sin coefficient x2 know positive play video starting 42 follow transcript 402 means f value point higher f value point line means positive right play video starting 416 follow transcript 416 know general points side play video starting 420 follow transcript 420 functions value positive verify points side negative linear classifier linear separator separate points two categories play video starting 437 follow transcript 437 natural question linear separator best ive line separate two classes line course determined vector beta coefficients different coefficients give different lines imagine lines job gamma example give line counts separator instances play video starting 56 follow transcript 506 course lines wont separate bad lines question multiple lines separate clauses align best fact imagine different ways choosing line logistical regression classifier earlier actually uses criteria determine line linear separate uses conditional likelihood training determines line best svm going look criteria determining line best time criteria tied classification arrow play video starting 549 follow transcript 549 basic idea separator maximize margin margin dotted lines indicate boundaries data points class margin simply distance line separator closest point class play video starting 618 follow transcript 618 margin side ive define margin side play video starting 627 follow transcript 627 order separator maximize margin middle two boundaries dont separator close side intuition makes lot sense play video starting 644 follow transcript 644 basic idea svm going linear separator maximize margin play video starting 652 follow transcript 652 slide ive changed notation im going beta denote parameters im going w w denote words dont confused w actually width width play video starting 712 follow transcript 712 im lowercase b denote beta 0 biased constant play video starting 720 follow transcript 720 instances represent x vector form multiplication transpose w vector multiply future vector play video starting 735 follow transcript 735 b bias constant w set weights way feature m features m weights represent vector play video starting 747 follow transcript 747 similarly data instance text object represented feature vector number elements xi feature value example word count verify multiply two vectors take dot product form linear separator different way representing way consistent notations people usually talk svm way better connect slides readings play video starting 831 follow transcript 831 okay maximize margins separator means boundary separator determined data points data points call support vectors illustrated two support vectors class two class quotas define margin basically imagine know supportive vectors play video starting 96 follow transcript 906 center separator line determined data points actually dont matter change data points wont affect margin separator stay mainly affected support vector machines sorry mainly affected support vectors thats called support vector machine okay question course set optimize line actually find line separator equivalent finding values w b determine exactly separator play video starting 958 follow transcript 958 simplest case linear svm simple optimization problem lets recall classifier linear separator weights features main goal remove weights w b classifier say x category theta 1 positive going say category assumption setup linear svm going seek parameter values optimize margins training error play video starting 1038 follow transcript 1038 training data basically classifiers set training points know x vector know corresponding label y define y two values values 0 1 1 positive 1 theyre corresponding two categories ive wonder dont define 0 1 having 1 1 purely mathematical convenience moment play video starting 1116 follow transcript 1116 goal optimization make sure labeling training data correct means y norm label instance x 1 classified value large threshold 1 threshold easily fit constant parameter values b w make righthand side 1 play video starting 1148 follow transcript 1148 hand y 1 means different class classifier give small value fact negative value value equal 1 two different instances different kinds cases combine convenient chosen y 1 category turns combine two constraint play video starting 1226 follow transcript 1226 y multiplied classifier value larger equal 1 play video starting 1233 follow transcript 1233 obviously y 1 constraint lefthand side y 1 equivalent inequality actually captures constraints unified way thats convenient way capturing constraints whats second goal thats maximize margin ensure separator training data cases separate data separator largest margin margin assumed related magnitude weight w transform multiplied w give basically sum squares weights small value expression means w small play video starting 1342 follow transcript 1342 weve assumed constraint play video starting 1346 follow transcript 1346 getting data training set classified correctly objective thats tied maximization margin simply minimize w transpose multiplied w denote phi w basically optimization problem variables optimize weights b constraints linear constraints objective function quadratic function weights quadratic program linear constraints standard algorithm variable solving problem solve problem obtain weights w b give welldefined classifier classifier classify new text objects previous formulation did allow error classification data linear separator means look nice previous slide line separate happen allowed errors principle stay minimize training error try maximize margin case soft margin data points completely separable play video starting 1517 follow transcript 1517 turns easily modify svm accommodate similar introduced extra variable xi fact data instance going model error allow instance optimization problem similar specifically added optimization problem added error constraint allow allow classifier make mistakes xi allowed error set xi 0 back original constraint instance classified accurately allow nonzero allow errors fact length xi large error large naturally dont happen minimize xi xi needs minimized order control error play video starting 1642 follow transcript 1642 result objective function add original w basically ensuring minimize weights minimize errors simply take sum instances xi model error allowed instance combine basically minimize errors play video starting 1716 follow transcript 1716 theres parameter c thats constant control tradeoff minimizing errors maximizing margin c set zero back original object function maximize margin play video starting 1734 follow transcript 1734 dont optimize training errors xi set large value make constraints easy satisfy thats good course c set nonzero value positive value c set large value object function dominated training errors optimization margin play secondary role happens happen play video starting 187 follow transcript 1807 try best minimize training errors going take care margin affects generalization factors classify future data good particular parameter c actually set carefully case knearest neighbor optimize number neighbors optimize c general achievable crossvalidation basically look empirical data value c set order optimize performance play video starting 1849 follow transcript 1849 modification problem quadratic programming linear constraints optimizing algorithm actually applied solve different version program play video starting 192 follow transcript 1902 obtained weights bias classifier thats ready classifying new objects thats basic idea svm play video starting 1916 follow transcript 1916 summarize text categorization methods introduce methods generative models discriminative methods tend perform similarly optimized theres clear winner pros cons performance vary different data sets different problems reason feature representation critical play video starting 1952 follow transcript 1952 methods require effective feature representation design effective feature set domain knowledge humans definitely play important role new machine learning methods algorithm representation learning help learning features play video starting 2012 follow transcript 2012 common thing performing similarly data set different mistakes performance similar mistakes make different means useful compare different methods particular problem combine multiple methods improve robustness wont make mistakes assemble approaches combine different methods tend robust useful practice techniques introduce supervised machine learning general method means methods actually applied text categorization problem long humans help annotate training data sets design features supervising machine learning classifiers easily applied problems solve categorization problem allow characterize content text concisely categories predict sum properties real world variables associated text data computers course trying optimize combinations features provided human different ways combining optimize different object functions play video starting 2158 follow transcript 2158 order achieve good performance require effective features training data play video starting 224 follow transcript 2204 general rule improve feature representation training data generally better performance affected effectiveness features choice specific classifiers feature design tends important choice specific classifier play video starting 2230 follow transcript 2230 design effective features unfortunately applicationspecific theres general thing say analysis categorization problem try understand features help distinguish categories general lot domain knowledge help design features play video starting 231 follow transcript 2301 way figure effective features error analysis categorization results example look category tends confused categories confusion matrix examine errors systematically categories look specific instances mistake made features prevent mistake allow obtain insights design new features error analysis important general thats insights specific problem play video starting 2342 follow transcript 2342 finally leverage machine learning techniques example feature selection technique havent talked important trying select useful features actually train full classifier training classifier help identify features high values ways ensure sparsity model meaning recognize widths example svm actually tries minimize weights features force features force small number features play video starting 2421 follow transcript 2421 techniques dimension reduction thats reduce high dimensional feature space low dimensional space typically clustering features various ways metrics factorization job techniques actually similar talking models discuss talking morals psa lda actually help reduce dimension features imagine words original feature matched topic space lets say k topics document represented vector k values corresponding topics topic define dimension k dimensional space original high dimensional space corresponding words way learn effective features especially categories supervise learning low dimensional structures play video starting 2529 follow transcript 2529 original worth features combined amazing dimension features lower dimensional space features multi resolution useful deep learning new technique developed machine learning play video starting 2551 follow transcript 2551 particularly useful learning representations deep learning refers deep neural network classifier intermediate features embedded models highly nonlinear transpire recent events thats allowed train complex network effectively technique effective speech recognition computer reasoning recently applied text promise important advantage approach play video starting 2634 follow transcript 2634 relationship featured design learn intermediate replantations compound features automatically valuable learning effective replantation text recalibration text domain words exemplary representation text content humans imaging communication generally sufficient representing content tasks theres new representation people invented new word think value deep learning text processing tends lower inaudible speech revenue anchored corresponding design worked features play video starting 2731 follow transcript 2731 people promising learning effective features especially complicated tasks analysis effective play video starting 2741 follow transcript 2741 goes words play video starting 2747 follow transcript 2747 regarding training examples generally hard lot training examples involves human labor play video starting 2756 follow transcript 2756 ways help assume low quality training examples called pseudo training examples example take reviews internet overall ratings train categorizer meaning positive negative categorize reviews two categories assume five star reviews positive training samples star negative course five star reviews mention negative opinions training sample high quality useful play video starting 2845 follow transcript 2845 idea exploit unlabeled data techniques called semisupervised machine learning techniques allow combine labeled data unlabeled data case easy model text plus read categorization imagine lot unlabeled text data categorization actually clustering text data learn categories try align categories categories defined training data know documents category fact algorithm actually combine allow essentially pick useful words label data think way basically lets say classify unlabeled text documents going assume high confidence classification results actually liable suddenly training data enabler know labeled category labeled category two label completely reliable useful lets assume actually training label examples combine true training examples improved categorization method idea powerful play video starting 3023 follow transcript 3023 enabled data training data different advanced machine learning techniques called domain adaptation transfer learning borrow training examples related problem different categorization password play video starting 3046 follow transcript 3046 follow different distribution working basically two domains different careful overfit training domain signals related training data example training categorization news give effective plus y class vine topics tweets learn news help look writing tweets mission learning techniques help effectively heres suggested reading find details methods covered music
12 overview weeks lessons learn techniques joint mining text nontext data contextual text mining techniques analyzing topics text association various context information time location authors sources data summary text mining content time module take approximately 3 dedicated time complete videos assignments activities activities module listed required assignments bold activity estimated time required 12 video lectures 2 hours 12 graded quiz 1 hour goals objectives actively engage learning experiences module able explain necessary useful perform joint analysis mining text nontext data explain general idea contextual probabilistic latent semantic analysis cplsa main difference cplsa plsa give multiple application examples cplsa contextual text mining explain general idea social network authors context analyze topics text data potential benefit application perspective explain time series stock prices context analyze topics text data time stamps topic models guiding questions develop answers following guiding questions watching video lectures textbased prediction interesting application perspective humans playing important role textbased prediction “data mining loop” necessary useful jointly mine analyze text nontext data nontext data potentially help analyzing text data text data potentially help mining nontext data give examples context text article partition text data context information give examples leverage context information perform interesting comparative analysis topics text data what’s general idea contextual probabilistic latent semantic analysis cplsa different plsa give examples interesting topic patterns found cplsa what’s general idea cplsa analyzing impact event think interesting application what’s general idea social network authors text data complex context improve topic analysis text data give example interesting application what’s general idea time series stock prices time supervise discovery topics text data give example interesting application additional readings resources following readings optional c zhai s massung text data management analysis practical introduction information retrieval text mining acm morgan claypool publishers 2016 chapters 18 19 hongning wang yue lu chengxiang zhai latent aspect rating analysis review text data rating regression approach proceedings acm kdd 2010 pp 783792 2010 doi 10114518358041835903 hongning wang yue lu chengxiang zhai 2011 latent aspect rating analysis aspect keyword supervision proceedings acm kdd 2011 pp 618626 doi 10114520204082020505 chengxiang zhai atulya velivelli bei yu crosscollection mixture model comparative text mining proceedings 10th acm sigkdd international conference knowledge discovery data mining kdd 2004 acm new york ny usa 743748 doi 10114510140521014150 qiaozhu mei contextual text mining opens new tab phd thesis university illinois urbanachampaign 2009 hyun duk kim malu castellanos meichun hsu chengxiang zhai thomas rietz daniel diermeier mining causal topics text data iterative topic modeling time series feedback proceedings 22nd acm international conference information knowledge management cikm 2013 acm new york ny usa 885890 doi 10114525055152505612 noah smith textdriven forecasting retrieved 31 2015 httpwwwcscmuedunasmithpaperssmithwhitepaper10pdf opens new tab key phrases concepts keep eyes open following key terms phrases complete readings interact lectures topics help better understand content module textbased prediction “data mining loop” context text data contextual text mining contextual probabilistic latent semantic analysis cplsa views topic coverage topics spatiotemporal trends topics event impact analysis networkregularized topic modeling netplsa causal topics iterative topic modeling time series supervision tips success recommend following review video lectures number times gain solid understanding key questions concepts introduced possible tips suggestions peers class learning community help learn grow way helping address questions peers pose engaging we’ll learn better it’s good idea refer video lectures chapter readings weve read reference responses appropriate critique information presented take notes read materials watch lectures taking notes interacting material find easier remember understand notes you’ll find it’s easier complete assignments ahead favor take notes getting giving help getgive help following means learner help center opens new tab find information regarding specific technical problems example technical problems error messages difficulty submitting assignments problems video playback find answer documentation report problem coursera staff clicking contact link available topics page learner help center content issues opens new tab forum report errors lecture video content assignment questions answers assignment grading text links course pages content course materials university illinois staff community tas monitor forum respond issue2 mark completed item completed dislike report issue
working project please time work project mark completed item dislike report issue
office hours office hour due fall break mark completed item dislike report issue
schedule take exam exam instructions password quiz precedes unlocks proctored exam proctor enter password circumstances type password make attempt password quiz note exam immediately unlock proctor enters password please proctor know going refresh page resolve issue refresh page schedule proctored exam note schedule exam proctoru website httpsgoproctorucom opens new tab following instructions time scheduling exam proctoru click sign link university illinois proctoru portal page opens new tab create new user account proctoru login password recommended university illinois email address register account proctoru account skip step httpsgoproctorucom opens new tab schedule exam account created exams page click schedule new exam button schedule exam date time fill institution term exam dropdown menus click find reservations button schedule exam page select reservation time calendar bottom screen important reservations listed please select view radio button filter results display exam times specified preference click book button desired exam appointment time confirm selection page click proceed cart button ready continue cart click proceed checkout button enter appropriate credit card information click make payment exam confirmation page receive email message scheduled exam information take proctored exam date time exam appointment login university illinois proctoru portal page opens new tab logging countdown proctored exam time top page prior exam appointment reschedule reschedule button appointment time start button appear appointment click start button connected proctor guide proctored exam process navigate password quiz course site open password quiz proctor proctor type password password quiz circumstances type password please turn head proctor enters password submit password quiz proctor enters password password accepted start proctored exam proctors supervision proctor witness submit exam make sure follow proctors instructions remain connected instructed disconnect proctor reason session gets disconnected try reconnect immediately contact proctoru remain disconnected proctor submitting exam incident report submitted instructor mark completed item completed dislike report issue
exam policies technical support following policies enforced taking exam exam closed notes external material allowed two sheets scratch paper exam calculators allowed bathroom breaks allowed disconnected exam 5 minutes log back proctoru soon youre able resume exam disconnected 5 minutes reschedule exam proctoru make sure internet connection stable begin exam sure submit exam disconnecting proctoru live technical support run technical issues coursera platform taking exam contact coursera live chat technical assistance access coursera live chat coursera learner center httpslearnercourserahelp opens new tab make sure log coursera account bottom right page prompted chat live connects coursera live assistant connected live chat agent make sure mention agent registered student mcsds program university illinois mark completed item completed dislike report issue
mp1 assignmentmachine programming mp familiar meta text mining toolkit opens new tab toolkit useful later mps course project attempting mp please make sure youve completed steps mentioned programming assignment overview httpswwwcourseraorglearncs410supplementirzboprogrammingassignmentsoverview opens new tab mp score 1 leaderboard livedatalab means successfully completed mp 100 grade coursera complete mp1 sunday september 4 2022 1159pm cdt course uses thirdparty app mp1 enhance learning experience app reference basic information name email coursera id coursera honor code learn monika thotha understand submitting work isn’t result permanent failure course deactivation coursera account launch app dislike report issue
mp21 mp2 4part assignment familiar building evaluating search engines third part mp 21 meta toolkit indexing search course uses thirdparty app mp21 enhance learning experience app reference basic information name email coursera id coursera honor code learn monika thotha understand submitting work isn’t result permanent failure course deactivation coursera account launch app dislike report issue
mp22 overview part mp2 participate search competition create search engine meta similar did part 1 ranker evaluated ndcg scores 3 relevance datasets cranfield dataset apnews dataset faculty dataset collected annotated classmates evaluation results displayed leaderboard livedatalab latest submission results displayed herealso grader default configtoml stopwordstxt files provided changing files make impact scores please modify searchevalpy potentially notice changes scores course uses thirdparty app mp22 enhance learning experience app reference basic information name email coursera id coursera honor code learn monika thotha understand submitting work isn’t result permanent failure course deactivation coursera account launch app dislike report issue
mp31 overview mp3 analogy detection two part mp familiar large language models chatgpt analogy detection web pages please create account website httpstimancsillinoiseduanalogymplogin opens new tab please refer document detailed instructions httpsdocsgooglecomdocumentd1ffnmufqvbrwcqybo0y17egecl31uoy5uo5meikv24oedituspsharing opens new tab video website httpsillinoiszoomusrecshare81xrz1xjevdhliwrdzjmq9clak5bkevufeux8kg84uadfntyzi9q1d3pulswq3nq6cmnteiyau2hcstarttime1699402451000 opens new tab course uses thirdparty app mp31 enhance learning experience app reference basic information name email coursera id coursera honor code learn monika thotha understand submitting work isn’t result permanent failure course deactivation coursera account launch app dislike report issue
play video starting follow transcript 000 music lecture recommender systems play video starting 12 follow transcript 012 talked lot aspects search engines play video starting 19 follow transcript 019 talked problem search ranking problem different methods ranking implementation search engine evaluate search engine play video starting 36 follow transcript 036 important know web search engines important applications text retrieval useful tools help people convert big raw text data small set relevant documents play video starting 56 follow transcript 056 reason spend lectures search engines techniques search engines actually useful recommender systems topic lecture overall two systems actually connected techniques shared play video starting 122 follow transcript 122 slide talked two different modes text access pull push play video starting 131 follow transcript 131 mentioned recommender systems main systems serve users push mode systems take initiative recommend information user pushes information user works user stable information system good recommender system called filtering system recommending useful items people discarding filtering useless articles sense similar play video starting 216 follow transcript 216 cases system make binary decision usually theres dynamic source information items knowledge users interest system make decision item interesting user interesting system recommend article user play video starting 243 follow transcript 243 basic filtering question user item u item x two ways answer question think play video starting 256 follow transcript 256 look items u likes x actually items play video starting 35 follow transcript 305 look likes x user looks users users strategies combined follow strategy look item similarity case recommending text objects talking contentbased filtering contentbased recommendation look second strategy compare users case user similarity technique called collaborative filtering play video starting 346 follow transcript 346 lets look contentbased filtering system system look play video starting 352 follow transcript 352 system binary classifier knowledge users interests called user interest profile play video starting 42 follow transcript 402 maintains profile keep track users interests utility function guide user make decision nice plan utility function moment helps system decide set threshold accepted documents passed threshold classified initialization module take users input users specified keywords chosen category feed system initiators profile play video starting 439 follow transcript 439 typically learning module learn users feedback time note case typical users information stable system lot opportunities observe users user taken recommended item viewed signal indicate recommended item relevant user discarded relevant feedback long term feedback long time system collect lot information users interest improve classify whats criteria evaluating system play video starting 524 follow transcript 524 know filtering system actually performs case ranking evaluation measures map cant afford waiting lot documents rank documents make decision users system make decision real time general decide item threshold words trying decide absolute relevance play video starting 556 follow transcript 556 case common user strategy utility function evaluate system show linear utility function thats defined example three multiplied number good items delivered minus two multiplied number bad items delivered words play video starting 622 follow transcript 622 treat gambling game delete good item lets say win three dollars gain three dollars deliver bad lose two dollars utility function basically measures money game right clear maximize utility function strategy delivered good articles possible minimize delivery bad articles thats obvious right play video starting 73 follow transcript 703 interesting question set coefficients showed three negative two possible coefficients ask question reasonable play video starting 717 follow transcript 717 think play video starting 721 follow transcript 721 think thats reasonable choice choices play video starting 726 follow transcript 726 example 10 minus 1 1 minus 10 whats difference think play video starting 736 follow transcript 736 utility function affect systems threshold issue play video starting 743 follow transcript 743 right think two extreme cases 10 1 1 10 think encourage system encourage system conservative think bigger award delivering good document incur small penalty delivering bad intuitively encouraged deliver try deliver hope getting good delivered big reward play video starting 819 follow transcript 819 hand 110 dont big prize deliver good document hand big loss deliver bad imagine system reluctant deliver lot documents absolutely sure utility function designed based specific application three basic problems contentbased filtering following make filtering decision binary decision maker binary classifier given text document profile description user say yes document deleted play video starting 98 follow transcript 908 thats decision module initialization module earlier system started initialize system based limited text exclusion examples user play video starting 926 follow transcript 926 third model learning model able learn limited relevance judgements counted user preferences deliver documents dont deliver document user able know user likes play video starting 950 follow transcript 950 accumulate lot documents entire history play video starting 956 follow transcript 956 modules optimized maximize utility deal system different approaches going talk extend retrieval system search engine information filtering heres weve spent lot time talking search engines actually hard extend search engine information filtering heres basic idea extending retrieval system information filtering reuse lot retrieval techniques scoring right know score documents queries going match similarity profile text description document score threshold filtering decision retrieval find scores documents apply threshold document passing threshold passing threshold going say relevant going deliver user component add course learn history traditional feedback techniques learn improve scoring know rock hill scoring improvement develop new approaches learn accept set initially learn update threshold time heres system look generalize vectorspace model filtering problems right document vector fed scoring module exists search engine implements vectorspace model profile treated query essentially profile vector matched document vector generate score play video starting 123 follow transcript 1203 score fed thresholding module say yes evaluation based utility filtering results says yes document user user give feedback feedback information adjust threshold adjust vector representation vector learning essentially query modification feedback case search threshold learning new component talk bit music
play video starting follow transcript 000 sound play video starting 9 follow transcript 009 interesting challenges threshold learning filtering problem show historical data collect filtering system scores status relevance score 365 relevant second relevant separate course lot documents dont know status delivered user judgements documents delivered user random sample sensitive data biased creates difficultly learning play video starting 58 follow transcript 058 secondly general labeled data relevant data challenging machine learning approaches typically require training data play video starting 113 follow transcript 113 extreme case beginning dont labeled data system make decision thats difficult problem beginning finally issue exploration versus exploitation tradeoff means explore document space bit user interested documents data labeled words going explore space user interests testing user interested documents play video starting 156 follow transcript 156 currently matching users interests play video starting 21 follow transcript 201 lower threshold bit deliver near misses user user respond play video starting 213 follow transcript 213 user respond extra document play video starting 220 follow transcript 220 tradeoff hand explore hand dont explore deliver nonrelevant information exploitation means exploit learn user lets say know user interested particular topic dont deviate dont deviate dont exploit thats good miss opportunity learn interest user play video starting 251 follow transcript 251 dilemma play video starting 254 follow transcript 254 thats difficulty problem solve play video starting 258 follow transcript 258 solve problems general think empirical utility optimization strategy strategy basically optimize threshold based historical data previous slide right compute utility training data candidate score threshold pretend cut point cut different scoring threshold point happen whats utility training data compute utility know relevant status assume know relevant status based approximation clickthroughs threshold gives maximum utility training data course doesnt account exploration talked play video starting 356 follow transcript 356 difficulty biased training sample mentioned play video starting 41 follow transcript 401 general upper bound true optimal threshold threshold actually lower possible discarded item actually interesting user play video starting 419 follow transcript 419 solve problem generally low threshold explore bit heres particular approach called betagamma threshold learning idea falling show ranked list training documents ranked positions y axis show utility course function depends specify coefficients utility function imagine depending cutoff position utility play video starting 454 follow transcript 454 suppose cut position utility example identify cutting cutoff point optimal point theta optimal point achieve maximum utility chosen threshold play video starting 517 follow transcript 517 zero utility threshold cutoff utility zero mean means lower threshold bit reach threshold utility lower nonactive least right high optimal utility gives safe point explore threshold explained desirable explore interest space desirable lower threshold based training means general set threshold range lets say alpha control play video starting 68 follow transcript 608 deviation optimal utility point formula threshold interpolation zero utility threshold optimal utility threshold play video starting 622 follow transcript 622 question set alpha play video starting 627 follow transcript 627 deviate optimal utility point play video starting 633 follow transcript 633 depend multiple factors way solve problem encourage threshold mechanism explore zero point thats safe point going necessarily reach way zero point going parameters define alpha specifically follows beta parameter control deviation optimal threshold based accounting overfitting training data lets say adjustment factor whats interesting gamma parameter formula gamma controlling inference number examples training set formula n denotes number training examples bigger actually encourage exploration words small try explore means examples sure exhausted space interest explore examples user feel probably dont explore gives beta gamma exploration right examples exploration threshold closer optimal threshold thats basic idea approach approach actually working evaluation studies particularly effective work arbitrary utility appropriate lower bound play video starting 843 follow transcript 843 explicitly addresses explorationexploitation tradeoff uses zero utility threshold point safeguard explorationexploitation tradeoff going explore zero utility point take analogy gambling dont risk losing money safe spend conservative strategy exploration play video starting 913 follow transcript 913 problem course approach purely heuristic zero utility lower boundary conservative course advance machine learning approaches proposed solving problems active research area play video starting 935 follow transcript 935 summarize two strategies recommended systems filtering systems content based looking item similarity collaborative filtering looking user similarity weve covered contentbased filtering approach lecture talk collaborative filtering contentbased filtering system generally solve problems relative filtering decision learning system actually built based search engine system adding threshold mechanism adding adaptive learning algorithm allow system learn long term feedback user play video starting 1030 follow transcript 1030 music
play video starting 7 follow transcript 007 lecture collaborative filtering play video starting 11 follow transcript 011 lecture going continue discussion recommended systems particular going look approach collaborative filtering slide talked two strategies answer basic question user u item x previous lecture looked item similarity thats contentbased filtering lecture going look user similarity different strategy called collaborative filtering play video starting 44 follow transcript 044 collaborative filtering play video starting 47 follow transcript 047 make filtering decisions individual user based judgements uses play video starting 54 follow transcript 054 say infer individuals interest preferences similar users general idea following given user u going find similar users u1 going predict preferences based preferences similar users u1 play video starting 122 follow transcript 122 user similarity judged based similarity preferences common set items play video starting 131 follow transcript 131 exact content item doesnt matter going look relation users items play video starting 141 follow transcript 141 means approach general applied items text objects approach work following assumptions users interest similar preferences second users similar preferences probably share interest example interest user information retrieval infer user probably favor sigir papers play video starting 214 follow transcript 214 interested information retrieval researching probably favor sigir papers thats assumption make assumption true help collaborative filtering work assume people favor sigir papers infer interest probably information retrieval simple examples make sense cases assumption actually make sense assumption make sufficiently large number user preferences available example lot ratings users movies indicate preferences movies lot data cluttered filtering effective play video starting 39 follow transcript 309 problem thats called cold start problem means dont preferences available system fully take advantage collaborative filtering lets look filtering problem formal way play video starting 330 follow transcript 330 picture shows general considering lot users showing m users u1 considering number objects lets say n objects order o1 assume users able judge objects user example give ratings items example items movies products users give ratings 1 5 ratings available combinations users watched movies rated movies obviously wont able watch movies users actually watch movies general small symmetrics items entries unknown values play video starting 439 follow transcript 439 whats interesting potentially infer value element matrix based values thats essential question collaborative filtering assume theres unknown function f map pair user object rating observed sum values function play video starting 58 follow transcript 508 infer value function pairs dont available similar machinery problems wed know values function training data set hope predict values function test data function approximation pick function based observed ratings setup approaches solving problem fact active research area reason special conferences dedicated problem play video starting 610 follow transcript 610 major conference devoted problem music
play video starting follow transcript 000 sound going talk basic strategy based similarity users predicting rating object active user ratings similar users active user called memory based approach bit similar play video starting 40 follow transcript 040 storing user information considering particular user going try retrieve rating users similar users user case try information users predict preference user general idea notations x sub j denotes rating object o j user u play video starting 117 follow transcript 117 n sub average rating object user play video starting 126 follow transcript 126 n needed normalize ratings objects user normalization going subtract average rating ratings normalize ratings ratings different users comparable play video starting 155 follow transcript 155 users generous generally give high ratings critical ratings directly compared aggregate normalization prediction rating item user active user u sub play video starting 224 follow transcript 224 based average ratings similar users play video starting 230 follow transcript 230 user u sub user interested recommending items interested recommending o sub j interested knowing likely user object know play video starting 250 follow transcript 250 idea look similar users user liked object play video starting 259 follow transcript 259 mathematically say predicted rating user app object user object o j basically combination normalized ratings different users fact taking sum users users contribute equally average conjured weights weight controls inference user prediction course naturally weight related similarity ua particular user ui similar contribution user ui make predicting preference ua play video starting 43 follow transcript 403 formula extremely simple sum possible users sum ratings normalized ratings explained ratings normalized order comparable play video starting 422 follow transcript 422 ratings weighted similarity play video starting 426 follow transcript 426 imagine w similarity user user play video starting 434 follow transcript 434 whats k k simply normalizer sum weights users play video starting 447 follow transcript 447 means basically consider weight k coefficients weight sum users play video starting 5 follow transcript 500 normalization strategy predictor rating range ratings make prediction play video starting 513 follow transcript 513 right basically main idea memorybased approaches collaborative filtering play video starting 522 follow transcript 522 make prediction map back rating user actually make add mean rating average rating user u sub predicted value recover meaningful rating user user generous average high add rating adjusted relatively high rate recommend item user actually doesnt matter interested basically normalized reading thats meaningful evaluate filter approaches typically assume actual ratings user objects unknown prediction compare predicted ratings actual ratings access actual ratings pretend dont know compare systems predictions actual ratings case obviously systems prediction adjusted match actual ratings user whats happening basically play video starting 71 follow transcript 701 okay memory based approach course look formula write program implement face problem determining w function know w function formula easy implement play video starting 722 follow transcript 722 different ways compute function weight w specific approaches generally differ computed play video starting 735 follow transcript 735 possibilities imagine possibilities popular approach pearson correlation coefficient play video starting 748 follow transcript 748 sum commonly rated items formula standard appears correlation coefficient formula play video starting 8 follow transcript 800 basically measures two users tended give higher ratings similar items lower ratings similar items play video starting 811 follow transcript 811 measure cosine measure going treat rating vectors vectors vector space going measure angle compute cosine angle two vectors measure vector space model retrieval imagine different ways cases note users similarity based preferences items did actually content information items didnt matter items movies books products text documents cabled content allows approach applied wide range problems newer approaches course information user clearly know user preferences items actual filtering system collaborative filtering combine content based filtering context information interesting approaches people starting new approaches proposed memory based approach work reasonably easy implement practical applications starting point strategy works application play video starting 956 follow transcript 956 obvious ways improve approach mainly improve user similarity measure practical issues deal example lot missing values set default values average ratings user simple solution advanced approaches actually try predict missing values predictive values improve similarity fact memory based apology predict missing values right iterative approach preliminary prediction predictive values improve similarity function play video starting 1049 follow transcript 1049 heuristic way solve problem strategy obviously affect performance claritative filtering heuristics improve similarity functions play video starting 116 follow transcript 1106 idea actually similar idea idf text search called inverse user frequency iuf idea look two users share similar ratings item popular item viewed people inaudible people interested item interesting rare item viewed users two users deal item give similar ratings says similarity emphasize similarity items viewed users music
play video starting follow transcript 000 sound summarize discussion recommender systems sense filtering task recommender task easy sense task actually difficult easy users expectation low case system takes initiative push information user user doesnt make effort recommendation better right recommend noise items useless documents recommend useful information users generally appreciate thats sense thats easy filtering actually harder task retrieval make binary decision cant afford waiting lot items youre going item better make decision item think news filtering soon news decide news interesting user wait days make accurate recommendation relevant news utility going significantly decreased play video starting 128 follow transcript 128 reason hard data sparseness think learning problem collaborative filtering example purely based learning past ratings dont ratings theres right yeah mentioned cold start problem actually serious serious problem course strategies proposed soft problem play video starting 2 follow transcript 200 different strategies alleviate problem example user information asses similarity preferences users items give additional information available user play video starting 221 follow transcript 221 talk two strategies filtering task contentbased look items collaborative filtering look similarity obviously combined practical system imagine generally combined give hybrid strategy filtering recall talked push versus pull two strategies getting access text data recommender system easy help users push mode search engines serving users pull mode obviously two combined combined two system support user multiple mode information access future anticipate system useful user active research area lot new algorithms proposed time particular new algorithms tend lot context information context context user context user items items isolated theyre connected ways users form social network theres rich context leverage order play video starting 359 follow transcript 359 solve problem thats active research area machine learning algorithms applied additional readings handbook called recommender systems collection lot good articles give overview number specific approaches recommender systems music
play video starting follow transcript 000 noise play video starting 6 follow transcript 006 lecture summary course play video starting 12 follow transcript 012 map shows major topics covered course play video starting 19 follow transcript 019 key highlevel takeaway messages talked natural language content analysis play video starting 29 follow transcript 029 main takeaway messages natural language processing foundation text retrieval currently nlp isnt robust battle wars generally main method modern search engines sufficient search tasks obviously complex search tasks deeper natural language processing techniques talked high level strategies text access talked push versus pull pull talked querying versus browsing play video starting 113 follow transcript 113 general future search engines integrate techniques math involved information access play video starting 123 follow transcript 123 talk number issues related search engines talked search problem framed ranking problem play video starting 134 follow transcript 134 talked number retrieval methods start overview vector space model probabilistic model talked vector space model depth play video starting 148 follow transcript 148 later talked language modeling approach thats probabilistic model takeaway message modeling retrieval function tend look similar generally various heuristics important ones tfidf weighting document length normalization tf transformed sub media transformation function play video starting 222 follow transcript 222 talked implement retrieval system main techniques talked construct inverted index prepare system answer query quickly talked faster search inverted index play video starting 246 follow transcript 246 talked evaluate text retrieval system mainly introduced cranfield evaluation methodology important evaluation methodology applied tasks play video starting 31 follow transcript 301 talked major evaluation measures important measures search engine map mean average precision ndcg summarize discount accumulative gain precision recall two basic measures play video starting 322 follow transcript 322 talked feedback techniques talked rocchio vector space model mixture model language modeling approach feedback important technique especially considering opportunity learning lot pixels web play video starting 342 follow transcript 342 talked web search talked parallel scene solve scalability issue scene going net reduce talked linking permission model app improve search talked page rank hits major hours analyzing links web play video starting 47 follow transcript 407 talked learning rank machine learning combine multiple features improvement scoring effectiveness improved approach improve robustness ranking function easy expand search engine features promote page play video starting 436 follow transcript 436 finally talked future web search play video starting 440 follow transcript 440 major reactions future improving count regeneration engines play video starting 450 follow transcript 450 finally talked recommended systems systems increment push mode talk two approaches contentbased collaborative filtering combined play video starting 57 follow transcript 507 obvious missing piece picture user user interface important component search engine current search interface relatively simple actually done lot studies user interfaces visualization example topic learn reading book excellent book kinds studies search face play video starting 548 follow transcript 548 know topics talked read additional readings listed short course manage cover basic topics text retrievals search engines play video starting 64 follow transcript 604 resources additional information advanced topics give thorough treatment topics talked main source synthesis digital library play video starting 621 follow transcript 621 lot short textbook textbooks long tutorials tend lot information explain topic lot series related cause information concepts retrieval services human langauge technology artificial intelligence machine learning major journals conferences listed tend lot research papers topic course finally information resources readings tool kits check url play video starting 710 follow transcript 710 taken text mining course data mining specialization series naturally step take course picture shows mine big text data generally two kinds techniques text retrieval covered course techniques help convert raw big text data small relevant text data actually needed specific application human plays important role mining text data text data written humans consume involving humans process data mining important course covered various strategies help users access relevant data techniques essential text mining system help prominence help users interpret inner patterns user define text data mining general user back original data better understand patterns play video starting 830 follow transcript 830 text mining cause text mining analytics course dealing user following information second step picture convert text data actionable knowledge play video starting 849 follow transcript 849 helping users digest found information find patterns reveal knowledge text knowledge application systems help decision making help user finish task taken course natural step natural step take course play video starting 924 follow transcript 924 thank taking course hope fun found course useful look interacting future opportunity music
play video starting follow transcript 000 sound looking text mining problem closely problem similar general data mining focusing text data play video starting 21 follow transcript 021 going text mining algorithms help turn text data actionable knowledge real world especially decision making completing tasks require text data support general real world problems data mining tend kinds data nontextual general picture nontext data play video starting 56 follow transcript 056 reason concerned joint mining text nontext data course going focus text mining going touch joint analysis text data nontext data problem definition look landscape topics text mining analytics play video starting 121 follow transcript 121 slide shows process generating text data detail play video starting 127 follow transcript 127 specifically human sensor human observer look word perspective play video starting 134 follow transcript 134 different people looking world different angles theyll pay attention different things person different times pay attention different aspects observed world humans able perceive world perspective human sensor form view world called observed world course different real world perspective person taken biased play video starting 216 follow transcript 216 observed world represented example entityrelation graphs general way knowledge representation language general basically person mind world dont know exactly looks course human express person observed natural language english result text data play video starting 255 follow transcript 255 course person different language express observed case text data mixed languages different languages play video starting 310 follow transcript 310 main goal text mining actually revert process generating text data hope able uncover aspect process play video starting 328 follow transcript 328 specifically think mining example knowledge language play video starting 335 follow transcript 335 means looking text data english able discover english usage english patterns english play video starting 347 follow transcript 347 type mining problems result knowledge language useful various ways play video starting 358 follow transcript 358 look picture mine knowledge observed world mining content text data play video starting 411 follow transcript 411 going look text data try essence extracting high quality information particular aspect world interested play video starting 426 follow transcript 426 example particular person particular entity regarded mining content describe observed world users mind persons mind play video starting 445 follow transcript 445 look imagine mine knowledge observer text data infer properties person play video starting 53 follow transcript 503 properties mood person sentiment person play video starting 510 follow transcript 510 note distinguish observed word person text data cant describe person observed objective way description subjected sentiment general imagine text data contain factual descriptions world plus subjective comments thats possible text mining mine knowledge observer finally look picture left side picture certainly say real world right text mining infer real world variables called predictive analytics play video starting 6 follow transcript 600 predict value interesting variable picture basically covered multiple types knowledge mine text general play video starting 614 follow transcript 614 infer real world variables results mining text data intermediate results help prediction example mine content text data generate summary content summary help predict variables real world course generated original text data emphasize processing text data generate features help prediction important play video starting 74 follow transcript 704 thats show results mining tasks mining content text data mining knowledge observer helpful prediction play video starting 721 follow transcript 721 fact nontext data nontext data help prediction course depends problem general nontext data important prediction tasks example predict stock prices changes stock prices based discussion news articles social media example text data predict real world variables case obviously historical stock price data important prediction thats example nontext data useful prediction going combine kinds data make prediction nontext data analyzing text supplying context play video starting 825 follow transcript 825 look text data looking content andor opinions expressed text play video starting 832 follow transcript 832 text data generally context associated play video starting 837 follow transcript 837 example time location associated text data useful context information play video starting 848 follow transcript 848 context interesting angles analyzing text data example partition text data different time periods availability time analyze text data time period make comparison similarly partition text data based locations meta data thats associated form interesting comparisons areas sense nontext data actually interesting angles perspectives text data analysis help make contextsensitive analysis content language usage play video starting 936 follow transcript 936 opinions observer authors text data analyze sentiment different contexts fairly general landscape topics text mining analytics course going selectively cover topics actually hope cover general topics play video starting 106 follow transcript 1006 going cover natural language processing briefly understanding text data determines represent text data text mining second going talk mine word associations text data word associations form lexical knowledge language third going talk topic mining analysis way analyze content text useful ways analyzing content useful techniques text mining play video starting 1053 follow transcript 1053 going talk opinion mining sentiment analysis regarded example mining knowledge observer play video starting 117 follow transcript 1107 finally going cover textbased prediction problems try predict real world variable based text data play video starting 1117 follow transcript 1117 slide serves road map course going outline topics cover rest course music
play video starting follow transcript 000 sound play video starting 9 follow transcript 009 lecture natural language content analysis natural language content analysis foundation text mining going talk play video starting 24 follow transcript 024 particular natural language processing factor present text data play video starting 33 follow transcript 033 determines algorithms analyze mine text data play video starting 40 follow transcript 040 going take look basic concepts natural language play video starting 46 follow transcript 046 im going explain concepts similar example youve dog chasing boy playground simple sentence read sentence dont think meaning computer understand sentence computer steps play video starting 113 follow transcript 113 computer needs know words segment words english easy look space computer know categories words syntactical categories example dog noun chasings verb boy noun called lexical analysis particular tagging words syntactic categories called partofspeech tagging play video starting 145 follow transcript 145 computer needs figure relationship words dog form noun phrase playground prepositional phrase way connected order create meaning combinations make sense play video starting 27 follow transcript 207 called syntactical parsing syntactical analysis parsing natural language sentence outcome parse tree tells structure sentence know interpret sentence semantics order meaning map phrases structures real world antithesis mind dog concept know boy concept know connecting phrases know understanding play video starting 252 follow transcript 252 computer formally represent entities symbols dog d1 means d1 dog play video starting 34 follow transcript 304 boy b1 means b1 refers boy represents chasing action predicate chasing predicate three arguments d1 b1 p1 playground formal rendition semantics sentence reach level understanding make inferences example assume theres rule says someones chased person scared infer boy scared inferred meaning based additional knowledge finally infer sentence requesting person say sentence saying sentence purpose saying sentence called speech act analysis pragmatic analysis language case person saying reminding person bring back dog play video starting 435 follow transcript 435 means saying sentence person actually takes action action make request play video starting 446 follow transcript 446 slide clearly shows order understand sentence lot things computer general hard computer especially correctly difficult play video starting 58 follow transcript 508 main reason natural language processing difficult designed make human communications efficient play video starting 515 follow transcript 515 result example lot common sense knowledge play video starting 521 follow transcript 521 assume knowledge theres encode knowledge play video starting 529 follow transcript 529 makes communication efficient play video starting 532 follow transcript 532 keep lot ambiguities ambiguities words play video starting 539 follow transcript 539 assume ability disambiguate word theres problem having word mean possibly different things different context play video starting 552 follow transcript 552 computer difficult computer common sense knowledge computer confused makes hard natural language processing makes hard step slide showed earlier play video starting 616 follow transcript 616 ambiguity main killer meaning step multiple choices computer decide whats right choice decision difficult moment play video starting 631 follow transcript 631 general common sense reasoning order fully understand natural language computers today dont thats hard computers precisely understand natural language point play video starting 648 follow transcript 648 specific examples challenges think worldlevel ambiguity word design noun verb weve got ambiguous part speech tag play video starting 7 follow transcript 700 root multiple meanings mathematical sense square root plant play video starting 712 follow transcript 712 syntactic ambiguity refers different interpretations play video starting 719 follow transcript 719 sentence terms structures example natural language processing actually interpreted two ways play video starting 728 follow transcript 728 ordinary meaning getting talking topic processing natural language theres possible interpretation say language processing natural play video starting 748 follow transcript 748 dont generally problem imagine computer determine structure computer make choice two play video starting 759 follow transcript 759 classic example man boy telescope ambiguity lies question telescope called prepositional phrase attachment ambiguity play video starting 814 follow transcript 814 meaning attach prepositional phrase telescope modify boy modifying verb problem anaphora resolution john persuaded bill buy tv refer john bill play video starting 839 follow transcript 839 presupposition difficulty quit smoking implies smoked knowledge order understand languages play video starting 852 follow transcript 852 problems state art natural language processing techniques perfectly simplest part speech tagging solve problem accuracy listed 97 taken studies earlier play video starting 917 follow transcript 917 studies obviously particular data sets numbers meaningful take context data set evaluation show numbers mainly give sense accuracy things doesnt mean data set accuracy precisely 97 general parsing speech tagging fairly perfect play video starting 953 follow transcript 953 parsing difficult partial parsing meaning phrases correct probably achieve 90 better accuracy play video starting 106 follow transcript 1006 complete parse tree correctly difficult play video starting 1013 follow transcript 1013 semantic analysis aspects semantic analysis particularly extraction entities relations example recognizing person thats location person person met place word sense extent play video starting 1038 follow transcript 1038 occurrence root sentence refers mathematical sense sentiment analysis aspect semantic analysis play video starting 1050 follow transcript 1050 means tag senses generally positive talking product talking person play video starting 112 follow transcript 1102 inference hard generally big domain feasible limited domain thats generally difficult problem artificial intelligence speech act analysis difficult probably specialized cases lot help humans annotate data computers learn play video starting 1136 follow transcript 1136 slide shows computers able understand natural language precisely explains text mining problem difficult rely mechanical approaches computational methods understand language precisely today particular statistical machine learning method statistical analysis methods try meaning text possible later actually play video starting 1220 follow transcript 1220 algorithms extract interesting model text fully understand meaning natural language sentences precisely music
play video starting follow transcript 000 sound play video starting 10 follow transcript 010 specific examples cant today part speech tagging easy 100 correctly example turned highway verses turned fan two offs actually differentness active categories difficult complete parsing correct example man boy telescope actually difficult parse depending context precise deep semantic analysis hard example define meaning precisely difficult sentence john owns restaurant state summarized follows robust general nlp tends shallow deep understanding scale play video starting 112 follow transcript 112 reason course techniques cover general shallow techniques analyzing text data mining text data generally based statistical analysis robust general play video starting 136 follow transcript 136 category shallow analysis techniques advantage able applied text data natural topic downside dont give deeper understanding text rely deeper natural language analysis play video starting 2 follow transcript 200 typically require human effort annotate lot examples analysis computers machine learning techniques learn training examples task practical applications generally combine two kinds techniques general statistical methods backbone basis applied text data top going humans take data supervised machine learning tasks especially important tasks bring humans loop analyze text data precisely course cover general statistical approaches generally dont require human effort theyre practically useful deeper analysis techniques require lot human effort annotate text today summarize main points take nlp foundation text mining obviously better understand text data better text mining play video starting 330 follow transcript 330 computers today able understand natural language deep nlp requires common sense knowledge inferences working limited domains feasible large scale text mining shallow nlp based statistical methods done large scale main topic course generally applicable lot applications sense useful techniques practice statistical nlp basis humans help needed various ways music
play video starting follow transcript 000 music play video starting 7 follow transcript 007 lecture topic mining analysis play video starting 12 follow transcript 012 going talk term topic slide earlier lecture define task topic mining analysis raised question exactly define topic theta play video starting 31 follow transcript 031 lecture going offer way define thats initial idea idea defining topic simply term play video starting 42 follow transcript 042 term word phrase play video starting 45 follow transcript 045 general terms describe topics thought define topic term example terms sports travel science define topic way analyze coverage topics document example discover extent document covers sports found 30 content document sports 12 travel discover document two cover sports coverage zero play video starting 132 follow transcript 132 course discussed task definition topic mining analysis two tasks discover topics second analyze coverage lets think discover topics represent topic term means mine k topical terms collection play video starting 21 follow transcript 201 course different ways play video starting 25 follow transcript 205 going talk natural way likely effective going parse text data collection obtain candidate terms candidate terms words phrases lets say simplest solution take word term words candidate topics going design scoring function match good term topic play video starting 235 follow transcript 235 design function things consider example pure statistics design scoring function play video starting 245 follow transcript 245 intuitively favor representative terms meaning terms represent lot content collection mean favor frequent term simply frequency design scoring function highest scored terms general terms functional terms terms occur frequently english play video starting 314 follow transcript 314 avoid having words top penalize words general favor terms fairly frequent frequent particular approach based tfidf weighting retrieval play video starting 335 follow transcript 335 tf stands term frequency idf stands inverse document frequency talked ideas lectures discovery word associations statistical methods meaning function defined based statistics scoring function general applied language text apply approach particular problem able leverage domainspecific heuristics example news favor title words actually general favor title words authors tend title describe topic article play video starting 427 follow transcript 427 dealing tweets favor hashtags invented denote topics naturally hashtags good candidates representing topics play video starting 444 follow transcript 444 design scoring function discover k topical terms simply picking k terms highest scores course encounter situation highest scored terms similar theyre semantically similar closely related synonyms thats desirable coverage content collection remove redundancy way greedy algorithm called maximal marginal relevance ranking basically idea list based scoring function gradually take terms collect k topical terms term course picked pick term going look terms picked try avoid picking term thats similar considering ranking term list considering redundancy candidate term respect terms picked play video starting 558 follow transcript 558 thresholding balance redundancy removal high score term okay k topical terms regarded topics discovered connection lets think going compute topic coverage pi sub ij play video starting 623 follow transcript 623 looking picture sports travel science topics suppose give document pick coverage topic document play video starting 636 follow transcript 636 approach simply count occurrences terms example sports occurred four times document travel occurred twice normalize counts estimate coverage probability topic general formula collect counts terms represent topics simply normalize coverage topic document add play video starting 715 follow transcript 715 forms distribution topics document characterize coverage different topics document think idea solving problem ask question good best way solving problem play video starting 738 follow transcript 738 lets examine approach general empirical evaluation play video starting 746 follow transcript 746 actual data sets works play video starting 752 follow transcript 752 case lets take look simple example text document thats nba basketball game play video starting 84 follow transcript 804 terms content sports play video starting 88 follow transcript 808 simply count words represent topics find word sports actually did occur article content sports play video starting 822 follow transcript 822 count sports zero means coverage sports estimated zero course term science did occur document estimate zero thats okay sports certainly okay know content sports estimate problem play video starting 850 follow transcript 850 whats term travel actually occurred document estimate coverage topic travel got nonzero count estimated coverage nonzero obviously desirable play video starting 98 follow transcript 908 simple example illustrates problems approach count words belong topic consider related words cant simply count topic word sports case did occur related words basketball game count related words second problem word star actually ambiguous probably means basketball star imagine mean star sky case star actually suggest topic science play video starting 954 follow transcript 954 deal finally main restriction approach term describe topic describe complicated topics example specialized topic sports harder describe word phrase words example illustrates general problems approach treating term topic lacks expressive power meaning represent simple general topics represent complicated topics require words describe play video starting 1037 follow transcript 1037 second incomplete vocabulary coverage meaning topic represented term suggest terms related topic talking sports terms related allow easily count related terms order conversion coverage topic finally problem word sense disintegration topical term related term ambiguous example basketball star versus star sky play video starting 1110 follow transcript 1110 lecture going talk solve problem topic music
play video starting follow transcript 000 music play video starting 6 follow transcript 006 lecture mixture unigram language models play video starting 11 follow transcript 011 lecture continue discussing probabilistic topic models particular introduce mixture unigram language models slide earlier talked rid background words top document play video starting 36 follow transcript 036 solve problem useful think end having problem obviously words frequent data maximum likelihood estimate estimate obviously assign high probability words order maximize likelihood order rid mean wed differently play video starting 15 follow transcript 105 particular say distribution doesnt explain words tax data going say common words explained distribution natural way solve problem think distribution account common words way two distributions mixed generate text data model call background topic model generate common words way target topic theta generating common handle words characterised content document play video starting 152 follow transcript 152 work small modification previous setup distribution two distributions decide distribution generate word word sample two distributions play video starting 213 follow transcript 213 text data generating way look generating word time eventually generate lot words generate word going decide two distributions controlled probability probability theta sub d probability theta sub b play video starting 241 follow transcript 241 probability enacting topic word distribution probability enacting background word play video starting 252 follow transcript 252 distribution denoted theta sub b play video starting 255 follow transcript 255 case give example set 05 youre going basically flip coin fair coin decide general probabilities dont equal bias topic process generating word flip coin based probabilities choosing model lets say coin shows head means going topic two word distribution going word distribution generate word going slow path play video starting 341 follow transcript 341 going background word distribution generate word play video starting 346 follow transcript 346 case model uncertainty associated word distribution think model generating text data model called mixture model play video starting 42 follow transcript 402 lets case whats probability observing word w showed words text cases setup model interested computing likelihood function basic question whats probability observing specific word know word observed two distributions consider two cases sum two cases play video starting 434 follow transcript 434 case topic distribution generate word case probably theta sub d probability choosing model multiplied probability actually observing word model events happen order observe choosing topic theta sub d actually sampled word distribution similarly second part accounts different way generally word background play video starting 515 follow transcript 515 obviously probability text similar right two ways generating text case product probability choosing particular word multiplied probability observing word distribution play video starting 535 follow transcript 535 actually general form make sure understood expression convince probability obsolete text summarize observed probability word mixture model general sum different ways generating word play video starting 6 follow transcript 600 case product probability selecting component model multiplied probability actually observing data point component model general occurring later basic idea mixture model retrieve thesetwo distributions model box bring components view box model generative model give probability word play video starting 642 follow transcript 642 way determines probability different distribution play video starting 650 follow transcript 650 basically complicated mixture model complicated distribution called mixture model play video starting 7 follow transcript 700 treat generative model useful think likelihood function illustration dimmer illustration generated model mathematically model define following generative model probability word assumed sum two cases play video starting 726 follow transcript 726 generating word form general form calculation earlier symbol w denote water basically sum right sum due fact water generated ways two ways case sum term product two terms two terms probability selecting component d second probability actually observing word component model general description mixture models make sure understand basis understanding kinds top models play video starting 828 follow transcript 828 setup model write functioning question estimate parameter parameters given data general text data estimate model parameters estimation allow discover interesting knowledge text case discover presented parameters two kinds parameters two worded distributions result topics coverage topic play video starting 912 follow transcript 912 coverage topic determined probability c d probability theta whats interesting think special cases send happen zero right look likelihood function play video starting 936 follow transcript 936 degenerate special case distribution okay easily verify assuming two 10 zero play video starting 949 follow transcript 949 sense mixture model general previous model distribution cover special case play video starting 959 follow transcript 959 summarize talked mixture two unigram language models data considering document model mixture model two components two unigram lm models specifically theta sub d intended denote topic document d theta sub b representing background topic set attract common words common words assigned high probability model play video starting 1033 follow transcript 1033 parameters collectively called lambda show play video starting 1041 follow transcript 1041 think question parameters talking exactly usually good exercise allows model depth complete understanding whats going model mixing weights course play video starting 1059 follow transcript 1059 likelihood function look looks similar document product words document exactly difference sum recalled play video starting 1125 follow transcript 1125 sum mixture model mixture model introduce probability choosing particular component distribution play video starting 1139 follow transcript 1139 way writing product unique words vocabulary having product positions document form look different unique words commutative formed computing maximum likelihood estimate later maximum likelihood estimator usual find parameters maximize likelihood function constraints course two kinds probabilities inaudible sum 1 choice inaudible sum 1 music
play video starting follow transcript 000 sound lets look behaviour mixed model case lets look response data frequencies basically likelihood function two word document case solution text probability 09 probability 01 interesting think scenario start adding words document happen add thes document play video starting 41 follow transcript 041 change game right picture likelihood function look start likelihood function two words right add words know multiply likelihood function additional terms account additional occurrences case additional terms going multiply term right probability play video starting 112 follow transcript 112 occurrence wed multiply term add terms number thes add document d obviously changes likelihood function whats interesting think change solution whats optimal solution play video starting 138 follow transcript 138 intuitively youd know original solution pulling 9 versus pulling longer optimal new function right play video starting 148 follow transcript 148 question change general sum know take away probability mass word add probability mass word question word reduce probability word larger probability particular lets think probability increased 01 decrease 01 think play video starting 219 follow transcript 219 pause video moment think question understanding important behavior mixture model maximum likelihood estimator look formula moment object function influenced text computer imagine make sense actually assign smaller probability text lock make room larger probability repeated times increase bit positive impact slight decrease text relatively small impact occurred right means behavior observe high frequency words generated high probabilities distributions surprise maximizing likelihood data word occurs makes sense give word higher probability impact likelihood function fact general phenomenon maximum likelihood estimator case occurrences term encourages unknown distribution theta sub d assign higher probability word play video starting 47 follow transcript 407 interesting think impact probability theta sub b probability choosing two component models weve assuming model equally likely gives 05 look likelihood function try picture happen increase probability choosing background model terms different form probability play video starting 440 follow transcript 440 larger background high probability word coefficient 09 05 larger larger overall result larger makes important theta sub d increase probability large impact increasing probability regulated coefficient point larger background important increase value means behavior high frequency words tend high probabilities effected regularized probability choosing component likely component chosen important higher values frequent words various small probability chosen incentive summarize discussed mixture model discussed estimation problem mixture model particular discussed general behavior estimator means expect estimator capture infusions component model attempts assign high probabilities high frequent words data collaboratively maximize likelihood second different component models tend bet high probabilities different words avoid competition waste probability allow collaborate efficiently maximize likelihood play video starting 633 follow transcript 633 probability choosing component regulates collaboration competition component models allow component models respond change example frequency theta point data play video starting 653 follow transcript 653 talked special case fixing component background word distribution right distribution estimated collection documents large collection english documents distribution normalized frequencies terms give probabilities words specialized mixture model show effectively rid word component play video starting 723 follow transcript 723 make cover topic discriminative play video starting 727 follow transcript 727 example imposing prior model parameter prior basically means model exactly background language model recall talked bayesian estimation prior allow favor model consistent prior fact consistent going say model impossible zero prior probability effectively excludes scenario issue talk later music
play video starting 6 follow transcript 006 lecture expectationmaximization algorithm called em algorithm lecture going continue discussion probabilistic topic models particular going introduce em algorithm family useful algorithms computing maximum likelihood estimate mixture models familiar scenario two component mixture model try factor background words topic word distribution interested computing estimate going try adjust probability values maximize probability observed document note assume parameters known thing unknown word probabilities given theta sub lecture going look compute maximum likelihood estimate lets start idea separating words text data two groups group explained background model group explained unknown topic word distribution basic idea mixture model suppose actually know word distribution mean example words known background word distribution hand words text mining clustering known topic word distribution color blue blue words assumed topic word distribution know separate words problem estimating word distribution extremely simple think moment youll realize simply take words known word distribution theta sub d normalize problem easy solve known words distribution precisely fact making model longer mixture model observe distribution generate part data actually back single word distribution problem case lets call words known theta d pseudo document d prime normalize words counts word wi thats fairly straightforward dictated maximum likelihood estimator idea doesnt work practice dont know word distribution gives idea guess word written specifically given parameters infer distribution word lets assume actually know tentative probabilities words theta sub d parameters known mixture model lets consider word text question think text likely having generated theta sub d theta sub b words infer distribution generate text inference process typical bayesian inference situation prior two distributions prior prior probability distribution prior given two probabilities case prior saying model equally likely imagine different prior possible called prior guess distribution generate word reserve word thats call prior dont observe word dont know word observed best guess say theyre equally likely right flipping coin bayesian inference typically learn update belief observed evidence evidence evidence word text know interested word text text regarded evidence bayes rule combine prior data likelihood end combine prior likelihood basically probability word text distribution cases text possible note background possible small probability intuitively guess case youre guess text probably theta sub d likely theta sub d probably text higher probability theta sub d background model small probability going say text likely theta sub d guess distribution generate text depend high probability text word distribution tend guess distribution gives word higher probability likely maximize likelihood going word higher likelihood words going compare two probabilities word given distributions guess affected prior compare two priors imagine adjust probabilities going say probability choosing background model 100 percent strong prior affect guess think wait moment text background probability small prior high end combine two base formula provides solid principled way making guess quantify specifically lets think probability word generated fact theta sub d order texts generated theta sub d two things happen theta sub d selected selection probability secondly actually observed text distribution multiply two probability text fact generated theta sub d similarly background model probability generating text product similar form introduced latent variable z denote word background topic z zero means topic theta sub d means background theta sub b probability text generated simply normalize estimate probability word text theta sub d theta sub b equivalently probability z equal zero given observed evidence text application bayes rule step crucial understanding em algorithm able initialize parameter values randomly going take guess z values distributing generate word initialized parameter values allow complete specification mixture model allows apply bayes rule infer distribution likely generate word prediction essentially helped separate words two distributions cant separate sure separate probabilistically
play video starting follow transcript 000 sound general idea expectationmaximization em algorithm play video starting 14 follow transcript 014 em algorithms introduce hidden variable help solve problem easily case hidden variable binary variable occurrence word binary variable indicate word generated 0 sub d 0 sub p show possible values variables example background z value text hand topic zero z play video starting 53 follow transcript 053 course dont observe z values imagine theyre values z attaching words play video starting 12 follow transcript 102 thats call hidden variables play video starting 16 follow transcript 106 idea talked predicting word distribution generate word predictor value hidden variable em algorithm work follows initialize parameters random values case parameters mainly probability word given theta sub d initial addition stage initialized values allow base roll take guess z values wed guess values cant say sure textt background guess given formula called estep algorithm try estep guess z values invoke thats called mstep step simply take advantage inferred z values group words distribution ground play video starting 227 follow transcript 227 normalize count estimate probabilities revise estimate parameters play video starting 236 follow transcript 236 illustrate group words believed come zero sub d thats text mining algorithm example clustering play video starting 251 follow transcript 251 group help reestimate parameters interested help estimate parameters play video starting 36 follow transcript 306 note set parameter values randomly guess improved estimate course dont know exactly zero going split hard way going softer split happened play video starting 329 follow transcript 329 going adjust count probability believe word generated theta sub d play video starting 339 follow transcript 339 come come right estep em algorithm iteratively improve uur initial estimate parameters estep mstep estep augment data additional information z mstep take advantage additional information separate data split data accounts collect right data accounts reestimate parameter new generation parameter going repeat going estep improve estimate hidden variables lead generation reestimated parameters play video starting 434 follow transcript 434 word distribution interested play video starting 439 follow transcript 439 okay bridge two variable z hidden variable indicates likely water top water distribution theta sub p play video starting 456 follow transcript 456 slide lot content pause reader digest basically captures essence em algorithm start initial values random themself invoke estep followed mstep improved setting parameters repeated hillclimbing algorithm gradually improve estimate parameters explain later guarantee reaching local maximum loglikelihood function lets take look computation specific case formulas em formulas superscripts n indicate generation parameters example n plus means improved improvement setting assumed two numerals equal probabilities background model null relevance statistics word counts assume four words counts background model assigns high probabilities common words play video starting 625 follow transcript 625 iteration picture happen initialize values probability interested normalized uniform distribution words play video starting 640 follow transcript 640 estep give guess distribution generate word different probabilities different words thats words different probabilities background two distributions equally likely initial audition say uniform distribution difference background distribution different guess probability words believed likely topic play video starting 715 follow transcript 715 hand likely probably background play video starting 720 follow transcript 720 z values know mstep probabilities adjust counts four multiplied 033 order allocated accounts topic play video starting 739 follow transcript 739 done multiplication note guess says 100 point zero play video starting 752 follow transcript 752 full count word topic general going point zero going percentage counts topic simply normalize counts new generation parameters estimate compare older play video starting 818 follow transcript 818 compare probability different words believed come topic higher probability text play video starting 832 follow transcript 832 course new generation parameters allow adjust inferred latent variable hidden variable values new generation values estep based new generation parameters new inferred values zs give generation estimate probabilities word actually happen compute probabilities em algorithm row show loglikelihood likelihood increasing iteration note loglikelihood negative probability 0 1 take logarithm negative value whats interesting youll note column inverted word split probabilities word believed come distribution case topical distribution right wonder useful main goal estimate word distributions primary goal hope discriminative order distribution column biproduct actually useful think example estimate extent document covered background words add take average know extent covered background versus content explained background music
play video starting 7 follow transcript 007 showed empirically likelihood converge theoretically proved em algorithm converge local maximum heres illustration happened detailed explanation required knowledge inequalities havent covered play video starting 39 follow transcript 039 x dimension c0 value parameter y axis likelihood function curve original likelihood function hope maximize hope find c0 value point maximize case mitsumoto easily find analytic solution problem resolve numerical errors em algorithm algorithm hillclimb algorithm mean start random guess lets say start thats starting point try improve moving point higher likelihood thats ideal hill climbing em algorithm way achieve two things fix lower bound likelihood function lower bound play video starting 151 follow transcript 151 fit lower bound maximize lower bound course reason works lower bound easier optimize know current guess maximizing lower bound move point top play video starting 213 follow transcript 213 right map original likelihood function find point lower bound guaranteed improve guess right improve lower bound original likelihood curve lower bound definitely improved play video starting 236 follow transcript 236 know improving lower bound definitely improve original likelihood function lower bound example current guess parameter value given current generation guess reestimated parameter values illustration guess better current guess reached maximum stuck two equal estep basically compute lower bound dont directly compute likelihood function compute length variable values basically part lower bound helps determine lower bound mstep hand maximize lower bound allows move parameters new point thats em algorithm guaranteed converge local maximum play video starting 342 follow transcript 342 imagine local maxima repeat em algorithm multiple times order figure actual global maximum actually general difficult problem numeral optimization example started gradually climb top thats optimal wed climb way way climb gear start em algorithm generally start different points way determine good initial starting point play video starting 429 follow transcript 429 summarize lecture introduced em algorithm general algorithm computing maximum maximum likelihood estimate kinds models simple model hillclimbing algorithm converge local maximum depend initial points play video starting 449 follow transcript 449 general idea two steps improve estimate estep roughly inaudible predicting values useful hidden variables simplify estimation case distribution generate word mstep exploit augmented data make easier estimate distribution improve estimate parameters improve guaranteed terms likelihood function note necessary stable convergence parameter value likelihood function ensured increase properties satisfied order parameters convert stable value play video starting 547 follow transcript 547 data augmentation done probabilistically means going say exactly whats value hidden variable going probability distribution possible values hidden variables causes split counts events probabilistically play video starting 67 follow transcript 607 case split word counts two distributions music
play video starting follow transcript 000 sound lets talk exchanging plsa lda motivate talk deficiencies plsa generative model compute probability new document thats pis needed generate document pis tied document training data cant compute pis future document play video starting 34 follow transcript 034 theres heuristic workaround secondly parameters ive asked compute parameters exactly plsa parameters means model complex means local maxima prone overfitting means hard find good local maximum play video starting 12 follow transcript 102 representing global maximum terms explaining future data find overfit training data complexity model model flexible fit precisely training data looks doesnt allow generalize model data play video starting 123 follow transcript 123 necessary problem text mining interested hitting training documents interested modern future data cases care generality worry overfitting play video starting 142 follow transcript 142 lda proposing improve basically make plsa generative model imposing dirichlet prior model parameters dirichlet special distribution specify product sense lda bayesian version plsa parameters regularized parameters achieve goal plsa text mining means compute top coverage topic word distributions plsa theres parameters plsa fewer fewer parameters order compute topic coverage word distributions face problem influence variables parameters model influence part face local maximum problem essentially similar theoretically lda elegant way looking top bottom problem lets generalize plsa lda standard plsa lda full treatment lda scope course dont time depth talking give brief idea whats extending enables right picture lda remove background model simplicity play video starting 315 follow transcript 315 model parameters free change impose prior word distributions represented theta vectors word distributions set parameters pis present vector convenient introduce lda vector document case theta vector topic play video starting 350 follow transcript 350 difference lda plsa lda going allow free chain going force drawn distribution play video starting 43 follow transcript 403 specifically drawn two dirichlet distributions respectively dirichlet distribution distribution vectors gives probability four particular choice vector take example pis right dirichlet distribution tells vectors pi likely distribution controlled vector parameters alphas play video starting 431 follow transcript 431 depending alphas characterize distribution different ways full choices pis likely example favor choice relatively uniform distribution topics favor generating skewed coverage topics controlled alpha similarly topic word distributions drawn dirichlet distribution beta parameters note alpha k parameters corresponding inference k values pis document beta n values corresponding controlling m words vocabulary play video starting 517 follow transcript 517 impose price generation process different start joined pis dirichlet distribution pi tell probabilities play video starting 535 follow transcript 535 going pi topic course similar plsa model play video starting 547 follow transcript 547 similar going distributions free going draw dirichlet distribution going sample word rest similar likelihood function complicated lda theres close connection likelihood function lda plsa im going illustrate difference top plsa likelihood function copied previous slide dropped background simplicity play video starting 627 follow transcript 627 lda formulas similar things equation essentially probability generating word multiple word distributions play video starting 640 follow transcript 640 formula sum possibilities generating word sum product probability choosing topic multiplied probability observing word topic play video starting 655 follow transcript 655 important formula ive stressed multiple times actually core assumption topic models topic models extensions lda plsa rely important understand gives probability getting word mixture model probability document plsa component lda formula lda formula add sum integral thats account fact pis fixed drawn original distribution thats thats take integral consider possible pis possibly draw dirichlet distribution similarly likelihood collection components added integral play video starting 758 follow transcript 758 right basically area adding integrals account uncertainties added course dirichlet distributions cover choice parameters pis theta play video starting 812 follow transcript 812 likelihood function lda lets talk parameter estimation inferences parameters estimated exactly approach maximum likelihood estimate lda think parameters lda versus plsa youll therere fewer parameters lda case parameters alphas betas maximum likelihood estimator compute course complicated form likelihood function complicated whats important notice parameters interested name topics coverage longer parameters lda case basic inference posterior inference compute based parameters alpha beta unfortunately computation intractable generally resort approximate inference play video starting 918 follow transcript 918 methods available im sure different tool kits lda read papers play video starting 930 follow transcript 930 different extensions lda course cant give indepth instruction know computed based inference parameters alphas betas math inaudible actually end math list similar plsa especially algorithm called class assembly algorithm looks similar algorithm end similar play video starting 1010 follow transcript 1010 summarize discussion properties topic models models general principle way mining analyzing topics text applications best basic task setup take test data input going output k topics topic characterized word distribution going output proportions topics covered document play video starting 1038 follow transcript 1038 plsa basic topic model fact basic topic model adequate applications thats spend lot time explain plsa detail play video starting 1053 follow transcript 1053 lda improves plsa imposing priors led theoretically appealing models practice lda plsa tend give similar performance practice plsa lda work equally tasks play video starting 1112 follow transcript 1112 suggested readings know topic nice review probabilistic topic models play video starting 1120 follow transcript 1120 second discussion automatically label topic model ive distributions intuitively suggest topic exactly topic phrases label topic make easy understand paper techniques third empirical comparison lda plsa various tasks conclusion tend perform similarly music
play video starting follow transcript 000 sound lecture text clustering play video starting 14 follow transcript 014 lecture going talk text clustering play video starting 18 follow transcript 018 important technique topic mining analysis particular lecture going start basic questions clustering play video starting 31 follow transcript 031 text clustering interested text clustering play video starting 38 follow transcript 038 following lectures going talk text clustering evaluate clustering results play video starting 47 follow transcript 047 text clustering play video starting 49 follow transcript 049 clustering actually general technique data mining learned courses play video starting 56 follow transcript 056 idea discover natural structures data play video starting 11 follow transcript 101 words group similar objects case objects course text objects example documents terms passages sentences websites ill group similar text objects lets example dont text objects shapes denote objects grouped play video starting 133 follow transcript 133 ask natural structures natural groups look agree group objects based chips locations two dimensional space play video starting 153 follow transcript 153 got three clusters case play video starting 156 follow transcript 156 agreement three clusters depends perspective look objects play video starting 27 follow transcript 207 thing different way different clusters youll example ambiguity clearly main point problem actually defined play video starting 229 follow transcript 229 problem lies define similarity mean similar objects play video starting 238 follow transcript 238 problem clearly defined order defined clustering problem play video starting 246 follow transcript 246 problem general two objects similar depending look example kept two words car horse play video starting 3 follow transcript 300 two words similar depends look physical play video starting 311 follow transcript 311 properties car horse different look functionally car horse transportation tools sense similar depends perspective look objects play video starting 332 follow transcript 332 make clustering problem defined user define perspective assessing similarity play video starting 344 follow transcript 344 call perspective clustering bias play video starting 349 follow transcript 349 define clustering problem important specify play video starting 355 follow transcript 355 perspective similarity defining similarity group similar objects similarity defined different ways group objects lets look example objects shapes similar slide ask group objects play video starting 438 follow transcript 438 feel previous slide example think steer group ships give cluster looks feel objects grouped based sizes give different way cluster data look size look similarity size play video starting 512 follow transcript 512 clearly depending perspective different clustering result clearly tells order evaluate clustering perspective perspective hard define best clustering result play video starting 536 follow transcript 536 examples text clustering setup play video starting 542 follow transcript 542 example cluster documents text collection case documents units clustered play video starting 552 follow transcript 552 able cluster terms case terms objects cluster terms define concept theme topic fact theres topic models previous lectures give cluster terms sense take terms high probabilities word distribution example cluster text segments example passages sentences segments extract former larger text objects play video starting 632 follow transcript 632 example extract order text segments topic lets say topic model weve got text objects play video starting 645 follow transcript 645 cluster segments weve got discover interesting clusters ripple subtopics case combining text clustering techniques general lot text mining play video starting 75 follow transcript 705 accurate combined flexible way achieve goal sophisticated mining analysis text data play video starting 716 follow transcript 716 cluster fairly large text objects mean text objects contain lot documents example cluster websites website actually compose multiple documents similarly cluster articles written author example trigger articles published unit clustering way group authors based theyre published papers similar play video starting 755 follow transcript 755 text clusters cluster generate hierarchy thats general cluster text object different levels play video starting 88 follow transcript 808 generally text clustering interesting useful technique text mining particularly exploratory text analysis play video starting 820 follow transcript 820 typical scenario getting lot text data lets say email messages customers time period literature articles hope sense overall content connection example interested getting sense major topics typical representative documents connection clustering help achieve goal link similar text objects objects duplicated content example case technique help remove redundancy remove duplicate documents play video starting 910 follow transcript 910 topic linking complete coverage topic play video starting 919 follow transcript 919 text clustering create structure text data create hierarchy structures useful problems play video starting 931 follow transcript 931 text clustering induce additional features represent text data cluster documents treat cluster feature say document cluster feature value document cluster feature value zero helps additional discrimination text classification discuss later play video starting 959 follow transcript 959 general applications text clustering thought two specific ones cluster search results example inaudible search engine cluster results user overall structure results return fall query querys ambiguous particularly useful clusters likely represent different senses ambiguous word play video starting 1028 follow transcript 1028 application understand major complaints customers based emails right case cluster email messages find major clusters understand major complaints music
play video starting follow transcript 000 sound lecture generating probabilistic models text clustering play video starting 13 follow transcript 013 lecture going continue discussing text clustering going introduce generating probabilistic models way text clustering overall plan covering text clustering previous lecture talked text clustering text clustering interesting lecture going talk text clustering general slide two kinds approaches generating probabilistic models topic lecture later discuss similaritybased approaches play video starting 53 follow transcript 053 talk generating models text clustering useful revisit topic mining problem topic models two problems similar slide earlier lecture topic model show input text collection c number topics k vocabulary v hope generate output two things set topics denoted theta awarded distribution pi j probabilities document covers topic topic coverage visualized slide topic model main difference text clustering problem document assumed possibly cover multiple topics general document covering topic nonzero probabilities text clustering allow document cover topic assume topic cluster play video starting 224 follow transcript 224 means change problem definition slightly assuming document generated precisely topic play video starting 237 follow transcript 237 definition clustering problem youll hear output changed longer detailed coverage distributions pi j going cluster assignment decisions ci ci decision document c sub going take value 1 k indicate k clusters play video starting 39 follow transcript 309 basically tells d cluster illustrated longer multiple topics covered document precisely topic topic uncertain connection play video starting 329 follow transcript 329 problem mining topic discussed earlier slide hope estimate topic model distribution based precisely document thats assume document covers precisely topic play video starting 352 follow transcript 352 consider variations problem example consider n documents covers different topic thats n documents topics course case documents independent topics independent allow documents share topics assume going assume fewer topics number documents documents share topics n documents share k topics precisely document clustering problem play video starting 434 follow transcript 434 connections naturally think probabilistically generative model solve problem text clustering play video starting 443 follow transcript 443 question generative model clustering play video starting 449 follow transcript 449 cases designing generative model hope generative model adopt output hope generate structure hope model case clustering structure topics document covers topic hope embed preferences generative model think main difference problem topic model talked earlier main requirement force document generated precisely topic k topics topic model play video starting 535 follow transcript 535 lets revisit topic model detail detailed view two component mixture model k components looks similar generate document play video starting 553 follow transcript 553 generate word independent play video starting 557 follow transcript 557 generate word make choice distributions decide probability p theta 1 probability choosing distribution top make decision regarding distribution generate word going distribution sample word note generative model decision distribution word independent means example generated second distribution theta 2 text likely generated top play video starting 649 follow transcript 649 means words document generated general multiple distributions play video starting 658 follow transcript 658 text clustering document clustering hoped document generated precisely topic play video starting 79 follow transcript 709 means modify model lets think model clustering reason allowed multiple topics contribute word document play video starting 728 follow transcript 728 causes confusion going know cluster document importantly violating assumption partitioning documents clusters topic correspond cluster documents document generate precisely topic means words document generated precisely distribution true topic model thats clustering did ensure distribution generate words document play video starting 815 follow transcript 815 realize problem naturally design alternative mixture model clustering youre make decision regarding distribution generate document document potentially generated k word distributions time made decision topics going stay regime generate words document play video starting 849 follow transcript 849 means made choice distribution generating word going stay distribution generating words document words make choice basically make decision document state generate words similarly choosing second distribution theta sub 2 state generate entire document d compare picture previous decision particular distribution made document case document clustering case topic model make decisions number words document word make potentially different decision thats key difference two models play video starting 958 follow transcript 958 obviously mixed model group box show model give probability document model switch choosing different distribution dont observe thats mixture model course main problem document clustering infer distribution generate document allow recover cluster identity document play video starting 1037 follow transcript 1037 useful think difference topic model mentioned multiple times play video starting 1046 follow transcript 1046 mainly two differences choice play video starting 1056 follow transcript 1056 particular distribution made document clustering topic model made multiple times different words second word distribution going regenerate words document play video starting 1119 follow transcript 1119 case distribution doesnt generate words document multiple distribution generate words document play video starting 1134 follow transcript 1134 lets think special case probability choosing particular distribution equal 1 means uncertainty stick particular distribution case clearly longer mixture model theres uncertainty precisely distributions generating document going back case estimating order distribution based document play video starting 1212 follow transcript 1212 thats connection discussed earlier clearly cases generative model solve problem look data think design model design model step write likelihood function going look estimate parameters play video starting 1236 follow transcript 1236 case whats likelihood function going similar topic models different play video starting 1245 follow transcript 1245 recall likelihood function looks realize general probability observing data point mixture model going sum possibilities generating data play video starting 13 follow transcript 1300 case going sum k topics user generated document sum recall formula looks going product two probabilities probability choosing distribution probability observing particular datapoint distribution play video starting 1327 follow transcript 1327 map formula problem probability observing document d play video starting 1337 follow transcript 1337 basically sum case two different distributions simplified situation two clusters case sum two cases case probability choosing distribution theta 1 theta 2 probability multiplied probability observing document particular distribution play video starting 1416 follow transcript 1416 expanded probability observing document product observing word x sub made assumption word generated independently probability document product probability word document play video starting 1440 follow transcript 1440 form similar topic model useful think difference purpose copying probability topic model two components formula looks similar ways similar play video starting 152 follow transcript 1502 difference play video starting 156 follow transcript 1506 particular difference top mixture model document clustering take product take sum play video starting 1516 follow transcript 1516 thats corresponding assumption make choice choosing distribution stay distribution itll generate words thats product sum play video starting 1530 follow transcript 1530 sum corresponds choice topic model sum actually product thats generated word independently thats product generate word make decision regarding distribution sum word general mixture models estimate models algorithm discuss later music
play video starting follow transcript 000 sound lecture continuing discussion generative probabilistic models text clustering play video starting 13 follow transcript 013 lecture going continue talking text clustering particularly generative probabilistic models play video starting 23 follow transcript 023 slide earlier written likelihood function document two distributions two component mixed model document clustering play video starting 39 follow transcript 039 lecture going generalize k clusters look formula think question generalize youll realize add terms play video starting 57 follow transcript 057 add thetas probabilities thetas probabilities generating d thetas precisely going general presentation mixture model document clustering play video starting 119 follow transcript 119 cases follow steps generating model think data case data collection documents end documents denoted d sub talk models think modelling case design mixture k unigram language models bit different topic model similar parameters set theta denote distributions corresponding k unigram language models p theta probability selecting k distributions generate document note goal find clusters actually general notion probability cluster later allow assign document cluster highest probability able generate document play video starting 231 follow transcript 231 result recover interesting play video starting 236 follow transcript 236 properties later play video starting 242 follow transcript 242 model basically make following assumption generation document theta probability theta generate words document distribution note important distribution words document different topic model likelihood function play video starting 310 follow transcript 310 take look formula different notation second line equation going notation changed unique word vocabulary product particular position document x subject w change notation change allows show estimation formulas easily change topic model presentation basically product probabilities words play video starting 410 follow transcript 410 likelihood function talk parameter estimation simply maximum likelihood estimator thats standard way things familiar different model estimated parameters allocate clusters documents lets take look situation closely repeated parameters mixture model play video starting 443 follow transcript 443 think estimating model actually information clustering right theta example represents content cluster actually byproduct help summarize cluster look top terms cluster word distribution tell cluster play video starting 511 follow transcript 511 p theta interpreted indicating size cluster tells likely cluster generate document likely cluster generate document assume larger cluster size play video starting 530 follow transcript 530 note plsa probability theta dependent d play video starting 537 follow transcript 537 recall topic chose document actually depends d means document potentially different choice topics generic choice probability documents course particular document infer topic likely generate document sense document dependent probability clusters play video starting 610 follow transcript 610 lets look key problem assigning documents clusters assigning clusters documents play video starting 617 follow transcript 617 thats computer c sub d take values range k indicate cluster assigned d play video starting 628 follow transcript 628 think way likelihood assign d cluster corresponding topic theta likely generate d play video starting 642 follow transcript 642 means going distributions gives d highest probability words distribution content matches d inaudible intuitively makes sense approach consider size clusters available better way likelihood prior case prior p theta going base formula compute posterior probability theta given d play video starting 725 follow transcript 725 theta based posterior probability following formula bottom slide case going theta large p theta means large cluster high probability generating d going favor cluster thats large consistent document intuitively makes sense chance document large cluster generally higher small cluster play video starting 87 follow transcript 807 means estimate parameters model easily solve problem document clustering discuss actually compute estimate model music
play video starting follow transcript 000 sound lecture continuing discussion generative probabilistic models tax classroom play video starting 14 follow transcript 014 lecture going finishing discussion generative probabilistic models text crossing play video starting 21 follow transcript 021 slide show define mixture model text crossing likelihood function looks compute maximum likelihood estimate estimate parameters lecture going talk exactly going compute maximum likelihood estimate cases algorithm solve problem mixture models heres detail algorithm document clustering understood algorithm works topic models trsa think similar adapt bit new mixture model recall algorithm starts initialization parameters happened topic models play video starting 128 follow transcript 128 going repeat likelihood converges step e step m step m step going infer distribution generate document introduce hidden variable zd document variable take value range 1 k representing k different distributions play video starting 159 follow transcript 159 specifically basically going apply base rules infer distribution likely generated document computing posterior probability distribution given document play video starting 217 follow transcript 217 know proportional probability selecting distribution p z probability generating document distribution product probabilities world document clear remember play video starting 245 follow transcript 245 normalizer constraint probability case know constraint probability estep probabilities z equals sum 1 documented generated precisely k topics probability generated sum 1 know constraint easily compute distribution long know proportional compute product simply normalize play video starting 331 follow transcript 331 probabilities make sum 1 topics thats estep estep know distribution likely generated document d unlikely play video starting 345 follow transcript 345 mstep going reestimate parameters based z values knowledge distribution generate document reestimation involves two kinds parameters 1 p theta probability selecting particular distribution observe dont knowledge cluster likely observed documents crack evidence infer cluster likely proportional sum probability z sub d j equal play video starting 434 follow transcript 434 gives evidence topic theta generate document pull normalize probabilities play video starting 450 follow transcript 450 key theta sub play video starting 454 follow transcript 454 parameters probabilities words distribution cluster similar case piz report kinds words documents inferred generated particular topic theta allows estimate words actually generated theta normalize accounts probabilities probabilities words sum note important understand constraints precisely normalizing formulas important know distribution play video starting 554 follow transcript 554 example probability theta k topics thats k probabilities sum 1 probability word given theta probability distribution words probabilities sum 1 lets take look simple example two clusters ive two clusters ive assumed initialized values two distributions lets assume randomly initialize two probability selecting cluster 05 equally likely lets consider document two occurrences text two occurrences mining four words medical health did occur document lets think hidden variable play video starting 650 follow transcript 650 document hidden variable piz hidden variable work thats output mixture model case output mixture model observation mixture model document word hidden variable attached document hidden variable tell distribution generate document going take two values two indicate two topics play video starting 725 follow transcript 725 infer distribution generally d base rule looks order topic theta 1 generate document two things happen theta sub 1 selected given p theta 1 second generating four words document two occurrences text two occurrences sub mining thats numerator product probability selecting theta 1 probability generating document theta 1 denominator sum two possibilities generality document plug numerical values verify case document likely generated theta 1 likely theta 2 probability easily compute probability z equals 2 given document constraint thats going 1 minus 100 101 important note computation potential problem underflow look original numerator denominator involves competition product small probabilities imagine document words going small value cause problem underflow solve problem normalize take average two math solutions compute average screen called theta bar play video starting 924 follow transcript 924 average distribution comparable distributions terms quantities magnitude divide numerator denominator normalizer basically normalizes probability generating document average word distribution normalizer exactly normalizer numerator denominator value expression changed normalization make numerators denominators manageable overall value going small avoid underflow problem play video starting 1024 follow transcript 1024 times logarithm product convert sum log probabilities help preserve precision case algorithm solve problem sum denominator normalizes effective solving problem technique thats useful situations situations lets look mstep estep estimate distribution likely generated document d d1s got topic d2 second topic lets think compute mstep basically reestimate parameters look p theta 1 p theta 2 estimate intuitively pool z probabilities estep documents say theyre likely theta 1 intuitively give higher probability theta 1 case take average probabilities weve obtain 06 theta 1 01 likely theta 2 probability 02 natural 04 word probabilities intuition going order estimate probabilities words theta 1 going look documents generated theta 1 going pull words documents normalize basically play video starting 1220 follow transcript 1220 specifically going example kinds text documents estimating probability text given theta 1 going raw count total accounts discount probabilities document likely generated theta 1 gives fractional accounts accounts normalized order probability normalize probability words assign 1 summarize discussion generative models clustering show slight variation topic model clustering documents shows power generating models general changing generation assumption changing model slightly achieve different goals capture different patterns types data case cluster represented unigram language model word distribution similar topic model word distribution actually generates term cluster byproduct document generated choosing unigram language model generating words document single language model different copy model generate words document multiple unigram language models play video starting 1356 follow transcript 1356 estimated model parameters given topic characterization cluster probabilistic assignment document cluster play video starting 147 follow transcript 1407 probabilistic assignment useful applications achieve harder clusters mainly play video starting 1416 follow transcript 1416 partition documents disjointed clusters force document cluster corresponding words distribution thats likely generated document weve algorithm compute maximum likelihood estimate case special number addition technique avoid underflow music
play video starting follow transcript 000 music lecture similaritybased approaches text clustering play video starting 13 follow transcript 013 lecture going continue discussion text clustering play video starting 18 follow transcript 018 particular going cover different kinds approaches generative models similaritybased approaches general idea similaritybased clustering explicitly specify similarity function measure similarity two text objects contrast generative model implicitly define clustering bias particular object function inaudible function play video starting 52 follow transcript 052 process driven optimizing inaudible explicitly view think similar useful allows inject particular view similarity clustering program similarity function aim optimally partitioning partitioning data clusters different groups try maximize intergroup similarity minimize intergroup similarity ensure objects put group similar objects put different groups similar general goals clustering trade achieving goals different methods similarity based clustering general think distinguish two strategies high level progressively construct hierarchy clusters leads hierarchical clustering distinguish two ways construct hierarchy depending started collection divide connection started individual objectives gradually group bottomup called agglomerative gradually group similar objects larger larger clusters group topdown divisive case gradually partition data set smaller smaller clusters general strategy start initial tentative clustering iteratively improve leads flat clustering example kmeans different clustering methods available full coverage clustering methods scope course going talk two representative methods detail play video starting 314 follow transcript 314 hierarchical agglomerative clustering hac kmeans agglomerative hierarchical clustering case given similarity function measure similarity two objects gradually group similar objects bottomup fashion form larger larger groups form hierarchy stop stopping criterion met number clusters achieved threshold similarity reached play video starting 352 follow transcript 352 different variations mainly differ ways compute group similarity based individual objects similarity lets illustrate induced structure based similarity start text objects measure similarity course based provided similarity function pair highest similarity group going pair group play video starting 430 follow transcript 430 two highest similarity going gradually group time going pick highest similarity similarity pairs group play video starting 445 follow transcript 445 give binary tree eventually group play video starting 450 follow transcript 450 depending applications hierarchy structure browsing example cutoff lets say cut four clusters threshold cut cut high level two clusters general idea think implement algorithm youll realize specified compute group similarity play video starting 524 follow transcript 524 given similarity function two objects group groups assess similarity two groups different ways three popular methods singlelink completelink averagelink given two groups singlelink algorithm going define group similarity similarity closest pair two groups completelink defines similarity two groups similarity system pair averagelink defines similarity average similarity pairs two groups easier understand methods illustrating two groups g1 g2 objects group know compute similarity two objects question compute similarity two groups play video starting 629 follow transcript 629 general base similarities objects two groups play video starting 635 follow transcript 635 terms singlelink looking closest pair case two paired objects defined similarities two groups play video starting 647 follow transcript 647 long close going say two groups play video starting 651 follow transcript 651 close optimistic view similarity play video starting 657 follow transcript 657 complete link hand sense pessimistic taking similarity two pair similarity two groups going make sure two groups having high similarity pair two groups objects two groups ensured high similarity play video starting 729 follow transcript 729 average link takes average pairs different ways computing group similarities lead different clustering algorithms general give different results useful take look differences make comparison play video starting 753 follow transcript 753 singlelink expected generally loose clusters reason long two objects similar two groups bring two groups play video starting 89 follow transcript 809 think similar having parties people means two groups people partying long group person play video starting 827 follow transcript 827 connected group two leaders two groups good relationship bring two groups case cluster loose theres guarantee members two groups actually close away case based individual decisions sensitive outliers completelink opposite situation expect clusters tight based individual decision sensitive outliers continue analogy having party people completelink mean two groups come ensure play video starting 921 follow transcript 921 people unlikely talk comfortable talking ensure class coherent average link clusters group decision play video starting 937 follow transcript 937 going insensitive outliers practice best depend application lose clusters aggressively cluster objects singlelink good times tight clusters completelink better general empirically evaluate methods application know better play video starting 107 follow transcript 1007 lets look example method similaritybased clustering case called kmeans clustering represent text object term vector assume similarity function defined two objects going start tentative clustering results selecting k randomly selected vectors centroids k clusters treat centers represent represent cluster gives initial tentative cluster going iteratively improve process goes centroids decide going assign vector cluster centroid closest current vector basically going measure distance vector centroids closest put object cluster tentative assignment objects clusters going partition objects k clusters based tentative clustering centroids play video starting 1128 follow transcript 1128 recompute centroid based locate object cluster adjust centroid repeat process similaritybased objective function case cluster sum squares converges theoretically show process actually going minimize cluster sum squares define object function given k clusters process converge local minimum think process moment remind algorithm mixture model play video starting 1213 follow transcript 1213 algorithm similar algorithm mixture model clustering specifically initialize parameters algorithm random initialization similar play video starting 1234 follow transcript 1234 algorithm recall going repeat estep mstep improve parameter estimation case going improve clustering result iteratively two steps fact two steps similar algorithm locate vector clusters based tentative clustering similar inferring distribution generate document mixture model essentially similar estep whats difference difference dont make probabilistic allocation case estep brother make choice going make call closest cluster two going say cluster two theres choice going say assume set belonging cluster two going probability going put object precisely cluster estep probability location split counts going say exactly distribution generate data point going adjust centroid similar mstep reestimate parameters thats better estimate parameter better clustering result adjusting centroid note centroid based average vectors cluster similar mstep countspull counts normalize difference course difference estep going consider probabilities count points case kmeans going make count objects allocated cluster subset data points algorithm principle consider data points based probabilistic allocations play video starting 1456 follow transcript 1456 nature similar thats maximizing defined object functions guaranteed convert local minimum summarize discussion clustering methods discussed model based approaches mainly mixture model implicit similarity function define clustering bias explicit define similarity function model defines clustering bias clustering structure built generative model thats potentially different model recover different structure play video starting 1540 follow transcript 1540 complex generative models discover complex clustering structures talk full easily design generate model generate hierarchical clusters prior customize clustering algorithm example control topic cluster multiple clusters disadvantage approach easy way directly control similarity measure play video starting 1611 follow transcript 1611 hard inject special definition similarity model play video starting 1620 follow transcript 1620 talked similaritybased approaches approaches flexible actually specify similarity functions play video starting 1629 follow transcript 1629 major disadvantage objective function clear play video starting 1635 follow transcript 1635 kmeans algorithm clearly defined objective function similar model based approach hierarchical clustering algorithm hand harder specify objective function clear exactly optimized play video starting 17 follow transcript 1700 approaches generate term clusters document clusters term clusters general generated representing term text content example take context term representation term done semantic relation learning certainly cluster terms based actual text inaudible course term clusters generated generative models weve music
play video starting follow transcript 000 music lecture evaluation text clustering play video starting 12 follow transcript 012 talked multiple ways text clustering know method works best play video starting 22 follow transcript 022 evaluation talk evaluation back clustering bias introduced beginning play video starting 32 follow transcript 032 two objects similar depending look play video starting 37 follow transcript 037 clearly specify perspective similarity problem clustering defined perspective important evaluation look slide two different ways cluster shapes ask question best better actually theres way answer question knowing wed cluster based shapes cluster based sizes thats precisely perspective clustering bias crucial evaluation play video starting 119 follow transcript 119 general evaluate text clusters two ways direct evaluation indirect evaluation direct evaluation answer following questions close systemgenerated clusters ideal clusters generated humans play video starting 138 follow transcript 138 closeness assessed play video starting 144 follow transcript 144 multiple perspectives help characterize quality cluster result multiple angles desirable play video starting 156 follow transcript 156 quantify closeness allow easily compare different measures based performance figures play video starting 29 follow transcript 209 finally case essentially inject clustering bias play video starting 215 follow transcript 215 humans basically humans bring desire clustering bias exactly general procedure look play video starting 228 follow transcript 228 given test set consists lot text objects humans create ideal clustering result going ask humans partition objects create gold standard judgments based particular application generate think best clustering results compare system generated clusters test set play video starting 31 follow transcript 301 ideally system results human generated results general going quantify similarity systemgenerated clusters gold standard clusters similarity measure multiple perspectives give various meshes quantitatively evaluate cluster clustering result commonly measures purity measures cluster similar object cluster gold standard normalized mutual information commonly measure basically measures based identity cluster object system generally predict cluster object gold standard vice versa mutual information captures correlation cluster labels normalized mutual information quantifying similarity evaluation purpose f measure possible measure play video starting 421 follow transcript 421 thorough discussion evaluation evaluation issues scope course play video starting 429 follow transcript 429 ive suggested reading end take look know play video starting 436 follow transcript 436 discuss high level ideas allow think evaluation applications second way evaluate text clusters indirect evaluation case question answer useful clustering results intended applications course application specific question usefulness going depend specific applications play video starting 57 follow transcript 507 case clustering bias imposed independent application counts best cluster result dependent application play video starting 519 follow transcript 519 procedure wise create test set text objects intended application quantify performance system play video starting 532 follow transcript 532 case care contribution clustering application baseline system compare play video starting 545 follow transcript 545 current system hope add clustering improve baseline system different clustering method trying experiment hope better idea word clustering case baseline system work add clustering algorithm baseline system produce clustering system play video starting 611 follow transcript 611 compare performance clustering system baseline system terms performance measure particular application play video starting 621 follow transcript 621 case call indirect evaluation clusters theres explicit assessment quality clusters assess contribution clusters particular application play video starting 637 follow transcript 637 summarize text clustering play video starting 641 follow transcript 641 useful unsupervised general text mining technique particularly useful obtaining overall picture text content needed explore text data step deal lot text data play video starting 71 follow transcript 701 second application second applications discover interesting clustering structures text data structures meaningful play video starting 713 follow transcript 713 approaches form text clustering discussed model based approaches narrative based approaches general strong clusters tend show matter method effectiveness method highly depends desired clustering bias captured appropriately done right generating model model design appropriate clustering right similarity function expressly define bias deciding optimal number customers difficult problem order cluster methods thats unsupervised algorithm theres training guide select best number clusters play video starting 85 follow transcript 805 methods automatically determine number clusters general implied application clustering bias thats specified clearly defining clustering bias impossible say optimal number cluster important keep mind play video starting 831 follow transcript 831 say application determine number clusters example youre clustering search results obviously dont generate 100 clusters number dictated interface design play video starting 846 follow transcript 846 situations able fitness data assess weve got good number clusters explain data vary number clusters watch fit data play video starting 97 follow transcript 907 general add components mixed model fit data better dont set probability new component zero cant general fit data question add components able significantly improve fitness data determine right number clusters finally evaluation clustering results done directly indirectly order good sense method works heres suggested reading particularly useful better understand matches calculated clustering general music
play video starting follow transcript 000 sound play video starting 6 follow transcript 006 lecture text categorization play video starting 11 follow transcript 011 lecture going talk text categorization play video starting 16 follow transcript 016 important technique text data mining analytics play video starting 22 follow transcript 022 relevant discovery various different kinds knowledge related topic mining analysis thats analyzing text data based predefined topics secondly related opinion mining sentiment analysis discovery knowledge observer human sensor categorize authors example based content articles written right general categorize observer based content produce play video starting 112 follow transcript 112 finally related textbased prediction text categorization techniques predict variables real world remotely related text data play video starting 127 follow transcript 127 important technique text data mining play video starting 134 follow transcript 134 overall plan covering topic going talk text categorization interested lecture going talk text categorization evaluate categorization results problem text categorization defined follows given set predefined categories possibly forming hierarchy set training examples training set labeled text objects means text objects enabled known categories task classify text object predefined categories picture slide shows happens play video starting 230 follow transcript 230 text categorization lot text objects processed categorization system system general assign categories documents right categorization results assume availability training examples documents tag known categories examples important helping system learn patterns different categories help system know recognize play video starting 311 follow transcript 311 categories new text objects specific examples text categorization fact examples play video starting 327 follow transcript 327 text objects vary categorize document passage sentence collections text case clustering units analyzed vary lot creates lot possibilities secondly categories vary allocate general theres two major kinds categories internal categories categories categorize content text object example topic categories sentiment categories generally content text objects categorization content play video starting 48 follow transcript 408 external categories characterize entity associated text object example authors entities associated content produce content determining author written part example thats called author attribution play video starting 433 follow transcript 433 mininal categories associate text data long minimal connection entity text data example collect lot reviews restaurant lot reviews product text data help infer properties product restaurant case treat categorization problem categorize restaurants categorize products based corresponding reviews example external category specific examples applications news categorization common started lot news agencies assign predefined categories categorize news generated everyday virtual article categorizations important aspect example biomedical domain theres mesh annotations mesh stands medical subject heading ontology terms play video starting 549 follow transcript 549 characterize content literature articles detail play video starting 554 follow transcript 554 example application spam email detection filtering right spam filter help distinguish spams legitimate emails clearly binary classification problem play video starting 614 follow transcript 614 sentiment categorization product reviews tweets applications categorize comparing positive negative positive negative neutral play video starting 627 follow transcript 627 send categories assign two text content play video starting 635 follow transcript 635 application automatic email routing sorting automatically sort emails different folders thats application text categorization folder category play video starting 648 follow transcript 648 results important applications routing emails right person handle helpdesk email messaging generally routed particular person handle different people tend handle different kinds requests cases person manually assign messages right people imagine cant able automatically text categorization system help routing request class file incoming request categories category actually corresponds person handle request finally author attribution mentioned application example text actually infer properties play video starting 741 follow transcript 741 entities variants problem formulation simplest case binary categorization two categories examples information retrieval search engine play video starting 759 follow transcript 759 applications distinguishing relevant documents nonrelevant documents particular query play video starting 86 follow transcript 806 spam filtering distinguishing spams nonspams two categories classifications opinions two categories positive negative play video starting 819 follow transcript 819 general case kcategory categorization applications two categories topic categorization example multiple topics email routing example multiple folders route email right person handle multiple people classify cases two kinds categories play video starting 849 follow transcript 849 variation hierarchical categorization categories form hierarchy topical hierarchy common play video starting 858 follow transcript 858 variation joint categorization thats multiple categorization tasks related hope join categorization leverage dependency tasks improve accuracy individual task binary categorizations fundamental part simple probably actually perform categorization tasks example kcategory categorization task actually performed binary categorization play video starting 940 follow transcript 940 basically look category separately binary categorization problem object category meaning categories play video starting 953 follow transcript 953 hierarchical categorization done progressively flat categorization level categorize objects lets say small number highlevel categories category categorized subcategories play video starting 1015 follow transcript 1015 text categorization important showed applications general reasons text categorization helps enrich text representation thats achieve understanding text data thats useful text analysis categorization text represented multiple levels keyword conditions thats lot text processing tasks add categories two levels transition play video starting 1055 follow transcript 1055 semantic categories assigned directly indirectly useful application example semantic categories useful attribution directly useful example semantic categories facilitate aggregation text content case applications text categorization play video starting 1125 follow transcript 1125 example know overall opinions product play video starting 1132 follow transcript 1132 categorize opinions individual view positive negative allow easy aggregate sentiment tell 70 views positive 30 negative play video starting 1153 follow transcript 1153 categorization harder aggregate opinions concise way coding text sense based vocabulary applications text categorizations called text coded encoded control vocabulary second reasons text categorization infer properties entities text categories allows infer properties entities associate text data means text categorization discover knowledge world general long associate entity text data text data help categorize corresponding entities single information network connect entities text data obvious entities directly connected authors imagine authors affiliations authors age things actually connected text data indirectly made connection make prediction values general way allow text mining text categorization discover knowledge world useful especially big text data analytics text data extra sets data extracted humans infer decision factors nontextual data specifically text example think examples inferring properties entities example discovery nonnative speakers language done categorizing content speakers play video starting 14 follow transcript 1400 example predict party affiliation politician based political speech example text data infer knowledge real world nature problems thats defined text categorization problem music
play video starting 6 follow transcript 006 lecture methods text categorization play video starting 12 follow transcript 012 lecture going discuss text categorization play video starting 19 follow transcript 019 therere methods text categorization play video starting 25 follow transcript 025 method idea determine category based rules design carefully reflect domain knowledge category prediction problem example topic categorization news articles say news article mentions word game sports three times going say sports things allow deterministically decide category document put play video starting 12 follow transcript 102 strategy work following conditions hold categories defined allows person clearly decide category based clear rules play video starting 121 follow transcript 121 certainly categories play video starting 125 follow transcript 125 half easy distinguished based surface features text means official features keywords punctuations easily identify text data play video starting 141 follow transcript 141 example special vocabulary known occur particular category effective easily vocabulary padding vocabulary recognize category play video starting 157 follow transcript 157 sufficient knowledge designing words thats case effective domains general problems approach label intensive requires lot manual work obviously cant kinds categorization problems scratch different problem problem given rules doesnt scale play video starting 241 follow transcript 241 secondly handle uncertainty rules rules arent 100 reliable take example looking occurrences words texts trying decide topic play video starting 257 follow transcript 257 actually hard 100 correct rule example say game sports basketball sure sports imagine types articles mention cures exactly sports marginally touching sports main topic topic different topic sports play video starting 327 follow transcript 327 thats disadvantage approach finally rules inconsistent lead robustness specifically results categorization different depending rule applied case facing uncertainty decide order applying rules combination results contradictory problems approach turns problems solved alleviated machine learning play video starting 47 follow transcript 407 machine learning methods automatic put automatic quotation marks completely automatic cause require work specifically human experts help two ways human experts annotate data cells category labels tell computer documents receive categories called training data play video starting 438 follow transcript 438 secondly human experts set features represent text object potentially clue category basic features computers look play video starting 455 follow transcript 455 case tax natural choice words feature common choice start course sophisticated features phrases parts ancients tags syntax structures human experts machine running learn soft rules categorization training data soft rules means going decided category assigned document going rule deterministic similar saying matches games sports times likely sports going say exactly sure going probabilities weights combine evidences learning process basically going figure features useful separating different categories going figure optimally combine features minimize errors categorization training data training data important basis learning trained classifier applied new text object predict likely category thats simulate prediction human assign text object human make judgement machine learning text categorization talk problem general setting supervisement set learn classifier map value x map y x text objects y categories set categories class phi take value x input generate value y output hope output y right category x correct course judged based training data thats general goal machine learning problems supervised learning problems given examples input output function computers going figure function behaves based examples try able compute values future xs play video starting 738 follow transcript 738 general methods rely discriminative features text objects distinguish different categories thats features important provided humans combine multiple features weight map weights optimized minimize errors training data learning processes optimization problem objective function tied errors training data play video starting 812 follow transcript 812 different methods tend vary ways measuring errors training data optimize different objective function called loss function cost function play video starting 826 follow transcript 826 tend vary ways combining features linear combination example simple powerful nonlinear combinations nonlinear models complex training tradeoffs lead different variations play video starting 850 follow transcript 850 variations learning methods general distinguish two kinds classifiers high level called generative classifiers called discriminative classifiers generative classifiers try learn data looks category attempts model joint distribution data label x y factored product distribution labels joint probability sorry conditional probability x given y y model distribution labels model data generate particular label play video starting 948 follow transcript 948 estimate models compute conditional probability label given data based probability data given label play video starting 102 follow transcript 1002 label distribution bayes rule play video starting 107 follow transcript 1007 important thing conditional probability label directly decide label likely play video starting 1018 follow transcript 1018 approaches objective function actually likelihood model data generated indirectly captures training errors model data category accurately classify accurately play video starting 1038 follow transcript 1038 example naïve bayes classifier case approaches called discriminative classifies classifies try learn features separate categories direct attack problem categorization separation classes sorry problem play video starting 114 follow transcript 1104 discriminative classifiers attempt model conditional probability label given data point directly play video starting 1117 follow transcript 1117 objective function tends directly measure errors categorization training data play video starting 1124 follow transcript 1124 examples logistical regression support vector machines knearest neighbors cover classifiers detail lectures music
play video starting follow transcript 000 sound lecture generative probabilistic models text categorization play video starting 14 follow transcript 014 general two kinds approaches text categorization machine learning generating probabilistic models discriminative approaches lecture going talk generative models lecture going talk discriminative approaches problem text categorization actually similar document clustering assume document belongs category cluster main difference clustering dont know predefined categories clusters fact thats goal text clustering play video starting 55 follow transcript 055 find clusters data play video starting 59 follow transcript 059 case categorization given categories predefined categories based categories training data allocate document categories multiple categories similarity two problems actually document clustering models text categorization understand generated models text categorization perspective clustering slide weve talked text clustering assume multiple topics represented word distributions topic cluster estimated model faced problem deciding cluster document d belong question boils decide theta generate d play video starting 26 follow transcript 206 suppose d l words represented xi compute probability particular topic word distribution zeta generate document play video starting 227 follow transcript 227 general base wall make influence prior information consider topic cluster higher prior likely document cluster favor cluster likelihood part part play video starting 256 follow transcript 256 topic word distribution explain content document pick topic thats high values specifically multiply topic highest product rigorously wed going topic maximize posterior probability top given document gets posterior p prior thats belief topic likely observe document conditional probability posterior probability topic observed document d play video starting 349 follow transcript 349 base wall allows update probability based prior details prior related posterior lefthand side play video starting 45 follow transcript 405 related word distribution explains document two related way find topic higher posterior probability equivalent maximize product multiple times course play video starting 432 follow transcript 432 change probability document product probability word thats weve made assumption independence generating word document clustering play video starting 450 follow transcript 450 clearly assign document category based information word distributions categories prior categories idea directly adapted categorization precisely naive bayes classifier information looking categorization problem assume theta represents category accurately means word distribution characterizes content documents category accurately precisely did text clustering going assign document d category highest probability generating document words going maximize posterior probability play video starting 556 follow transcript 556 related prior inaudible previous slide naturally decompose inaudible product change notation write product product words vocabulary document doesnt contain words product accurately representing product words document count play video starting 637 follow transcript 637 word doesnt occur document count 0 time disappear actively product words document basically naive bayes classifier going score category document function play video starting 656 follow transcript 656 notice involves product lot small probabilities cause four problem way solve problem take logarithm function doesnt changes categories helps preserve precision function actually score category going category highest score function called naive bayes classifier keyword base understandable applying base rule posterior probability topic product likelihood prior play video starting 747 follow transcript 747 called naive weve made assumption word document generated independently naive assumption reality theyre generating independently word words likely occur example word text mixed category clustering likely appear text play video starting 815 follow transcript 815 assumption allows simplify problem actually effective text categorization tasks know model doesnt make assumption example assume words dependent make bigram analogy model trigram analogy model course mixture model model document looks category nature base rule classification actual generating model documents category vary talk simple case simplest case play video starting 9 follow transcript 900 question make sure theta actually represents category accurately clustering learned category distributions category data case make sure theta represents category play video starting 925 follow transcript 925 think question likely come idea training data play video starting 934 follow transcript 934 textbook typically assume training data available documents unknown generator category words documents known categories assigned course human experts t1 represents set documents known generator category 1 t2 represents documents known generated category 2 look picture youll model simplified unigram language model longer mixed modal know distribution generate documents theres uncertainty theres mixing different categories play video starting 1030 follow transcript 1030 estimation problem course simplified general imagine estimate probabilities marked probability estimate order relation two kinds prior probability theta indicates popular category likely observed document category water distributions know words high probabilities category play video starting 1111 follow transcript 1111 idea observe training data estimate two probabilities play video starting 1118 follow transcript 1118 general separately different categories thats documents known generated specific category know sense irrelevant categories dealing play video starting 1137 follow transcript 1137 statistical estimation problem observed data model guess parameters model take best guess parameters play video starting 1151 follow transcript 1151 problem times course havent thought problem havent life based classifier useful pause video moment think solve problem state problem lets think category 1 know word distribution generate documents generate word document independently know observed set n sub 1 documents set q1 documents generated category 1 generated word distribution question guess estimate probability word distribution guess entire probability category course singular probability depends likely documents categories play video starting 1255 follow transcript 1255 think moment training data documents known k categories estimate parameters spend time think help understand following slides spend time make sure try solve problem best solve problem thought realize following play video starting 1329 follow transcript 1329 whats bases estimating prior probability category observed lot documents form category intuitively lot documents sports medical science guess probability sports category larger prior category larger play video starting 1357 follow transcript 1357 basis estimating probability category youll assuming words observed frequently documents known generated category likely higher probability thats maximum naive bayes made thats made probability category answer question category popular simply normalize count documents category n sub denotes number documents category play video starting 1437 follow transcript 1437 simply normalize counts make probability words make probability proportional size training intercept category thats size set t sub play video starting 1455 follow transcript 1455 word distribution time category lets say considering category theta word higher probability simply count word occurrences documents known generated theta play video starting 1520 follow transcript 1520 put counts word set normalize counts make distribution words make probabilities words 1 case youre going proportional count word collection training documents t sub thats denoted c w t sub play video starting 1549 follow transcript 1549 notice write probable estimate form proportional numbers sufficient constraints distributions normalizer dictated constraint case useful think constraints two kinds probabilities figure answer question know normalize accounts good exercise work obvious issue naive bayes smoothing fact smoothing general problem older estimate language morals happen observed small amount data smoothing important technique address outsmarts case training data small data set small maximum likely estimator face problem zero probability means event observed estimated probability zero case word training documents lets say category estimator zero probability category generally accurate smoothing make sure zero probability reason smoothing way bring prior knowledge generally true lot situations smoothing data set small tend rely prior knowledge solve problem case inaudible says word zero probability smoothing allows inject prior initial order real zero probability play video starting 1754 follow transcript 1754 third reason obvious explain moment help achieve discriminative weighting terms called idf weighting inverse document frequency weighting mining word relations play video starting 1814 follow transcript 1814 smoothing general add pseudo counts events make sure event 0 count play video starting 1822 follow transcript 1822 possible way smoothing probability category simply add small non active constant delta count lets pretend category actually extra number documents represented delta play video starting 1840 follow transcript 1840 denominator add k multiplied delta probability 1 total weve added delta k times k categories sum add k multiply delta total pseudocount add estimate play video starting 196 follow transcript 1906 interesting think influence data obvious data smoothing parameter meaning larger data smoothing means rely pseudocounts ignore actual counts delta set infinity imagine happen approaches positively infinity going say category infinite amount documents theres distinction uniform play video starting 1944 follow transcript 1944 delta 0 back original estimate based observed training data estimate estimate probability category word distribution case find useful nonuniform seudocount word youll add pseudocounts word thats mule multiplied probability word given background language model theta sub b background model general estimated logic collection tests case set training data estimate background language model dont larger test data available play video starting 2036 follow transcript 2036 background language model pseudocounts find words receive pseudocounts words common words high probability background average model pseudocounts added words higher real words hand smaller pseudocounts addition background model cause nonuniform smoothing word distributions going bring probability common words higher level background model helps make difference probability words smaller categories category help background four words high probabilities important category documents contain lot occurrences words estimate influenced background model consequence categorization words tend influence decision words small probabilities background language model words dont help background language model difference primary differences occurrences training documents different categories play video starting 225 follow transcript 2205 smoothing parameter mu controls amount smoothing delta probability play video starting 2214 follow transcript 2214 easily understand add mu denominator represents sum pseudocounts add words play video starting 2225 follow transcript 2225 view non negative constant inaudible set control smoothing interesting special cases think lets think mu approaches infinity happen case estimate approach play video starting 2243 follow transcript 2243 background language model attempt background language model bring word distribution background language model essentially remove difference categories obviously dont special case thing background model suppose actually set two uniform distribution lets say 1 size vocabulary probability smoothing formula going similar top add delta going add constant pseudocounts word play video starting 2329 follow transcript 2329 general naive bayes categorization small thing probabilities compute score category document category highest score discussed earlier play video starting 2349 follow transcript 2349 useful understand naive bayes scoring function actually makes sense understand understand adding background model actually achieve effect idf weighting penalize common words suppose two categories going score based ratio probability right play video starting 2424 follow transcript 2424 lets say scoring function two categories right score document two categories going score based probability ratio ratio larger means likely category larger score likely document category bayes rule write ratio follows play video starting 259 follow transcript 2509 generally take logarithm ratio avoid small probabilities give formula second line interesting scoring function deciding two categories play video starting 2530 follow transcript 2530 look function parts part actually log probability ratio category bias play video starting 2541 follow transcript 2541 doesnt depend document says category likely favor category slightly right second part sum words right words observed document general consider words vocabulary going collect evidence category likely right sum product two things count word count word serves feature represent document play video starting 2627 follow transcript 2627 collect document second part weight feature weight word right weight tells extent observing word helps contribute decision put document category remember higher scoring function likely category look ratio basically sorry weight basically based ratio probability word two distributions essentially comparing probability word two distributions higher theta 1 theta 2 weight positive means observe word say likely category observe word likely document classified theta 1 play video starting 2735 follow transcript 2735 hand probability word theta 1 smaller probability word theta 2 word negative negative evidence supporting category means observe word likely document actually theta 2 play video starting 2758 follow transcript 2758 formula makes sense right going aggregate evidence document take sum words call features collected document help make decision feature weight tells play video starting 2819 follow transcript 2819 feature support category support category two estimated log probability ratio naïve bayes play video starting 2832 follow transcript 2832 finally constant bias formula actually formula generalized accommodate features thats introduce symbols introduce beta 0 denote bayes fi denote feature beta sub denote weight feature generalisation general represent document feature vector fi course case fi count word general put features think relevant categorization example document length font size count patterns document play video starting 2927 follow transcript 2927 scoring function defined sum constant beta 0 sum feature weights features play video starting 2942 follow transcript 2942 f sub feature value multiply value corresponding weight beta sub take sum aggregate evidence collect features course parameters parameters betas betas weights proper setting weights expect scoring function work classify documents case naive bayes clearly naive bayes classifier special case general classifier actually general form close classifier called logistical regression actually conditional approaches discriminative approaches classification play video starting 3032 follow transcript 3032 going talk approaches later note strong connection close connection two kinds approaches slide shows naive bayes classifier connected logistic regression discriminative classifiers tend general form bottom accommodate features solve problem music
practice quiz 10 practice quiz activity completed submit assignment resume assignment activity completed receive grade grade 100 view feedback keep highest score dislike report issue
quiz 10 quiz activity completed submit assignment due november 26 959 pm pst nov 26 959 pm pst try activity completed receive grade grade 100 view feedback keep highest score dislike report issue
play video starting follow transcript 000 sound lecture evaluation text categorization weve talked different methods text categorization know method works better play video starting 19 follow transcript 019 particular application know best way solving problem understand play video starting 29 follow transcript 029 know evaluate categorization results general thoughts evaluation play video starting 38 follow transcript 038 general evaluation empirical tasks categorization methodology developed 1960s information retrieval researchers called cranfield evaluation methodology basic idea humans create test correction play video starting 59 follow transcript 059 know document tagged desired categories case search query documents retrieved called ground truth ground truth test correction reuse collection test different systems compare different systems turn components system whats going happen basically provides way control experiments compare different methods play video starting 136 follow transcript 136 methodology virtually tasks involve empirically defined problems play video starting 145 follow transcript 145 case going compare systems categorization results categorization ground truth created humans play video starting 156 follow transcript 156 going compare systems decisions play video starting 2 follow transcript 200 documents category play video starting 26 follow transcript 206 categories assigned documents humans quantify similarity decisions equivalently measure difference system output desired ideal output generated humans play video starting 225 follow transcript 225 obviously highest similarity better results play video starting 230 follow transcript 230 similarity measured different ways lead different measures desirable match similarity different perspectives better understanding results detail example interested knowing category performs better category easy categorize general different categorization mistakes different costs specific applications areas serious ideally model differences read papers categorization dont generally simplified measure thats okay consider cost variation compare methods interested knowing relative difference methods okay introduce bias long bias particular method expect effective method perform better effective measure perfect play video starting 353 follow transcript 353 measure introduce called classification accuracy basic measure percentage correct decisions categories denoted c1 ck n documents denoted d1 d n pair category document look situation play video starting 416 follow transcript 416 system yes pair basically assigned category document denoted y m thats systems decision similarly look humans decisions human assigned category document plus sign means human think assignment correct incorrect minus combinations ns yes nos minus pluses four combinations total two correct thats y n two kinds errors measure classification accuracy simply count decisions correct normalize total number decisions made know total number decisions n multiplied k play video starting 520 follow transcript 520 number correct decisions basically two kinds y plusses n minus n put count convenient measure give number characterize performance method higher better course play video starting 541 follow transcript 541 method problems treated decisions equally reality decision errors serious example important decisions right documents play video starting 558 follow transcript 558 important decisions right categories call detailed evaluation results understand strands play video starting 612 follow transcript 612 different methods understand performance methods detail category document basis example shows clearly decision errors having different causes spam filtering retrieved two category categorization problem play video starting 636 follow transcript 636 missing legitimate email result type error letting spam come folder type error two types errors clearly different important miss legitimate email okay occasionally spam email come inbox error missing legitimate email high cost serious mistake classification error classification accuracy address issue play video starting 714 follow transcript 714 theres problem imbalance test set imagine theres skew test set instances category 98 instances category 2 category two case simple baseline accurately performs baseline sign similar put instances major category play video starting 736 follow transcript 736 98 accuracy case going appearing effective reality obviously good result play video starting 747 follow transcript 747 general classification accuracy measure ensure causes balance play video starting 754 follow transcript 754 equal number instances example class minority categories causes tend overlooked evaluation classification accuracy address problems course evaluate results ways different ways beneficial look multiple perspectives example look perspective document perspective based document question good decisions document play video starting 829 follow transcript 829 general cases decisions think four combinations possibilities depending system yes depending human correct incorrect yes four combinations human systems yes thats true positives system says yes positive system says yes positive human confirm correct true positive play video starting 97 follow transcript 907 system says yes human says thats incorrect thats false positive fp play video starting 915 follow transcript 915 system says human says yes false negative missed assignment system human says correctly assume thats true negatives right measures better characterize performance four numbers two popular measures precision recall proposed information retrieval researchers 1960s evaluating search results standard measures system says yes ask question correct whats percent correct decisions system says yes thats called precision true positive divided cases system says yes positives measure called recall measures play video starting 1014 follow transcript 1014 document categories case divide true positive true positives false negatives cases human says document category represents categories got recall tells system actually assigned categories document play video starting 1046 follow transcript 1046 gives detailed view document aggregate later play video starting 1052 follow transcript 1052 interested documents tell did documents subsets interesting example allows analyze errors detail separate documents characteristics look errors pattern document long document doesnt shock documents play video starting 1118 follow transcript 1118 gives insight inputting method similarly look percategory evaluation case going look good decisions particular category previous case define precision recall basically answer questions different perspective play video starting 1139 follow transcript 1139 system says yes correct means looking category documents assigned category category right recall tell category actually assigned documents category play video starting 12 follow transcript 1200 useful combine precision recall measure done f measure harmonic mean precision precision recall defined slide controlled parameter beta play video starting 1220 follow transcript 1220 indicate precision important recall beta set 1 measure called f1 case take equal weight procedure recall play video starting 1234 follow transcript 1234 f1 measure categorization play video starting 1239 follow transcript 1239 cases combine results think best way combining case dont know thought combined arithmetic mean right give range values obviously theres reason didnt f1 popular actually useful think difference think youll difference undesirable property arithmatic basically obvious think case system says yes category document pairs try compute precision recall case happen play video starting 1328 follow transcript 1328 basically measure arithmetic mean going reasonable f1 minus inaudible trade two values equal extreme case 0 letter f1 low mean reasonably high play video starting 141 follow transcript 1401 music
play video starting follow transcript 000 sound lecture continued discussion evaluation text categorization earlier introduced measures computer provision recall category document lecture going play video starting 27 follow transcript 027 examine combine performance different categories different documents aggregate take average title indicated called macro average contrast micro average talk later play video starting 47 follow transcript 047 category going compute precision require f1 example category c1 precision p1 recall r1 f value f1 similarly category 2 categories compute aggregate example aggregate precision values categories computing overall precision useful summarize data set aggregation done different ways case aggregate different values good think whats best way aggregation example consider arithmetic mean commonly geometric mean different behavior depending way aggregate got different conclusions terms method works better important consider differences choosing right suitable task difference fore example arithmetically geometrically arithmetically dominated high values geometrically affected low values base emphasis low values high values question relate similar recal f score thats generate overall precision recall f score play video starting 231 follow transcript 231 aggregation document right exactly situation document computer precision recall f completed computation documents going aggregate generate overall precision overall recall overall f score play video starting 253 follow transcript 253 examining results different angles ones useful depend application general beneficial look results perspectives especially compare different methods different dimensions reveal method better measure situations provides insightful understanding strands method weakness provides insight improving play video starting 328 follow transcript 328 mentioned microaverage contrast macro average talked earlier case pool decisions compute precision recall play video starting 345 follow transcript 345 compute overall precision recall counting cases true positive cases false positive computing values contingency table compute precision recall play video starting 46 follow transcript 406 contrast macroaveraging going category aggregate categories document aggregate documents pooled play video starting 421 follow transcript 421 similar classification accuracy earlier problem course treat instances decisions equally play video starting 432 follow transcript 432 desirable play video starting 436 follow transcript 436 property applications especially associate example cost combination actually compute example weighted classification accuracy associate different cost utility specific decision play video starting 456 follow transcript 456 variations methods useful general macro average tends information micro average reflect understanding performance play video starting 514 follow transcript 514 category performance document needed applications macro averaging micro averaging common reported research papers categorization categorization results actually evaluated ranking prospective play video starting 540 follow transcript 540 categorization results passed human various purposes example passed humans editing example news articles tempted categorized system human editors correct play video starting 62 follow transcript 602 email messages right person handling help desk case categorizations help prioritizing task particular customer service person play video starting 619 follow transcript 619 case results prioritized play video starting 626 follow transcript 626 system cant give score categorization decision confidence scores rank decisions evaluate results rank list search engine evaluation rank documents responsible query play video starting 649 follow transcript 649 example discovery spam emails evaluated play video starting 655 follow transcript 655 based ranking emails spam category useful people verify spam right person take rank check verify spam reflect utility humans task better evaluate ranking chris basically similar search play video starting 725 follow transcript 725 case problem better formulated ranking problem categorization problem example ranking documents search engine framed binary categorization problem distinguish relevant documents useful users useful typically frame ranking problem evaluate rank list thats people tend examine results play video starting 752 follow transcript 752 ranking evaluation reflects utility users perspective play video starting 758 follow transcript 758 summarize categorization evaluation evaluation important tasks right play video starting 87 follow transcript 807 dont right misleading results misled believe method better fact true important right play video starting 818 follow transcript 818 measures reflect intended results particular application example spam filtering news categorization results different ways play video starting 830 follow transcript 830 consider difference design measures appropriately play video starting 836 follow transcript 836 generally consider results processed user think users perspective quality important aspect quality important play video starting 849 follow transcript 849 trade offs multiple aspects precision recall know application high recall important high precision important play video starting 859 follow transcript 859 ideally associate different cost different decision arrow course designed application specific way play video starting 98 follow transcript 908 commonly measures relative comparison methods following classification accuracy commonly especially balance inaudible preceding inaudible scores common report characterizing performances given angles give inaudible inaudible document basis inaudible take average different ways micro versus macro inaudible general look results multiple perspectives particular applications perspectives important diagnoses analysis categorization methods generally useful look perspectives possible subtle differences methods tow method weak obtain sight improving method play video starting 104 follow transcript 1004 finally ranking appropriate careful categorization got better frame ranking tasks therere machine running methods optimizing ranking measures play video starting 1017 follow transcript 1017 two suggested readings chapters book find discussion evaluation measures second paper comparison different approaches text categorization excellent discussion evaluate textual categorization music
play video starting follow transcript 000 sound lecture opinion mining sentiment analysis covering motivation lecture going start talking mining different knowledge knowledge observer humans generated text data particular going talk opinion mining sentiment analysis play video starting 32 follow transcript 032 discussed earlier text data regarded data generated humans subjective sensors play video starting 43 follow transcript 043 contrast devices video recorder report whats happening real world objective generate viewer data example play video starting 58 follow transcript 058 main difference test data data video data rich opinions content tends subjective generated humans play video starting 116 follow transcript 116 actually unique advantaged text data compared data office great opportunity understand observers mine text data understand opinions understand peoples preferences people think play video starting 137 follow transcript 137 lecture following lectures mainly mine analyze opinions buried lot text data play video starting 149 follow transcript 149 lets start concept opinion easy formally define opinion define opinion subjective statement describing person believes thinks play video starting 28 follow transcript 208 highlighted words thats worth thinking bit words help better understand whats opinion helps define opinion formally needed computation resolve problem opinion mining lets look key word subjective contrast objective statement factual statement play video starting 240 follow transcript 240 statements proved right wrong play video starting 245 follow transcript 245 key differentiating factor opinions tends easy prove wrong right reflects person thinks play video starting 259 follow transcript 259 contrast objective statement usually proved wrong correct play video starting 37 follow transcript 307 example say computer screen battery play video starting 316 follow transcript 316 thats check having battery play video starting 323 follow transcript 323 contrast think sentence laptop best battery laptop nice screen statements subjective hard prove wrong correct play video starting 345 follow transcript 345 opinion subjective statement play video starting 350 follow transcript 350 lets look keyword person indicates opinion holder talk opinion opinion held notice target opinion opinion expressed play video starting 411 follow transcript 411 course believes thinks implies opinion depend culture background context general person think different different context people different background think different ways analysis shows multiple elements order characterize opinion play video starting 438 follow transcript 438 whats basic opinion representation least three elements right firstly specify whats opinion holder opinion second specify target whats opinion play video starting 457 follow transcript 457 third course opinion content exactly opinion identify basic understanding opinion useful understand enriched opinion representation play video starting 515 follow transcript 515 means understand example context opinion situation opinion expressed example time expressed people understand opinion sentiment understand opinion tells opinion holders feeling example opinion positive negative opinion holder happy sad understanding obvious extracting opinion content needs analysis play video starting 6 follow transcript 600 lets take simple example product review case actually expressed opinion holder expressed target obviously whats opinion holder thats reviewer clear whats opinion target thats product review example iphone 6 review posted usually cant information easier play video starting 627 follow transcript 627 content course review text thats general easy obtain product reviews fairly easy analyze terms obtaining basic opinion representation course information know context example review written 2015 know sentiment review positive additional understanding course adds value mining opinions play video starting 74 follow transcript 704 case task relatively easy thats opinion holder opinion target identified play video starting 714 follow transcript 714 lets take look sentence news case implicit holder implicit target tasker general harder identify opinion holder thats governor connecticut play video starting 732 follow transcript 732 identify target target hurricane sandy target mentioned hurricane 1938 whats opinion theres negative sentiment thats indicated words bad play video starting 753 follow transcript 753 identify context new england case play video starting 8 follow transcript 800 playoff review elements extracted natural ram processing techniques task harder deeper natural language processing play video starting 814 follow transcript 814 examples play video starting 817 follow transcript 817 suggest lot work easy done product reviews thats happened analyzing assembling news difficult difficult analysis opinions product reviews play video starting 836 follow transcript 836 interesting variations fact going examine variations opinions systematically lets think opinion holder play video starting 847 follow transcript 847 holder individual group people opinion committee country people play video starting 856 follow transcript 856 opinion target accounts vary lot entity particular person particular product particular policy ect group products products company general play video starting 911 follow transcript 911 specific attribute attribute entity example battery iphone elses opinion person comment persons opinion lot variation cause problem vary lot opinion content course vary lot surface identify onesentence opinion onephrase opinion longer text express opinion article play video starting 948 follow transcript 948 identify variation sentiment emotion damage thats feeding opinion holder distinguish positive versus negative mutual happy versus sad separate play video starting 103 follow transcript 1003 finally opinion context vary simple context different time different locations complex contexts background topic discussed opinion expressed particular discourse context interpreted different ways expressed context context inaudible entire discourse context opinion computational perspective interested opinions extracted text data turns differentiate distinguish different kinds opinions text data computation perspective observer make comment opinion targeting observe word case authors opinion example dont phone thats opinion author play video starting 1059 follow transcript 1059 contrast text report opinions person make observation persons opinion reported opinion example believe loves painting opinion expressed person doesnt mean author loves painting play video starting 1133 follow transcript 1133 clearly two kinds opinions analyzed different ways product reviews opinions false reviewer reviewer mention opinions friend friend play video starting 1151 follow transcript 1151 complication indirect opinions inferred opinions obtained making inferences whats expressed text necessarily look opinion example statement phone ran battery hour way factual statement true false right verify statement infer negative opinions quality battery phone feeling opinion holder battery opinion holder clearly wished battery longer play video starting 1242 follow transcript 1242 interesting variations pay attention extract opinions reason indirect opinions play video starting 1253 follow transcript 1253 useful extract person product factual sentences useful practical viewpoint dont necessarily extract subject sentences sentences opinions useful understanding person understanding product commend play video starting 1319 follow transcript 1319 task opinion mining defined taking textualized input generate set opinion representations representation identify opinion holder target content context ideally infer opinion sentiment comment context better understand play video starting 1343 follow transcript 1343 opinion play video starting 1344 follow transcript 1344 elements representation known gave good example case product wed opinion holder opinion target expressly identified thats turns simplest opinion mining tasks interesting think tasks simple cases easily build applications opinion mining techniques play video starting 1417 follow transcript 1417 talked opinion mining defined task lets talk bit opinion mining important useful identify three major reasons three broad reasons help decision support help optimize decisions look peoples opinions look read reviews order make decisions buying product service play video starting 1452 follow transcript 1452 interested opinions decide vote example play video starting 15 follow transcript 1500 policy makers know peoples opinions designing new policy thats general applications broad course second application understand people important example help understand peoples preferences help better serve people example optimize product search engine optimize recommender system know people interested people think product play video starting 1535 follow transcript 1535 help advertising course targeted advertising know people tend plot play video starting 1548 follow transcript 1548 third application called voluntary survey important research done surveys manual surveys question answer people feel informs answer questions directly related humans sensors usually aggregate opinions lot humans assess general opinion useful business intelligence manufacturers know products advantages play video starting 1631 follow transcript 1631 winning features products winning features competitive products play video starting 1637 follow transcript 1637 market research understanding consumers oppinions create useful directive datadriven social science research benefit text mining understand peoples opinions aggregate lot opinions social media lot popular play video starting 1658 follow transcript 1658 information actually study questions example study behavior people social media social networks regarded voluntary survey done people play video starting 1719 follow transcript 1719 general gain lot advantage prediction task leverage text data extra data problem text based prediction techniques help make predictions improve accuracy prediction music
play video starting follow transcript 000 noise lecture sentiment classification play video starting 11 follow transcript 011 assume play video starting 13 follow transcript 013 elements opinion representation ready known task sentiment classification case suppose know whos opinion holder whats opinion target know content context opinion mainly decide opinion sentiment review case sentiment classification understanding opinion play video starting 46 follow transcript 046 sentiment classification defined specifically follows input opinionated text object output typically sentiment label sentiment tag designed two ways polarity analysis categories positive negative neutral play video starting 18 follow transcript 108 emotion analysis polarity characterize feeling opinion holder play video starting 121 follow transcript 121 case polarity analysis numerical ratings reviews web play video starting 130 follow transcript 130 five denote positive negative example general disk holder categories characterize sentiment play video starting 143 follow transcript 143 emotion analysis course different ways design categories play video starting 149 follow transcript 149 six frequently categories happy sad fearful angry surprised disgusted play video starting 159 follow transcript 159 task essentially classification task categorization task weve special case text categorization means textual categorization method sentiment classification play video starting 215 follow transcript 215 course accuracy good sentiment classification requires improvement regular text categorization technique simple text categorization technique particular needs two improvements sophisticated features appropriate sentiment tagging discuss moment play video starting 241 follow transcript 241 consider order categories especially polarity analysis clear theres order categories independent theres order useful consider order example ordinal regression thats talk later lets talk features useful text categorization text mining general especially needed sentiment analysis play video starting 318 follow transcript 318 lets start simplest character ngrams sequence characters unit mixed different ns different lengths right general way robust way represent text data language pretty play video starting 342 follow transcript 342 robust spelling errors recognition errors right misspell word character representation actually allow match word occurs text correctly right misspell word correct form matched contain common ngrams characters course recommendation discriminating words play video starting 410 follow transcript 410 word ngrams sequence words mix different ns unigrams actually effective lot text processing tasks words word designed features humans communication good tasks good sufficient sentiment analysis clearly example sentence good good right case take good suggest positive thats good right accurate take bigram good accurate longer ngrams generally discriminative theyre specific match says lot accurate unlikely ambiguous cause overfitting unique features machine oriented program easily pick features training set rely unique features distinguish categories obviously classify generalize word future discriminative features necessarily occur thats problem overfitting thats desirable consider part speech tag ngrams part speech tagging example adjective noun form pair mix ngrams words ngrams part speech tags example word great followed noun feature hybrid feature useful sentiment analysis play video starting 66 follow transcript 606 word classes classes syntactic part speech tags semantic represent concepts thesaurus ontology wordnet recognized name entities people place categories enrich presentation additional features learn word clusters parodically example weve talked mining associations words cluster paradigmatically related words syntaxmatically related words clusters features supplement word base representation frequent pattern syntax frequent word set words form pattern necessarily occur locations words occur closely patterns discriminative features words obviously play video starting 714 follow transcript 714 generalize better regular ngrams frequent expected occur tested data lot advantages face problem overfeeding features complex problem general true parse treebased features parse tree derive features frequent subtrees paths discriminating theyre likely cause fitting general pattern discovery algorithms useful feature construction allow search large space possible features complex words useful general natural language processing important derive complex features enrich text representation example simple sentence showed long time ago lecture words derive simple word ngrams representations character ngrams nlp enrich representation lot information part speech tags parse trees entities speech act enriching information course generate lot features complex features mixed grams word part speech tags part parse tree play video starting 855 follow transcript 855 general feature design actually affects categorization accuracy significantly important part machine learning application general think effective combine machine learning error analysis domain knowledge design features main knowledge understanding problem design seed features define basic feature space lot possible features machine learning program work machine applied select effective features construct new features thats feature learning features analyzed humans error analysis look categorization errors analyze features help recover errors features cause overfitting cause errors lead feature validation revised feature set iterate consider different features space play video starting 107 follow transcript 1007 nlp enriches text recognition enriches feature space allows larger space features features useful lot tasks careful lot category features cause overfitting training careful overflow happen main challenge design features common challenge optimize trade exhaustivity specificity trade turns difficult exhaustivity means features actually high coverage lot documents sense features frequent specifity requires feature discriminative naturally infrequent features tend discriminative cause trade frequent versus infrequent features thats featured design usually odd thats probably important part machine learning problem particularly case text categoration specifically senitment classification music
play video starting follow transcript 000 noise lecture ordinal logistic regression sentiment analysis problem set typical sentiment classification problem specifically rating prediction opinionated text document d input generate output rating range 1 k discrete rating categorization problem k categories regular text categorization technique solve problem solution consider order dependency categories intuitively features distinguish category 2 1 rating 2 1 similar distinguish k k1 example positive words generally suggest higher rating train categorization problem treating categories independent capture play video starting 117 follow transcript 117 whats solution general order classify different approaches going talk called ordinal logistic regression lets think logistical regression binary sentiment categorization problem suppose wanted distinguish positive negative two category categorization problem predictors represented x features m features feature value real number representation text document play video starting 156 follow transcript 156 two values binary response variable 0 1 1 means x positive 0 means x negative course standard two category categorization problem apply logistical regression recall logistical regression assume log probability y equal assumed linear function features allow write probability y equals given x play video starting 236 follow transcript 236 equation bottom play video starting 243 follow transcript 243 thats logistical function relates probability probability y1 feature values course beta parameters direct application logistical regression binary categorization play video starting 38 follow transcript 308 multiple categories multiple levels binary logistical regression problem solve multi level rating prediction play video starting 321 follow transcript 321 idea introduce multiple binary class files case asked class file predict rating j ratings lower j yj equal 1 means rating j 0 means rating lower j play video starting 345 follow transcript 345 basically predict rating range 1k classifier distinguish k versus thats classifier going classifier distinguish k1 rest thats classifier 2 end classifier distinguish 2 1 altogether k1 classifiers play video starting 417 follow transcript 417 course solve problem logistical regression program straight previous slide parameters classifier different set parameters logistical regression classifies index j corresponds rating level play video starting 446 follow transcript 446 j replace beta 0 make notation consistent show ordinal logistical regression basically k minus regular logistic regression classifiers set parameters approach ratings follows play video starting 519 follow transcript 519 trained k1 logistic regression classifiers separately course take new instance invoke classifier sequentially make decision look classifier corresponds level rating k classifier tell object rating k probability logistical regression classifier larger point five going say yes rating k play video starting 62 follow transcript 602 large twentyfive means ratings k right play video starting 611 follow transcript 611 invoke classifier tells k minus play video starting 618 follow transcript 618 least k minus probability larger twentyfive say k1 says means rating k1 going keep invoking classifiers hit end decide two help solve problem right classifier actually give prediction rating range 1 k unfortunately strategy optimal way solving problem specifically two problems approach equations play video starting 76 follow transcript 706 problem parameters parameters count parameters exactly interesting exercise pause video try figure solution parameters classifier play video starting 728 follow transcript 728 classifiers play video starting 731 follow transcript 731 classifier n plus parameters k minus classifiers total number parameters k minus multiplied n plus thats lot lot parameters classifier lot parameters general lot data actually help training data help decide optimal parameters complex model play video starting 84 follow transcript 804 thats ideal play video starting 87 follow transcript 807 second problems problems k minus 1 plus fives independent problems actually dependent play video starting 818 follow transcript 818 general words positive make rating higher play video starting 825 follow transcript 825 classifiers classifiers able take advantage fact play video starting 833 follow transcript 833 idea ordinal logistical regression precisely key idea improvement k1 independent logistical regression classifiers idea tie beta parameters means going assume beta parameters parameters indicated inference weights going assume beta values k 1 parameters encodes intuition positive words general make higher rating likely play video starting 919 follow transcript 919 intuitively assumptions reasonable problem setup order categories play video starting 928 follow transcript 928 fact allow two positive benefits going reduce number families significantly play video starting 938 follow transcript 938 allow share training data parameters similar equal training data different classifiers shared help set optimal value beta play video starting 956 follow transcript 956 data help good beta value play video starting 101 follow transcript 1001 whats consequence formula look similar beta parameter index corresponds feature longer index corresponds level rating play video starting 1019 follow transcript 1019 means tie theres set better values classifiers classifier distinct r value r parameter different course needed predict different levels ratings r sub j different depends j different j different r value rest parameters beta ask question parameters thats interesting question think think moment param fewer parameters specifically m plus k minus m beta values plus k minus values play video starting 1115 follow transcript 1115 lets look basically thats basically main idea ordinal logistical regression play video starting 1124 follow transcript 1124 lets method actually assign ratings turns idea tying parameters beta values end having similar way make decisions specifically criteria predictor probabilities least 05 equivalent score object larger equal negative authors j scoring function taking linear combination features divided beta values play video starting 1215 follow transcript 1215 means simply make decision rating looking value scoring function bracket falls general decision rule score particular range values assign corresponding rating text object play video starting 1249 follow transcript 1249 approach going score object play video starting 1255 follow transcript 1255 features trained parameter values play video starting 13 follow transcript 1300 score compared set trained alpha values range score range decide rating object getting ranges alpha values correspond different levels ratings thats way train alpha values tied level rating music
play video starting 1 follow transcript 001 music lecture latent aspect rating analysis opinion mining sentiment analysis play video starting 14 follow transcript 014 lecture going continue discussing opinion mining sentiment analysis play video starting 19 follow transcript 019 particular going introduce latent aspect rating analysis allows perform detailed analysis reviews overall ratings play video starting 34 follow transcript 034 motivation play video starting 37 follow transcript 037 two reviews net hotel overall ratings case reviewers given five stars course reviews text play video starting 53 follow transcript 053 look reviews clear hotel good location service unclear reviewer liked hotel play video starting 16 follow transcript 106 decompose overall rating ratings different aspects value rooms location service play video starting 118 follow transcript 118 decompose overall ratings ratings different aspects obtain detailed understanding reviewers opinionsabout hotel play video starting 130 follow transcript 130 allow rank hotels different dimensions value rooms general detailed understanding reveal information users preferences reviewers preferences understand better reviewers view hotel different perspectives infer aspect ratings infer aspect weights reviewers care values opposed service case whats left weight distribution lot weight places value play video starting 218 follow transcript 218 care service place weight service value play video starting 225 follow transcript 225 reason important think five star value expensive reviewer cares lot service right service price good reviewer give five star reviewer cares value hotel five star likely mean cheap prices order interpret ratings different aspects accurately know aspect weights theyre combined detailed understanding opinion task reviews overall ratings input generate aspect ratings compose aspect ratings aspect rates output problem called latent aspect rating analysis play video starting 331 follow transcript 331 task general given set review articles topic overall ratings hope generate three things major aspects commented reviews second ratings aspect value room service play video starting 353 follow transcript 353 third relative weights placed different aspects reviewers task lot applications enable lot applications listed later show results example opinion based entity ranking generate aspectlevel opinion summary analyze reviewers preferences compare compare preferences different hotels personalized recommendations products play video starting 429 follow transcript 429 course question solve problem cases advanced topics won’t time cover technique detail i’m going give brisk basic introduction technique development problem step we’re going talk solve problem two stages later we’re going mention unified model take review overall rating input going segment aspects going pick words talking location words talking room condition play video starting 513 follow transcript 513 able obtain aspect segments particular going obtain counts words segment denoted c sub w d done seed words location room price retrieve inaudible segments segments mine correlated words seed words allow segmented text segments discussing different aspects course later inaudible models segmentation thats stage obtain council words segment second stage called latent rating regression going words frequencies different aspects predict overall rate predicting happens two stages play video starting 617 follow transcript 617 stage going inaudible weights words aspect predict aspect rating example discussion location word amazing mentioned times high weight example 39 increase aspect rating location word acted weight mentioned times decrease rating aspect ratings assume weighted combination word frequencies weights sentiment weights words course sentimental weights different different aspects aspect set term sentiment weights thats order beta sub w play video starting 718 follow transcript 718 second stage second step going assume overall rating simply weighted combination aspect ratings going assume aspect weights inaudible sub d take weighted average aspect ratings denoted r sub d play video starting 742 follow transcript 742 going assume overall rating simply weighted average aspect ratings set allows predict overall rating based observable frequencies left side observed information r sub d count play video starting 83 follow transcript 803 right side information range actually latent play video starting 89 follow transcript 809 hope discover typical case generating model embed interesting variables generated model going set generation probability overall rating given observed words course adjust parameter values betas rs alpha order maximize probability data case conditional probability observed rating given document cases example pisa predict text data predicting rating parameters course different uncover parameters nice r sub d precise ratings composer ratings different aspects inaudible sub d precisely aspect weights hope byproduct beta factor inaudible factor sentiment weights words play video starting 931 follow transcript 931 formally play video starting 933 follow transcript 933 data modeling set review documents overall ratings review document denote d overall ratings denote r sub d d presegments turn k aspect segments going ciwd denote count word w aspect segment course zero word doesnt occur segment play video starting 101 follow transcript 1001 model going predict rating based d interested provisional problem r subd given d model set follows r subd assumed two follow normal distribution doesnt mean denotes actually await average aspect ratings r sub d normal distribution variance data squared course assumption actual rating necessarily thing way make assumption formal way model problem allows compute interest quantities case aspect ratings aspect weights play video starting 1052 follow transcript 1052 aspect rating inaudible assuming weight sum weights weight inaudible weight play video starting 114 follow transcript 1104 overall rating assumed weighted average aspect ratings play video starting 1115 follow transcript 1115 values r sub d denoted vector depends d token specific weights we’re going assume vector drawn multivariate gaussian distribution mean denoted mu factor covariance metrics sigma play video starting 1143 follow transcript 1143 means generate overall rating going draw play video starting 1149 follow transcript 1149 set values multivariate gaussian prior distribution values going weighted average aspect ratings mean normal distribution generate overall rating play video starting 1213 follow transcript 1213 aspect rating sum sentiment weights words aspect note sentiment weights specific aspect beta indexed thats aspect gives way model different segment word play video starting 1236 follow transcript 1236 word positive sentiment aspect parameters beta sub w gives aspectspecific sentiment w obviously thats important parameters general parameters beta values delta mu sigma play video starting 1312 follow transcript 1312 question estimate parameters collectively denote parameters lambda usual maximum likelihood estimate give settings parameters maximized observed ratings condition respective reviews course give useful variables interested computing play video starting 1345 follow transcript 1345 specifically estimate parameters easily compute aspect rating aspect sub d thats simply take words occurred segment take counts multiply center weight word take sum course time zero words occurring thats going take sum words vocabulary play video starting 1417 follow transcript 1417 s factor weights alpha sub d part parameter right compute case maximum posteriori compute alpha value basically going maximize product prior alpha assumed multivariate gaussian distribution likelihood case likelihood rate probability generating observed overall rating given particular alpha value parameters details model read paper cited play video starting 155 follow transcript 1505 music
play video starting follow transcript 000 sound lecture continued discussion latent aspect rating analysis earlier talked solve problem lara two stages segmentation different aspects latent regression model learn aspect ratings later weight possible develop unified generative model solving problem model generational overrating based text model generation text natural solution topic model given entity assume aspects described word distributions topics topic model model generation reviewed text play video starting 11 follow transcript 101 assume words review text drawn distributions play video starting 18 follow transcript 108 way assumed generating model prsa play video starting 113 follow transcript 113 plug latent regression model text predict overrating means predict aspect rating combine aspect weights predict overall rating give unified generated model model generation text overall ready condition text play video starting 140 follow transcript 140 dont time discuss model detail cases part cause discuss cutting edge topics theres reference site find details play video starting 157 follow transcript 157 im going show simple results generated models rating decomposition decomposed ratings three hotels overall rating look overall rating cant tell difference hotels decomposing ratings aspect ratings hotels higher ratings dimensions value score better dimensions location give detailed opinions aspect level play video starting 238 follow transcript 238 groundtruth parenthesis allows prediction accurate accurate reflecting trends play video starting 253 follow transcript 253 second result compare different reviewers hotel table shows decomposed ratings two reviewers hotel high level overall ratings look overall ratings dont information difference two reviewers decompose ratings clearly high scores different dimensions shows model review differences opinions different reviewers detailed understanding help understand better reviewers better feedback hotel interesting sense byproduct problem formulation did design generating model component sentimental weights words different aspects highly weighted words versus negatively loaded weighted words four dimensions value rooms location cleanliness top words clearly make sense bottom words make sense play video starting 410 follow transcript 410 shows approach learn sentiment information directly data lexicon useful general word long lets say different sentiment polarities different context say battery life laptop long thats positive say rebooting time laptop long thats bad right reviews product laptop word long ambiguous mean positive mean negative lexicon learn generated models show word positive particular aspect clearly useful fact lexicon directly tag reviews hotels tag comments hotels social media tweets play video starting 58 follow transcript 508 whats interesting completely unsupervised assuming reviews overall rating available allow learn form potentially larger amount data internet reach sentiment lexicon play video starting 528 follow transcript 528 results validate preference words remember model infer wether reviewer cares service price know inferred weights correct poses difficult challenge evaluation show interesting way evaluating play video starting 550 follow transcript 550 prices hotels different cities prices hotels favored different groups reviewers top ten reviewers highest inferred value aspect ratio play video starting 69 follow transcript 609 example value versus location value versus room etcetera top ten reviewers highest ratios measure means reviewers tend put lot weight value compared dimensions means emphasize value play video starting 630 follow transcript 630 bottom ten hand reviewers lowest ratio mean means reviewers put higher weights aspects value people cared dimension didnt care value sense least compared top ten group play video starting 652 follow transcript 652 ratios computer based inferred weights model play video starting 657 follow transcript 657 average prices hotels favored top ten reviewers cheaper favored bottom ten provides indirect way validating inferred weights means weights random actually meaningful comparison average price three cities actually top ten tend average price bottom half care lot things service room condition tend hotels higher prices average results build lot interesting applications example direct application generate rated aspect summary decomposition generated summaries aspect positive sentences negative sentences aspect informative original review overall rating review text results aspects thats covered reviews ratings mp3 reviews results show model discover interesting aspects commented low overall ratings versus higher overall ratings care different aspects play video starting 822 follow transcript 822 comment different aspects help discover example consumers trend appreciating different features products example discovered trend people tend larger screens cell phones light weight laptop etcetera knowledge useful manufacturers design generation products interesting results analyzing users rating behavior average weights different dimensions different groups reviewers left side weights viewers expensive hotels gave expensive hotels 5 stars average rates tend service suggests people expensive hotels good service thats surprising thats way validate inferred weights play video starting 934 follow transcript 934 look right side look column 5 stars reviewers cheaper hotels gave cheaper hotels five stars expected put weight value thats cheaper hotels play video starting 952 follow transcript 952 look didnt expensive hotels cheaper hotels youll tended weights condition room cleanness play video starting 104 follow transcript 1004 shows model infer information thats hard obtain read reviews read reviews hard infer preferences emphasis case text mining algorithms humans review interesting patterns data course useful compare different hotels compare opinions different consumer groups different locations course model general applied reviews overall ratings useful technique support lot text mining applications play video starting 1050 follow transcript 1050 finally results applying model personalized ranking recommendation entities play video starting 1057 follow transcript 1057 infer reviewers weights different dimensions allow user actually say care example query shows 90 weight value 10 means dont care aspect care getting cheaper hotel emphasis value dimension query reviewers believe similar preference recommend hotels know infer weights reviewers different aspects find reviewers weights precise course inferred rates similar reviewers recommend hotels call personalized query specific recommendations nonpersonalized recommendations top top results generally higher price lower group thats reviewers cared value dictated query tended favor low price hotels application technique play video starting 1218 follow transcript 1218 shows text mining understand users better handle users better solve users better summarize discussion opinion mining general important topic lot applications play video starting 1233 follow transcript 1233 text sentiment analysis readily done text categorization standard technique tends enriched feature implementation play video starting 1245 follow transcript 1245 consider order categories talk ordinal regression problem assume generating models powerful mining latent user preferences particular generative model mining latent regression embed interesting preference information send weights words model result learn useful information fitting model data approaches proposed evaluated product reviews context opinion holder opinion target clear easy analyze course lot practical applications opinion mining news social media important thats difficult analyzing review data mainly opinion holders opinion targets interested calls natural management processing techniques uncover accurately play video starting 1350 follow transcript 1350 suggested readings two small books topic find lot discussion variations problem techniques proposed solving problem play video starting 148 follow transcript 1408 two papers generating models rating aspect rating analysis solving problem two stages second unified model topic model integrated regression model solve problem unified model play video starting 1430 follow transcript 1430 music
play video starting follow transcript 000 sound lecture textbased prediction lecture going start talking mining different knowledge slide going text data infer values variables real world directly related text remotely related text data different content analysis topic mining directly characterize content text different opinion mining sentiment analysis characterizing content focus subject content reflects know opinion holder play video starting 15 follow transcript 105 provides limited review predict play video starting 110 follow transcript 110 lecture following lectures going talk predict information world sophisticated patterns text data play video starting 128 follow transcript 128 useful take look big picture prediction data mining general call data mining loop picture right multiple sensors human sensors report real world form data course data form nontext data text data play video starting 151 follow transcript 151 goal predict values important real world variables matter example someones house condition weather variables important act make decisions based data predicted values general data mining analysis data play video starting 223 follow transcript 223 general treat data collected play video starting 230 follow transcript 230 prediction problem set interested joint mining nontext text data combine data play video starting 241 follow transcript 241 analysis generally multiple predictors interesting variable call features features put predictive model actually predict value interesting variable play video starting 32 follow transcript 302 allows change world basically general process making prediction based data test data play video starting 317 follow transcript 317 important emphasize human actually plays important role process play video starting 324 follow transcript 324 especially involvement text data human involved mining data control generation features help understand text data text data created consumed humans humans best consuming interpreting text data play video starting 348 follow transcript 348 course lot text data machines help thats text data mining play video starting 355 follow transcript 355 machines patterns lot data humans general human play important role analyzing text data applications human involved predictive model building adjusting testing particular lot domain knowledge problem prediction build predictive model course predictive values variables humans involved taking actions change word make decisions based particular values play video starting 436 follow transcript 436 finally interesting human involved controlling sensors play video starting 443 follow transcript 443 adjust sensors collect useful data prediction play video starting 452 follow transcript 452 thats call data mining loop perturb sensors itll collect new data useful data obtain data prediction data generally help improve predicting accuracy loop humans recognize additional data collected machines course help humans identify data collected general collect data useful learning actually subarea machine learning called active learning identify data play video starting 532 follow transcript 532 points helpful machine learning programs label right play video starting 538 follow transcript 538 general loop data acquisition data analysis data mining prediction values take actions change word observe happens decide additional data collected adjusting sensors prediction arrows note additional data acquire order improve accuracy prediction big picture actually general reflecting lot important applications big data play video starting 616 follow transcript 616 useful keep mind looking text mining techniques play video starting 622 follow transcript 622 text mining perspective interested text based prediction course texts make predictions useful prediction human behavior human preferences opinions general text data put nontext data interesting questions design effective predictors generate effective predictors text play video starting 653 follow transcript 653 question addressed extent previous lectures talked features design text data addressed extent talking knowledge mine text example topic mining useful generate patterns topic based indicators predictors fed predictive model topics intermediate recognition text allow design high level features predictors useful prediction variable generated original text data provides better implementation problem serves effective predictors play video starting 746 follow transcript 746 similarly similar analysis lead predictors data mining text mining algorithms generate predictors play video starting 758 follow transcript 758 question join mine text nontext data question addressed lecture following lectures going address problem generate enriched features prediction allows review lot interesting knowledge world patterns generated text nontext data useful prediction put predictors help improving prediction play video starting 839 follow transcript 839 basically textbased prediction actually serve unified framework combine text mining analysis techniques topic mining content mining techniques segment analysis play video starting 855 follow transcript 855 goal mainly evoke values realworld variables order achieve goal preparations subtasks subtask mine content text data topic mining mine knowledge observer sentiment analysis opinion play video starting 921 follow transcript 921 help predictors prediction problem play video starting 927 follow transcript 927 course add nontext data directly predicted model nontext data helps context text analyst improves topic mining opinion analysis improvement leads effective predictors problems enlarge space patterns opinions topics mine text discuss later joint analysis text nontext data actually understood two perspectives play video starting 105 follow transcript 1005 perspective nontext help testimony play video starting 1011 follow transcript 1011 nontext data context mining text data way partition data different ways leads number type techniques contextual types mining thats mine text context defined nontext data reference large body work direction highlight lectures play video starting 1039 follow transcript 1039 perspective text data help nontext data mining text data help interpret patterns discovered nontext data lets say discover frequent patterns nontext data text data associated instances pattern occurs text data associated instances pattern doesnt look gives two sets text data whats difference difference text data interpretable text content easy digest difference suggest meaning pattern found nontext data helps interpret patterns technique called pattern annotation play video starting 1132 follow transcript 1132 reference listed detail play video starting 1138 follow transcript 1138 references mentioned reference pattern annotation second qiaozhu meis dissertation contextual text mining contains large body work contextual text mining techniques play video starting 1156 follow transcript 1156 music
play video starting follow transcript 000 sound lecture contextual text mining play video starting 11 follow transcript 011 contextual text mining related multiple kinds knowledge mine text data im showing related topic mining make topics associated context time location similarly make opinion mining contextualized making opinions connected context play video starting 34 follow transcript 034 related text based prediction allows combine nontext data text data derive sophisticated predictors prediction problem specifically interested contextual text mining thats text rich context information direct context metadata indirect context direct context grow metadata time location authors source text data theyre available play video starting 114 follow transcript 114 indirect context refers additional data related metadata example office obtain additional context social network author authors age play video starting 130 follow transcript 130 information general directly related text process connect text data source text connected text general related data regarded context removed rated context play video starting 155 follow transcript 155 whats text context context partition text data interesting ways allow partition text data ways important allows interesting comparative analyses general provides meaning discovered topics associate text context play video starting 225 follow transcript 225 heres illustration context regarded interesting ways partitioning text data showed research papers published different years play video starting 241 follow transcript 241 different venues different conference names listed bottom sigir acl play video starting 249 follow transcript 249 text data partitioned interesting ways context play video starting 256 follow transcript 256 context includes time conference venues variables play video starting 36 follow transcript 306 lets partition interesting ways treat paper separate unit case paper id paper context independent treat papers 1998 group possible availability time partition data way allow compare topics example different years play video starting 339 follow transcript 339 similarly partition data based menus sigir papers compare papers rest compare sigir papers kdd papers acl papers play video starting 352 follow transcript 352 partition data obtain papers written authors course uses additional context authors allow compare subset set papers written countries play video starting 413 follow transcript 413 obtain set papers text mining compared papers topic note partitionings intersected generate complicated partitions play video starting 429 follow transcript 429 general enables discovery knowledge associated different context needed play video starting 437 follow transcript 437 particular compare different contexts gives lot useful knowledge example comparing topics time trends topics comparing topics different contexts reveal differences two contexts interesting questions require contextual text mining list specific ones example topics getting increasing attention recently data mining research answer question obviously analyze text context time play video starting 513 follow transcript 513 time context case difference responses people different regions event event broad answer question case course location context common research interests two researchers case authors context difference research topics published authors usa case context authors affiliation location play video starting 547 follow transcript 547 goes author look additional information connected author difference opinions topics expressed social network case social network authors topic context play video starting 66 follow transcript 606 topics news data correlated sudden changes stock prices case time series stock prices context play video starting 617 follow transcript 617 issues mattered 2012 presidential campaign presidential election case time serves context list basically contextual text mining applications music
play video starting follow transcript 000 music lecture specific technique contextual text mining called contextual probabilistic latent semantic analysis play video starting 19 follow transcript 019 lecture going continue discussing contextual text mining going introduce contextual probablitistic latent semantic analysis exchanging pos contextual text mining play video starting 34 follow transcript 034 recall contextual text mining hope analyze topics text consideration context associate topics property context interesting play video starting 48 follow transcript 048 approach contextual probabilistic latent semantic analysis cplsa main idea express add interesting context variables generating model play video starting 13 follow transcript 103 recall generate text generally assume start topics assemble words topics going add context variables coverage topics content topics tied context words going context influence coverage content topic play video starting 131 follow transcript 131 consequences enable discover contextualized topics make topics interesting meaningful topics interpreted specifically particular context interested example particular time period play video starting 152 follow transcript 152 extension plsa model cplsa following changes firstly model conditional likelihood text given context play video starting 27 follow transcript 207 clearly suggests generation text depend context allows bring context generative model play video starting 218 follow transcript 218 secondly makes two specific assumptions dependency topics context assume depending context depending different time periods different locations assume different views topic different versions word descriptions characterize topic play video starting 238 follow transcript 238 assumption allows discover different variations topic different contexts play video starting 246 follow transcript 246 assume topic coverage depends context play video starting 255 follow transcript 255 means depending time location cover topics differently play video starting 3 follow transcript 300 dependency allow capture association topics specific contexts em algorithm solve problem parameter estimation play video starting 316 follow transcript 316 case estimated parameters naturally contain context variables particular lot conditional probabilities topics given context allows contextual text mining basic idea play video starting 335 follow transcript 335 dont time introduce model detail references look know detail explain high level ideas detail particularly explain generation process text data context associated model play video starting 41 follow transcript 401 assume multiple topics example topics represent themes government response donation city new orleans example context hurricane katrina hit new orleans play video starting 422 follow transcript 422 assume different views associated topics view 1 view 2 view 3 view different version word distributions views tied context variables example tied location texas time july 2005 occupation author sociologist play video starting 456 follow transcript 456 right side assume document context information time known july 2005 location texas context information hope model going model text play video starting 515 follow transcript 515 idea model variations top content various content gives different views water distributions play video starting 527 follow transcript 527 bottom theme coverage top coverage vary context case location texas people cover red topics thats new orleans thats visualized time period particular topic covered variation considered cplsa generate searcher document context view play video starting 68 follow transcript 608 view course contexts lets say taken view depends time middle specific version word distributions probabilities words topic play video starting 626 follow transcript 626 chosen view situation similar happened standard prsa assume got word distribution associated topic right play video starting 639 follow transcript 639 coverage bottom going particular coverage coverage fixed plsa assigned particular document document coverage distribution play video starting 658 follow transcript 658 consider context distribution topics coverage topics vary depending context influenced coverage play video starting 710 follow transcript 710 example pick particular coverage lets say case picked document specific coverage play video starting 720 follow transcript 720 coverage word distributions generate document exactly way plsa means going coverage topic three topics lets say picked yellow topic draw word particular topic top play video starting 744 follow transcript 744 okay word government time different topic donate generate words basically process plsa play video starting 8 follow transcript 800 main difference obtain coverage word distribution context influence choice words extra switches tied contacts control choices different views topics choices coverage play video starting 822 follow transcript 822 naturally model parameters estimate estimate parameters involve context able understand context specific views topics context specific coverages topics precisely contextual text mining play video starting 840 follow transcript 840 simple results model necessary exactly model similar models slide sample results comparing news articles iraq war afghanistan war play video starting 856 follow transcript 856 30 articles iraq war 26 articles afghanistan war case goal review common topic covered sets articles differences variations topic two collections play video starting 918 follow transcript 918 case context explicitly specified topic collection play video starting 925 follow transcript 925 results show common theme thats corresponding cluster 1 column common theme indicting united nations involved wars common topic covered sets articles thats indicated high probability words united nations play video starting 951 follow transcript 951 know background course surprising topic relevant wars look column whats interestings two cells word distributions actually tell collection specific variations topic united nations indicates iraq war united nations involved weapons factions afghanistan war involved aid northern alliance different variation topic united nations play video starting 1030 follow transcript 1030 shows bringing context case different walls different collection texts topical variations tied contexts review differences coverage united nations two wars play video starting 1046 follow transcript 1046 similarly look second cluster class two killing people surprising know background wars wars involve killing people imagine familiar text collections lot text articles technique reveal common topics covered sets articles review common topics multiple sets articles look course column cluster two variations killing people corresponds different contexts play video starting 1128 follow transcript 1128 example results obtained blog articles hurricane katrina play video starting 1137 follow transcript 1137 case visualization trends topics time play video starting 1147 follow transcript 1147 top shows temporal trends two topics oil price flooding city new orleans play video starting 12 follow transcript 1200 topics obtained blog articles hurricane katrina play video starting 127 follow transcript 1207 people talk topics end teaching topics visualisation shows technique conditional distribution time given topic allows plot conditional probability curve youre initially two curves tracked later topic new orleans mentioned oil price turns time period hurricane hurricane rita hit region apparently triggered discussion flooding city play video starting 1254 follow transcript 1254 bottom curve shows coverage topic flooding city block articles different locations shows shift coverage related peoples migrating state louisiana texas example play video starting 1320 follow transcript 1320 case time context review trends topics play video starting 1327 follow transcript 1327 additional results spacial patterns case topic government response criticism slow response government case hurricane katrina play video starting 1344 follow transcript 1344 discussion covered different locations visualizations show coverage different weeks event initially covered victim states south gradually spread locations four bottom left pattern thats similar top left thats hurricane rita hit region technique allow location context examine issues topics course moral completely general apply connections text review spatial temporal patterns play video starting 1434 follow transcript 1434 view found application model look model event impact analysis play video starting 1443 follow transcript 1443 looking research articles information retrieval ir particularly sigir papers topic focusing retrieval models top words high probability model left play video starting 1459 follow transcript 1459 hope examine impact two events start trec text retrieval conference major evaluation sponsored government launched 1992 time known made impact topics research information retrieval play video starting 1523 follow transcript 1523 publication seminal paper croft porte language model approach information retrieval known made high impact information retrieval research hope model understand impact idea simply time context events divide time periods period event event compare differences topics variations case results show track study retrieval models vector space model boolean model trec apparently study retrieval models involved lot words suggest different retrieval tasks example email enterprise search tasks subtopical retrieval task later introduced trec play video starting 1628 follow transcript 1628 bottom variations correlated propagation language model paper classic probability risk model logic model boolean 1998 clear dominance language model probabilistic models words language model estimation parameters technique events context understand impact event technique generals analyze impact event suggested readings play video starting 1711 follow transcript 1711 paper simple staging psi label crosscollection comparison play video starting 1721 follow transcript 1721 perform comparative text mining allow extract common topics shared multiple collections variations collection play video starting 1731 follow transcript 1731 second main paper cplsa model discussion lot applications third lot details special temporal patterns hurricane katrina example music
play video starting follow transcript 000 sound lecture mine text data social network context lecture going continue discussing contextual text mining particular going look social network context play video starting 26 follow transcript 026 whats motivation network context analysis text play video starting 32 follow transcript 032 context text article form network play video starting 37 follow transcript 037 example authors research articles form collaboration networks play video starting 44 follow transcript 044 authors social media content form social networks example twitter people follow facebook people claim friends context connects content similarly locations associated text connected form geographical network general imagine metadata text data form network relations play video starting 124 follow transcript 124 benefit jointly analyzing text social network context network context general thats network impose constraints topics text play video starting 141 follow transcript 141 example reasonable assume authors connected collaboration networks tend write similar topics play video starting 153 follow transcript 153 heuristics guide analyzing topics text help characterize content associated subnetwork say play video starting 211 follow transcript 211 kinds data network text help play video starting 216 follow transcript 216 example difference opinions expressed two subnetworks reviewed type joint analysis play video starting 230 follow transcript 230 briefly model called network supervised topic model play video starting 240 follow transcript 240 slide going give general ideas slide going give details play video starting 248 follow transcript 248 general part course dont time cover frontier topics detail references allow read topic know details play video starting 35 follow transcript 305 useful know general ideas know know able general idea network supervised topic model following lets start viewing regular topic models lda sorting optimization problem course case optimization objective function likelihood function maximum likelihood estimator obtain parameters parameters give useful information obtain text data example topics maximize probability tests given parameters generally denoted number main idea incorporating network think constraints imposed based network general idea network impose constraints model parameters lambda example text adjacent nodes network similar cover similar topics cases tend cover similar topics play video starting 434 follow transcript 434 able smooth topic distributions play video starting 439 follow transcript 439 graph network adjacent nodes similar topic distributions share common distribution topics slight variations topic distributions coverage play video starting 52 follow transcript 502 technically simply add network regularizers likelihood objective function optimize probability test data given parameters lambda going optimize function f play video starting 519 follow transcript 519 function combines likelihood regularizer function called r regularizer defines parameters lambda network tells basically parameters preferred network constraint perspective easily effect implementing idea imposing prior model parameters necessary having probabilistic model idea going combine two single objective function play video starting 557 follow transcript 557 advantage idea general top model generative model text play video starting 67 follow transcript 607 doesnt plsa lea current topic models play video starting 612 follow transcript 612 similarly network network graph connects text objects play video starting 622 follow transcript 622 regularizer regularizer flexible capturing different heuristics capture play video starting 632 follow transcript 632 finally function f vary different ways combine general idea actually powerful offers general approach combining different types data single optimization framework general idea applied problem play video starting 656 follow transcript 656 paper reference particular instantiation called netplsa started case instantiating plsa incorporate simple constraint imposed network prior neighbors network similar topic distribution cover similar topics similar ways thats basically says english play video starting 724 follow transcript 724 technically modified objective function lets define texts actually network graph g play video starting 734 follow transcript 734 look formula actually recognize part fairly familiarly play video starting 740 follow transcript 740 fairly familiar recognize part likelihood test given topic model play video starting 752 follow transcript 752 look part precisely plsa loglikelihood maximize estimate parameters plsa second equation shows additional constraints parameters particular measure difference topic coverage node u node v two adjacent nodes network distributions similar computing square differences minimize difference note theres negative sign sum sum makes possible find parameters maximize plsa loglikelihood means parameters fit data respect constraint network play video starting 96 follow transcript 906 negative sign mentioned negative sign maximize object function actually minimize statement term play video starting 919 follow transcript 919 look picture results weight edge u v space network weight says two nodes strong collaborators researchers two strong connections two people social network weight means important theyre topic coverages similar thats basically says play video starting 955 follow transcript 955 finally parameter lambda new parameter control influence network constraint easily lambda set 0 back standard plsa lambda set larger value network influence estimated models effect going basically plsa going try make topic coverages two nodes strongly connected similar ensure coverages similar play video starting 1033 follow transcript 1033 results paper slide shows record results plsa data dblp data bibliographic data research articles experiments four communities applications ir information retrieval dm stands data mining ml machinery web four communities articles hoping play video starting 116 follow transcript 1106 topic mining help uncover four communities assembled topics generated plsa plsa generate four communities correspond intuition reason mixed words shared communities easy four topics separate topics coherent topics play video starting 1142 follow transcript 1142 whats interesting netplsa network collaboration network case authors impose constraints case four topics ned pierre gave meaningful topics topics correspond four communities information retrieval second data mining third machine learning fourth web separation influence network leverage collaboration network information essentially people form collaborating network assumed write similar topics thats going coherent topics listen text data based occurrences wont coherent topics topic model plsa lda able pick cooccurring words general topics generate represent words cooccur generate coherent results netplsa showing network contest useful play video starting 138 follow transcript 1308 similar model useful characterize content associated subnetwork collaborations play video starting 1319 follow transcript 1319 general view text mining context network treat text living rich information network environment means connect related data big network text data associated lot structures network example text data associated nodes network thats basically discussed netplsa text data associated age paths subnetworks way represent texts big environment context information powerful allows analyze data information general analysis text entire network information thats related text data heres suggested reading paper netplsa find details model make model music
play video starting follow transcript 000 sound play video starting 7 follow transcript 007 lecture time series context potentially discover causal topics text lecture going continue discussing contextual text mining particular going look time series context analyzing text potentially discover causal topics usual started motivation case hope text mining understand time series dow jones industrial average stock price curves youll sudden drop right interested knowing caused stock market crash play video starting 48 follow transcript 048 know background able figure look time stamp data help think question clues companion news stream lot news data generated period play video starting 18 follow transcript 108 actually discover crash happened time september 11 attack thats time sudden rise topic september 11 happened news articles play video starting 126 follow transcript 126 heres scenario analyze presidential election time series presidential prediction market example write trunk market stocks candidate believe candidate win tend buy stock candidate causing price candidate increase thats nice way actual survey peoples opinions candidates play video starting 2 follow transcript 200 suppose drop price candidate know caused sudden drop play video starting 210 follow transcript 210 social science study interested knowing method election issues matter people case look companion news stream ask question clues news stream insight example discover mention tax cut play video starting 235 follow transcript 235 increasing point thats related drop price cases special cases general problem joint analysis text time series data discover causal topics input case time series plus text data produced time period companion text stream play video starting 32 follow transcript 302 different standard topic models text collection thats time series serves context play video starting 313 follow transcript 313 output generate topics coverage text stream strong correlations time series play video starting 322 follow transcript 322 example topic managing price tends play video starting 328 follow transcript 328 call topics causal topics course theyre strictly speaking causal topics going able verify causal theres true causal relationship thats put causal quotation marks least correlating topics potentially explain cause humans certainly analyze topics understand issue better play video starting 359 follow transcript 359 output contain topics topic modeling hope topics regular topics topics certainly dont explain data best text explain data text meaning reprehend meaningful topics text cement importantly correlated external hand series thats given context understand solve problem lets adjust solve problem reactive topic model example prsa apply text stream extension cprsa contextual prsa discover topics correlation discover coverage time play video starting 453 follow transcript 453 simple solution topics set strongest correlation external time series play video starting 55 follow transcript 505 approach going good awareness pictured topics discover prsa lda means choice topics limited know models try maximize likelihood text data topics tend major topics explain text data aand necessarily correlated time series best correlated topics play video starting 534 follow transcript 534 interesting causal perspective play video starting 537 follow transcript 537 work site better approach proposed approach called iterative causal topic modeling idea iterative adjustment topic discovered topic models time series induce product play video starting 557 follow transcript 557 heres illustration work works take text stream input apply regular topic modeling generate number topics lets say four topics play video starting 69 follow transcript 609 going external time series assess topic causally related correlated external time series rank think topic topic four correlated topic two topic three stopped simple approached talked earlier topics call causal topics explained topics unlikely good general topics explain text connection necessary best topics correlated time series play video starting 651 follow transcript 651 approach zoom word level look word top ranked word listed topic lets say take topic 1 target examined know topic 1 correlated time series least best set topics play video starting 718 follow transcript 718 going look words topic top words play video starting 723 follow transcript 723 topic correlated time series words highly correlated time series example discover w1 w3 positively correlated time series w2 w4 negatively correlated play video starting 741 follow transcript 741 topic good mix words different correlations separate words going red words indicate positive correlations w1 w3 going sub topic play video starting 8 follow transcript 800 represents negatively correlated words w2 w4 play video starting 87 follow transcript 807 subtopics variations topics based correlation analysis topics related original topic topic 1 deviating time series information bias selection words sense expect sense correlated time series original topic 1 topic 1 mixed words separate play video starting 842 follow transcript 842 two subtopics play video starting 846 follow transcript 846 expected better coherent time series coherent mention idea back topic model prior guide topic modeling thats say ask topic models discover topics similar two subtopics cause bias correlate topics time series course apply topic models generation topics ran base time series set highly correlated topics analyze components work topic try analyzeword level correlation correlated subtopics fed process prior drive topic model discovery play video starting 946 follow transcript 946 process heuristic way optimizing causality coherence thats ultimate goal right pure topic models good maximizing topic coherence topics meaningful play video starting 102 follow transcript 1002 causality test correlation measure set words strongly correlate time series necessarily mean cementric connected extreme top play video starting 1021 follow transcript 1021 ideal causal topic thats scored high topic coherence causal relation approach regarded alternate way maximize sine engines apply topic models maximizing coherence decompose topic model words sets words strong correlated time series select strongly correlated words time series pushing model back causal dimension make better causal scoring apply selected words prior guide topic modeling back optimize coherence topic models ensure generation topics coherent iterate theyre optimized way picture play video starting 1120 follow transcript 1120 think component havent framework measure causality rest talking lets bit discussion show lets say topic government response talking coverage topic time time series x sub t play video starting 1143 follow transcript 1143 give time series represents external information non text time series y sub t stock prices question xt cause yt play video starting 1158 follow transcript 1158 words match causality relation two measure correlation two play video starting 128 follow transcript 1208 measures framework example pairs correlation common measure got consider time lag try capture causal relation past data data past play video starting 1226 follow transcript 1226 try correlate data points y represents future example introducing lag hopefully capture causal relation correlation measures person correlation play video starting 1245 follow transcript 1245 common measure causality granger causality test play video starting 1252 follow transcript 1252 idea test actually simple basically youre going regressive model history information y predict best information going build model going add history information x model improve prediction y statistically significant difference say x causal inference y wouldnt causal improvement prediction y play video starting 1332 follow transcript 1332 hand difference insignificant mean x cause relation thats basic idea dont time explain detail read read cited reference know measure convenient measure applications play video starting 1355 follow transcript 1355 lets look simple results generated approach data new york times time period june 2000 december 2011 time series stock prices two companies american airlines apple goal inject sum time series contest actually topics wise time series imagine dont input dont context topics new york times discovered prsa general topics people talk news right major topics news event play video starting 1441 follow transcript 1441 topics biased time series particularly look underlined words american airlines result airlines airport air united trade terrorism clearly topics correlated external time series right side topics clearly related apple right computer technology software internet com web means time series effectively served context bias discovery topics perspective results help people talked case people people talked topics correlated stock prices topics serve starting point people look issues youll find true causal relations results analyzing presidential election time series time series data iowa electronic market thats prediction market data new york times 2000 october 2000 thats 2000 presidential campaign election top three words significant topics new york times play video starting 1621 follow transcript 1621 look topics related campaign actually issues related important issues presidential election mention text data filtered articles mention candidate names play video starting 1645 follow transcript 1645 subset news articles different previous experiment play video starting 1653 follow transcript 1653 results clearly show approach uncover important issues presidential election tax cut oil energy abortion gun control known important issues presidential election supported literature political science play video starting 1717 follow transcript 1717 discussing wikipedia right basically results show approach effectively discover possibly causal topics based time series data play video starting 1735 follow transcript 1735 two suggested readings paper iterative topic modeling time series feedback find details approach works second reading granger casuality text play video starting 1755 follow transcript 1755 end lets summarize discussion textbased prediction textbased prediction generally useful big data applications involve text help inform new knowledge world knowledge whats discussed text play video starting 1817 follow transcript 1817 result support optimizing decision making wider spread application play video starting 1828 follow transcript 1828 text data combined nontext data prediction purpose prediction purpose generally combine nontext data text data cruel possible prediction result analysis text nontext necessary useful analyze text data nontext data help nontext data context mining text data discussed number techniques contextual text mining hand text data help interpret patterns discovered nontext data called pattern annotation play video starting 1914 follow transcript 1914 general active research topic new papers published open challenges solved music
play video starting 6 follow transcript 006 lecture summary course play video starting 10 follow transcript 010 lets revisit topics covered course beginning talked natural language processing enrich text representation talked mine knowledge language natural language express whats observing world text data play video starting 34 follow transcript 034 particular talked mine word associations talked analyze topics text discover topics analyze play video starting 47 follow transcript 047 regarded knowledge observed world talked mine knowledge observer particularly talk mine opinions sentiment analysis finally talk textbased prediction predicting values real world variables based text data discussing discuss role nontext data contribute additional predictors prediction problem context analyzing text data particular talked context analyze topics play video starting 133 follow transcript 133 key highlevel take away messages cost going major topics point key takeaway messages remember play video starting 147 follow transcript 147 nlp text representation play video starting 153 follow transcript 153 realize nlp important text replication enriches text representation nlp better text representation enables accurate knowledge discovery discover deeper knowledge buried text play video starting 212 follow transcript 212 current estate art natural energy processing robust result robust text mining technologies today tend based world inaudible tend rely lot statistical analysis weve discussed course recall weve word based representations weve relied lot statistical techniques statistical learning techniques particularly play video starting 247 follow transcript 247 wordassociation mining analysis important points introduced two concepts two basic complementary relations words paradigmatic syntagmatic relations actually general relations elements sequences take meaning elements occur similar context sequence elements tend cooccur relations meaningful sequences data play video starting 325 follow transcript 325 talked lot test similarity discuss discover paradynamic similarities compare context words discover words share similar context point level talked representing text data vector space model talked retrieval techniques bm25 measuring similarity text assigning weights terms tfidf weighting cetera part wellconnected text retrieval techniques relevant play video starting 43 follow transcript 403 point cooccurrence analysis text introduce information theory concepts entropy conditional entropy mutual information useful measuring cooccurrences words useful analyzing data useful example feature selection text categorization play video starting 430 follow transcript 430 important concept good know play video starting 435 follow transcript 435 talked topic mining analysis thats introduce probabilistic topic model spent lot time explain basic topic model plsa detail basics understanding lda theoretically opinion model did time depth introducing lda play video starting 52 follow transcript 502 practice plsa effective lda simpler implement efficient play video starting 511 follow transcript 511 part wilson videos general concepts useful know generative model general method modeling text data modeling kinds data play video starting 524 follow transcript 524 talked maximum life erase data em algorithm solving problem computing maximum estimator general techniques tend useful scenarios play video starting 540 follow transcript 540 talked text clustering text categorization two important building blocks text mining application systems text clustering talked solve problem slightly different mixture module probabilistic topic model prefer view similarity based approaches test cuss word play video starting 611 follow transcript 611 categorization talk two kinds approaches generative classifies rely base word play video starting 620 follow transcript 620 infer condition probability category given text data deeper introduce inaudible base detail play video starting 629 follow transcript 629 practical technique lot text capitalization tasks play video starting 637 follow transcript 637 introduce discriminative classifiers particularly logistical regression nearest labor sbn important popular useful text capitalization play video starting 652 follow transcript 652 parts discuss evaluate results evaluation important matches dont reflect volatility method give misleading results important variation right talked variation categorization detail lot specific measures play video starting 718 follow transcript 718 talked sentiment analysis paradigm thats introduced sentiment classification problem special case text recalculation talked extend improve text recalculation method sophisticated features needed sentiment analysis did review common complex features text analysis talked capture order categories sentiment classification particular introduced ordinal logistical regression talked latent aspect rating analysis unsupervised way generative model understand review data detail particular allows understand composed ratings play video starting 814 follow transcript 814 reviewer different aspects topic given text reviews overall ratings method allows ratings different aspects allows infer viewers laying weights aspects aspects important viewer revealed enables lot interesting applications play video starting 841 follow transcript 841 finally discussion prediction mainly talk joint mining text non text data important prediction play video starting 851 follow transcript 851 particularly talked text data help nontext data vice versa play video starting 858 follow transcript 858 case nontext data help text data analysis talked contextual text mining introduced contextual plsa generalizing generalized model plsa allows incorporate context variables time location general way allow reveal lot interesting topic patterns text data introduced net plsa case social network network general text data help analyze puppets play video starting 931 follow transcript 931 finally talk context mine potentially causal topics text layer play video starting 943 follow transcript 943 way text play video starting 947 follow transcript 947 help interpret patterns discovered lam text data did discuss detail reference stress thats important direction know build practical text mining systems understanding interpreting patterns important play video starting 1013 follow transcript 1013 summary key take away messages hope useful building text mining applications starting algorithms good basis read research papers know allowance organisms invent new hours play video starting 1040 follow transcript 1040 know topic suggest look areas depth play video starting 1048 follow transcript 1048 short period time course touch basic concepts basic principles text mining emphasize coverage practical algorithms cost covering algorithms cases omit discussion lot algorithms learn subject definitely learn natural language process foundation text based applications nlp better additional text deeper knowledge discover important play video starting 1137 follow transcript 1137 second area look statistical machine learning play video starting 1141 follow transcript 1141 techniques backbone techniques play video starting 1146 follow transcript 1146 text analysis applications nlp lot nlp techniques actually based supervised machinery play video starting 1156 follow transcript 1156 important key understanding advancing nlp techniques naturally tools text analysis general play video starting 129 follow transcript 1209 particularly interesting area called deep learning attracted lot attention recently promise application areas especially speech vision applied text data example recently work deep learning segment analysis achieve better accuracy thats example inaudible techniques werent able cover thats important play video starting 1241 follow transcript 1241 area emerged status learning water baring technique learn better recognition words better recognitions allow confuse similarity words provides directly way discover paradigmatic relations words results people got impressive thats promising technique did time touch play video starting 1312 follow transcript 1312 course new techniques lead practical useful techniques work better current technologies open question examined serious evaluation done example examining practical value word embedding word similarity basic evaluation play video starting 1336 follow transcript 1336 advanced techniques surely make impact text mining future important know statistical learning key predictive modeling crucial big data applications did talk predictive modeling component regression categorization techniques reason statistical learning important play video starting 147 follow transcript 1407 suggest learn data mining thats simply general data mining algorithms applied text data regarded special case general data play video starting 1423 follow transcript 1423 applications data mining techniques particular example pattern discovery useful generate interesting features test analysis reason information network mining techniques analyze text information work play video starting 1442 follow transcript 1442 good know order develop effective text analysis techniques finally recommend learn text retrieval information retrieval search engines especially important interested building practical text application systems search ending essential system component textbased applications thats texts data created humans consume humans best position understand text data important human loop big text data applications particular help text mining systems two ways effectively reduce data size large collection small collection relevant text data matter particular interpretation way annotate explain parents knowledge providence discover knowledge figure discovery reliable back original text verify search engine important play video starting 164 follow transcript 1604 techniques information retrieval example bm25 vector space useful text data mining mention know text retrieval youll techniques technique indexing technique enables quick response search engine users query techniques useful building efficient text mining systems play video starting 1635 follow transcript 1635 finally remind big picture harnessing big text data showed beginning semester play video starting 1645 follow transcript 1645 general deal big text application system two kinds text text retrieval text mining play video starting 1653 follow transcript 1653 text retrieval explained help convert big text data small amount relevant data particular problem help providing knowledge provenance help interpreting patterns later text mining analyzing relevant data discover actionable knowledge directly useful decision making tasks course covers text mining theres companion course called text retrieval search engines covers text retrieval havent taken course useful take especially interested building text caching system taking courses give complete set practical skills building system inaudible thank taking course hope learned useful knowledge skills test mining inaudible discussions lot opportunities techniques lot open channels hope learned build lot applications benefit society join research community discover new techniques text mining benefits thank music
practice quiz 12 practice quiz activity completed submit assignment try activity completed receive grade grade 8750 view feedback keep highest score dislike report issue
quiz 12 quiz activity completed submit assignment due november 26 959 pm pst nov 26 959 pm pst try activity completed receive grade grade 100 view feedback keep highest score dislike report issue
graded assignment project progress report submission grading assignment details due november 19 959 pm pst nov 19 959 pm pst attempts unlimited grading begins start grade haven’t submitted keep latest score available dislike report issue
mp32 overview mp32 classification competition part develop classifier participate classification competition classifier evaluated f1 scores 2 datasets metamia dataset created metamiacom mp31 analogy dataset collected annotated classmates livedatalab link httplivedatalab23centraluscloudappazurecom mp32 project github link put mp32 project course uses thirdparty app mp32 enhance learning experience app reference basic information name email coursera id coursera honor code learn monika thotha understand submitting work isn’t result permanent failure course deactivation coursera account launch app dislike report issue
graded assignment project code documentation presentation assignment details due december 15 959 pm pst dec 15 959 pm pst attempts unlimited grading begins start grade haven’t submitted keep latest score available dislike report issue
course course iframes supported browser expand mark completed dislike report issue
